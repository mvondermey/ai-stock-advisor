[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üñ•Ô∏è  FORCE_CPU enabled - PyTorch models will run on CPU (allows higher parallelism)
[INTERNET] Connection verified, using local time with internet sync: 2025-12-29 21:11:02 UTC
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
Using initial balance: $100,000.00
   üìä After fractionable filter: 5903 tickers
   üìä After ADR/special filter: 5649 tickers (filtered out 254)
   ‚úÖ Removed 254 foreign ADRs/special securities (e.g., symbols ending in Y)
[SUCCESS] Fetched 5649 tradable US equity tickers from Alpaca.
Total unique tickers found: 5649
üöÄ Step 1: Batch downloading data for 5649 tickers from 2024-09-29 to 2025-12-29...
  (Requesting 456 days of data based on BACKTEST_DAYS=90 + TRAIN_LOOKBACK_DAYS=365)
  - Downloading batch 1/1 (5649 tickers)...
  ‚ÑπÔ∏è  Market data not available yet (markets closed or processing). Using cached data.
  üìÇ Checking cache for 5649 tickers...
  ‚úÖ Cache hit for A (312 rows, 100% coverage)
  ‚úÖ Cache hit for AA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AAAU (312 rows, 100% coverage)
  ‚úÖ Cache hit for AAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for AAMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for AAOI (312 rows, 100% coverage)
  ‚úÖ Cache hit for AAON (312 rows, 100% coverage)
  ‚úÖ Cache hit for AAP (312 rows, 100% coverage)
  ‚úÖ Cache hit for AAPG (312 rows, 100% coverage)
  ‚úÖ Cache hit for AAPL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for AAXJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for AB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABBV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABCL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABEO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABEV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABFL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABNB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABVX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ABXB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACAD (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACES (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACET (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACGL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACGLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACIW (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACMR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACNB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACP (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACTG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACWI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACWV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ACWX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AD (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADBE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADEA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADME (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADP (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADSE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADSK (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADTN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ADV (312 rows, 100% coverage)
  ‚úÖ Cache hit for AEE (312 rows, 100% coverage)
  ‚úÖ Cache hit for AEG (312 rows, 100% coverage)
  ‚úÖ Cache hit for AEHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AEIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for AEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for AENT (312 rows, 100% coverage)
  ‚úÖ Cache hit for AEO (312 rows, 100% coverage)
  ‚úÖ Cache hit for AEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for AER (312 rows, 100% coverage)
  ‚úÖ Cache hit for AES (312 rows, 100% coverage)
  ‚úÖ Cache hit for AESI (312 rows, 100% coverage)
  ‚úÖ Cache hit for AESR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AEVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AFCG (312 rows, 100% coverage)
  ‚úÖ Cache hit for AFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for AFGB (312 rows, 100% coverage)
  ‚úÖ Cache hit for AFGC (312 rows, 100% coverage)
  ‚úÖ Cache hit for AFGD (312 rows, 100% coverage)
  ‚úÖ Cache hit for AFGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for AFIF (312 rows, 100% coverage)
  ‚úÖ Cache hit for AFK (312 rows, 100% coverage)
  ‚úÖ Cache hit for AFL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AFRM (312 rows, 100% coverage)
  ‚úÖ Cache hit for AFYA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AG (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGG (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGGH (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGGY (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGM (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGNCM (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGNCN (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGNCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGNCP (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGNG (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGOX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGYS (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for AGZD (312 rows, 100% coverage)
  ‚úÖ Cache hit for AHCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for AHH (312 rows, 100% coverage)
  ‚úÖ Cache hit for AHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AHT (312 rows, 100% coverage)
  ‚úÖ Cache hit for AI (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIEQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIFF (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIFU (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIM (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIRJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIRR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AISP (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIVL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for AIZN (312 rows, 100% coverage)
  ‚úÖ Cache hit for AJG (312 rows, 100% coverage)
  ‚úÖ Cache hit for AKAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for AKBA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AKO-B (312 rows, 100% coverage)
  ‚úÖ Cache hit for AKR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALF (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALGM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALGT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALK (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALKS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALKT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALLE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALMS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALNY (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALRM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALSN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALTG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALTO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALVO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ALXO (312 rows, 100% coverage)
  ‚úÖ Cache hit for AM (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMBA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMBP (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMCR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMCX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMDL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMDY (312 rows, 100% coverage)
  ‚úÖ Cache hit for AME (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMG (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMH (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMKR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMLP (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMN (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMP (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMPH (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMPL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMSF (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMWD (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMWL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMZA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMZN (312 rows, 100% coverage)
  ‚úÖ Cache hit for AMZY (312 rows, 100% coverage)
  ‚úÖ Cache hit for AN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANDE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANET (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANEW (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANF (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANGH (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANGL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANIK (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANNX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ANSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for AOA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AOD (312 rows, 100% coverage)
  ‚úÖ Cache hit for AOK (312 rows, 100% coverage)
  ‚úÖ Cache hit for AOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for AON (312 rows, 100% coverage)
  ‚úÖ Cache hit for AOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AORT (312 rows, 100% coverage)
  ‚úÖ Cache hit for AOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for AOSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AOUT (312 rows, 100% coverage)
  ‚úÖ Cache hit for APA (312 rows, 100% coverage)
  ‚úÖ Cache hit for APAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for APCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for APD (312 rows, 100% coverage)
  ‚úÖ Cache hit for APEI (312 rows, 100% coverage)
  ‚úÖ Cache hit for APG (312 rows, 100% coverage)
  ‚úÖ Cache hit for APGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for APH (312 rows, 100% coverage)
  ‚úÖ Cache hit for API (312 rows, 100% coverage)
  ‚úÖ Cache hit for APIE (312 rows, 100% coverage)
  ‚úÖ Cache hit for APLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for APLE (312 rows, 100% coverage)
  ‚úÖ Cache hit for APLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for APO (312 rows, 100% coverage)
  ‚úÖ Cache hit for APOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for APP (312 rows, 100% coverage)
  ‚úÖ Cache hit for APPF (312 rows, 100% coverage)
  ‚úÖ Cache hit for APPN (312 rows, 100% coverage)
  ‚úÖ Cache hit for APPS (312 rows, 100% coverage)
  ‚úÖ Cache hit for APRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for APTV (312 rows, 100% coverage)
  ‚úÖ Cache hit for APUE (312 rows, 100% coverage)
  ‚úÖ Cache hit for APYX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AQN (312 rows, 100% coverage)
  ‚úÖ Cache hit for AQNB (312 rows, 100% coverage)
  ‚úÖ Cache hit for AR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARDT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARES (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARGT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARGX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARHS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARKB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARKF (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARKG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARKK (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARKO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARKQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARKW (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARKX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARLP (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARMK (312 rows, 100% coverage)
  ‚úÖ Cache hit for AROC (312 rows, 100% coverage)
  ‚úÖ Cache hit for AROW (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARQQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARQT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARRY (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARTNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARW (312 rows, 100% coverage)
  ‚úÖ Cache hit for ARWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASEA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASH (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASHS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASLE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASML (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASND (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASPN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASPS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASTE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASUR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ASX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATER (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATHA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATHM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATKR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATMP (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATMU (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATNI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATON (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATXS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ATYR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AU (312 rows, 100% coverage)
  ‚úÖ Cache hit for AUB (312 rows, 100% coverage)
  ‚úÖ Cache hit for AUDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for AUNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AUPH (312 rows, 100% coverage)
  ‚úÖ Cache hit for AUR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AURA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AUSF (312 rows, 100% coverage)
  ‚úÖ Cache hit for AUTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVAH (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVAV (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVB (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVBP (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVD (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVDE (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVDL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVDV (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVES (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVIR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVMU (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVNS (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVNW (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVO (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVSF (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVSU (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVT (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVUV (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVXL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AVY (312 rows, 100% coverage)
  ‚úÖ Cache hit for AWAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for AWI (312 rows, 100% coverage)
  ‚úÖ Cache hit for AWK (312 rows, 100% coverage)
  ‚úÖ Cache hit for AWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for AX (312 rows, 100% coverage)
  ‚úÖ Cache hit for AXGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for AXIA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AXL (312 rows, 100% coverage)
  ‚úÖ Cache hit for AXON (312 rows, 100% coverage)
  ‚úÖ Cache hit for AXP (312 rows, 100% coverage)
  ‚úÖ Cache hit for AXS (312 rows, 100% coverage)
  ‚úÖ Cache hit for AXSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for AXTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AXTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for AYI (312 rows, 100% coverage)
  ‚úÖ Cache hit for AZN (312 rows, 100% coverage)
  ‚úÖ Cache hit for AZO (312 rows, 100% coverage)
  ‚úÖ Cache hit for AZTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for AZZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for B (312 rows, 100% coverage)
  ‚úÖ Cache hit for BA (312 rows, 100% coverage)
  ‚úÖ Cache hit for BAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BABA (312 rows, 100% coverage)
  ‚úÖ Cache hit for BAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BACQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BAER (312 rows, 100% coverage)
  ‚úÖ Cache hit for BAH (312 rows, 100% coverage)
  ‚úÖ Cache hit for BAK (312 rows, 100% coverage)
  ‚úÖ Cache hit for BALI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BALL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BALT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for BANC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BAND (312 rows, 100% coverage)
  ‚úÖ Cache hit for BANF (312 rows, 100% coverage)
  ‚úÖ Cache hit for BANR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BAP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BAPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BARK (312 rows, 100% coverage)
  ‚úÖ Cache hit for BATRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for BATRK (312 rows, 100% coverage)
  ‚úÖ Cache hit for BATT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BAUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for BAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBAG (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBBY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBCA (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBCP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBDO (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBEU (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBH (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBJP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBU (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBUC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBW (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBWI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BBY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCD (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCH (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCML (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCS (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCSF (312 rows, 100% coverage)
  ‚úÖ Cache hit for BCYC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BDEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BDN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BDRY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BDSX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BDTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BEAG (312 rows, 100% coverage)
  ‚úÖ Cache hit for BEAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for BEEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for BEKE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BELFB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BEPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BETZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BF-A (312 rows, 100% coverage)
  ‚úÖ Cache hit for BF-B (312 rows, 100% coverage)
  ‚úÖ Cache hit for BFAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for BFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BFEB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BFH (312 rows, 100% coverage)
  ‚úÖ Cache hit for BFIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BFLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BFOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for BFST (312 rows, 100% coverage)
  ‚úÖ Cache hit for BG (312 rows, 100% coverage)
  ‚úÖ Cache hit for BGC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BGLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for BGM (312 rows, 100% coverage)
  ‚úÖ Cache hit for BGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BGRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for BHB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BHE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BHF (312 rows, 100% coverage)
  ‚úÖ Cache hit for BHK (312 rows, 100% coverage)
  ‚úÖ Cache hit for BHP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BHRB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BHVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIBL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIDU (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIIB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BILI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BILL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BILS (312 rows, 100% coverage)
  ‚úÖ Cache hit for BILZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BINC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIOA (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIOX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIRD (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIRK (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BITB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BITI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BITO (312 rows, 100% coverage)
  ‚úÖ Cache hit for BITQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BITU (312 rows, 100% coverage)
  ‚úÖ Cache hit for BITX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIVI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BIZD (312 rows, 100% coverage)
  ‚úÖ Cache hit for BJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BJAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BJK (312 rows, 100% coverage)
  ‚úÖ Cache hit for BJRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BJUL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BJUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BK (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKAG (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKCH (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKD (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKF (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKH (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKIE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKNG (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKSE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKSY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKU (312 rows, 100% coverage)
  ‚úÖ Cache hit for BKV (312 rows, 100% coverage)
  ‚úÖ Cache hit for BL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLDP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLDR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLES (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLFY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLK (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLKB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLMN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLND (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLNK (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLOK (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLSH (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLTE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BLZE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for BMAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BMAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BMBL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BMEA (312 rows, 100% coverage)
  ‚úÖ Cache hit for BMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BMNR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for BMRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BMRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BMY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BND (312 rows, 100% coverage)
  ‚úÖ Cache hit for BNDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BNDW (312 rows, 100% coverage)
  ‚úÖ Cache hit for BNDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BNED (312 rows, 100% coverage)
  ‚úÖ Cache hit for BNL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BNO (312 rows, 100% coverage)
  ‚úÖ Cache hit for BNOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for BNS (312 rows, 100% coverage)
  ‚úÖ Cache hit for BNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BNTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOH (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOIL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOKF (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOND (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BORR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOTZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BOXX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BPOP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BPYPN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BPYPO (312 rows, 100% coverage)
  ‚úÖ Cache hit for BPYPP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRF (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRK-B (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRKR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRNS (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRNY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for BROS (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRRR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRSP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRW (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRZE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BRZU (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSCQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSCR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSCS (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSCU (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSCV (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSCX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSET (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSJQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSJR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSJS (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSRR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BST (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSV (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BSY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BTAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BTAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BTBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BTCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for BTCW (312 rows, 100% coverage)
  ‚úÖ Cache hit for BTDR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BTE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BTF (312 rows, 100% coverage)
  ‚úÖ Cache hit for BTG (312 rows, 100% coverage)
  ‚úÖ Cache hit for BTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BTSG (312 rows, 100% coverage)
  ‚úÖ Cache hit for BTU (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUCK (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUD (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUFB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUFD (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUFF (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUFR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUFT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUFZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for BULZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUR (312 rows, 100% coverage)
  ‚úÖ Cache hit for BURL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUSE (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUXX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BUYZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BV (312 rows, 100% coverage)
  ‚úÖ Cache hit for BVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BVS (312 rows, 100% coverage)
  ‚úÖ Cache hit for BW (312 rows, 100% coverage)
  ‚úÖ Cache hit for BWA (312 rows, 100% coverage)
  ‚úÖ Cache hit for BWB (312 rows, 100% coverage)
  ‚úÖ Cache hit for BWIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BWLP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BWMN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BWMX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BWX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BWXT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BWZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BX (312 rows, 100% coverage)
  ‚úÖ Cache hit for BXC (312 rows, 100% coverage)
  ‚úÖ Cache hit for BXMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for BXP (312 rows, 100% coverage)
  ‚úÖ Cache hit for BXSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for BY (312 rows, 100% coverage)
  ‚úÖ Cache hit for BYD (312 rows, 100% coverage)
  ‚úÖ Cache hit for BYLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for BYND (312 rows, 100% coverage)
  ‚úÖ Cache hit for BYRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for BZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for BZAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for BZH (312 rows, 100% coverage)
  ‚úÖ Cache hit for BZUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for C (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAAP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CABO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CACC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CACI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CADE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CADL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAH (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAKE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CALF (312 rows, 100% coverage)
  ‚úÖ Cache hit for CALM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CALX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAML (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CANE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CANG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAPE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAPL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CARE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CARG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CARR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CARS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CART (312 rows, 100% coverage)
  ‚úÖ Cache hit for CARY (312 rows, 100% coverage)
  ‚úÖ Cache hit for CARZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for CASH (312 rows, 100% coverage)
  ‚úÖ Cache hit for CASS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CASY (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CATH (312 rows, 100% coverage)
  ‚úÖ Cache hit for CATO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CATY (312 rows, 100% coverage)
  ‚úÖ Cache hit for CAVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CBL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CBLL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CBNK (312 rows, 100% coverage)
  ‚úÖ Cache hit for CBOE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CBON (312 rows, 100% coverage)
  ‚úÖ Cache hit for CBRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CBRL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CBSH (312 rows, 100% coverage)
  ‚úÖ Cache hit for CBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CBU (312 rows, 100% coverage)
  ‚úÖ Cache hit for CBZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for CC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCAP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCBG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCK (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCNE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCOI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CCU (312 rows, 100% coverage)
  ‚úÖ Cache hit for CD (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDLR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDNS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDW (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDXS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CDZI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CECO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CEFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CEG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CELC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CELH (312 rows, 100% coverage)
  ‚úÖ Cache hit for CEMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CENN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CENT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CENTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CENX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CEPU (312 rows, 100% coverage)
  ‚úÖ Cache hit for CERS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CERT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CEVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CF (312 rows, 100% coverage)
  ‚úÖ Cache hit for CFA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CFFN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CFLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CFO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CFR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGAU (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGBL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGCP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGDV (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGIE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGNX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGON (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGW (312 rows, 100% coverage)
  ‚úÖ Cache hit for CGXU (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHD (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHDN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHEF (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHGG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHH (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHIQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHKP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHRD (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHRW (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHWY (312 rows, 100% coverage)
  ‚úÖ Cache hit for CHYM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CIB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CIBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CIEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CIFR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CIGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CII (312 rows, 100% coverage)
  ‚úÖ Cache hit for CIM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CINF (312 rows, 100% coverage)
  ‚úÖ Cache hit for CING (312 rows, 100% coverage)
  ‚úÖ Cache hit for CINT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CION (312 rows, 100% coverage)
  ‚úÖ Cache hit for CIVB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CIVI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLDT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLF (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLFD (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLH (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLNE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLOA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLOI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLOU (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLOZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLSK (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLVT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLW (312 rows, 100% coverage)
  ‚úÖ Cache hit for CLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMBM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMCM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMCSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMDT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMDY (312 rows, 100% coverage)
  ‚úÖ Cache hit for CME (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMF (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMND (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMPO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMPS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMSD (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMTG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CMTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNCK (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNDT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNET (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNH (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNK (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNNE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNOB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNXC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNXN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNXT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CNYA (312 rows, 100% coverage)
  ‚úÖ Cache hit for COCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CODI (312 rows, 100% coverage)
  ‚úÖ Cache hit for COE (312 rows, 100% coverage)
  ‚úÖ Cache hit for COF (312 rows, 100% coverage)
  ‚úÖ Cache hit for COFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for COGT (312 rows, 100% coverage)
  ‚úÖ Cache hit for COHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for COHU (312 rows, 100% coverage)
  ‚úÖ Cache hit for COIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for COKE (312 rows, 100% coverage)
  ‚úÖ Cache hit for COLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for COLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for COLL (312 rows, 100% coverage)
  ‚úÖ Cache hit for COLM (312 rows, 100% coverage)
  ‚úÖ Cache hit for COLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for COM (312 rows, 100% coverage)
  ‚úÖ Cache hit for COMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for COMM (312 rows, 100% coverage)
  ‚úÖ Cache hit for COMP (312 rows, 100% coverage)
  ‚úÖ Cache hit for COMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CON (312 rows, 100% coverage)
  ‚úÖ Cache hit for CONL (312 rows, 100% coverage)
  ‚úÖ Cache hit for COO (312 rows, 100% coverage)
  ‚úÖ Cache hit for COOK (312 rows, 100% coverage)
  ‚úÖ Cache hit for COP (312 rows, 100% coverage)
  ‚úÖ Cache hit for COPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for COR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CORN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CORP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CORT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CORZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for COSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for COST (312 rows, 100% coverage)
  ‚úÖ Cache hit for COTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for COUR (312 rows, 100% coverage)
  ‚úÖ Cache hit for COWG (312 rows, 100% coverage)
  ‚úÖ Cache hit for COWZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for CP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPER (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPF (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPK (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPNG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CQP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CQQQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for CR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRBG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRBN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRBP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRBU (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRCL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRD-A (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRDO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CREX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRGY (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRH (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRK (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRML (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRNX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRON (312 rows, 100% coverage)
  ‚úÖ Cache hit for CROX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRSP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRSR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRTO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRVL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRVO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRVS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRWD (312 rows, 100% coverage)
  ‚úÖ Cache hit for CRWV (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSGP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSIQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSTE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSV (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSW (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSWC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CSX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTAS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTKB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTLP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTMX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTSH (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CTXR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CUB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CUBE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CUBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CUE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CUK (312 rows, 100% coverage)
  ‚úÖ Cache hit for CULP (312 rows, 100% coverage)
  ‚úÖ Cache hit for CURB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CURE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CURV (312 rows, 100% coverage)
  ‚úÖ Cache hit for CUT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CUZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVBF (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVEO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVGW (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVIE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVLG (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CVY (312 rows, 100% coverage)
  ‚úÖ Cache hit for CW (312 rows, 100% coverage)
  ‚úÖ Cache hit for CWAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CWB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CWBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CWCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for CWEB (312 rows, 100% coverage)
  ‚úÖ Cache hit for CWEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for CWH (312 rows, 100% coverage)
  ‚úÖ Cache hit for CWI (312 rows, 100% coverage)
  ‚úÖ Cache hit for CWK (312 rows, 100% coverage)
  ‚úÖ Cache hit for CWS (312 rows, 100% coverage)
  ‚úÖ Cache hit for CWST (312 rows, 100% coverage)
  ‚úÖ Cache hit for CWT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CXM (312 rows, 100% coverage)
  ‚úÖ Cache hit for CXSE (312 rows, 100% coverage)
  ‚úÖ Cache hit for CXT (312 rows, 100% coverage)
  ‚úÖ Cache hit for CXW (312 rows, 100% coverage)
  ‚úÖ Cache hit for CYBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for CYD (312 rows, 100% coverage)
  ‚úÖ Cache hit for CYH (312 rows, 100% coverage)
  ‚úÖ Cache hit for CYRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for CYTK (312 rows, 100% coverage)
  ‚úÖ Cache hit for CZA (312 rows, 100% coverage)
  ‚úÖ Cache hit for CZNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for CZR (312 rows, 100% coverage)
  ‚úÖ Cache hit for D (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAKT (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DALI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAPP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for DASH (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAVE (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAWN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for DB (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBA (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBAW (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBB (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBE (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBEF (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBEU (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBJP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBMF (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBND (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for DBX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DCBO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DCGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DCOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for DCOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for DCTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for DD (312 rows, 100% coverage)
  ‚úÖ Cache hit for DDD (312 rows, 100% coverage)
  ‚úÖ Cache hit for DDEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for DDI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DDIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for DDL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DDLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DDM (312 rows, 100% coverage)
  ‚úÖ Cache hit for DDOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for DDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DDWM (312 rows, 100% coverage)
  ‚úÖ Cache hit for DE (312 rows, 100% coverage)
  ‚úÖ Cache hit for DEA (312 rows, 100% coverage)
  ‚úÖ Cache hit for DEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for DECK (312 rows, 100% coverage)
  ‚úÖ Cache hit for DEED (312 rows, 100% coverage)
  ‚úÖ Cache hit for DEFI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DEHP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DEI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DELL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for DENN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DEO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DES (312 rows, 100% coverage)
  ‚úÖ Cache hit for DEUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DEW (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFAE (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFAS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFAU (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFCA (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFCF (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFE (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFEB (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFH (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFNL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFSD (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFSE (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFSU (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFSV (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DFVX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DG (312 rows, 100% coverage)
  ‚úÖ Cache hit for DGICA (312 rows, 100% coverage)
  ‚úÖ Cache hit for DGII (312 rows, 100% coverage)
  ‚úÖ Cache hit for DGP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DGRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for DGRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DGRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DGRW (312 rows, 100% coverage)
  ‚úÖ Cache hit for DGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DGT (312 rows, 100% coverage)
  ‚úÖ Cache hit for DGX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DH (312 rows, 100% coverage)
  ‚úÖ Cache hit for DHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for DHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DHIL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for DHS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DHT (312 rows, 100% coverage)
  ‚úÖ Cache hit for DIA (312 rows, 100% coverage)
  ‚úÖ Cache hit for DIAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for DIM (312 rows, 100% coverage)
  ‚úÖ Cache hit for DIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DINO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DINT (312 rows, 100% coverage)
  ‚úÖ Cache hit for DIOD (312 rows, 100% coverage)
  ‚úÖ Cache hit for DIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DISV (312 rows, 100% coverage)
  ‚úÖ Cache hit for DIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for DIVB (312 rows, 100% coverage)
  ‚úÖ Cache hit for DIVI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DIVO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DIVZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for DJAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DJCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DJD (312 rows, 100% coverage)
  ‚úÖ Cache hit for DJP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DJT (312 rows, 100% coverage)
  ‚úÖ Cache hit for DJTWW (312 rows, 100% coverage)
  ‚úÖ Cache hit for DJUL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DJUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DK (312 rows, 100% coverage)
  ‚úÖ Cache hit for DKL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DKNG (312 rows, 100% coverage)
  ‚úÖ Cache hit for DKS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for DLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DLR (312 rows, 100% coverage)
  ‚úÖ Cache hit for DLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DLTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for DLTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for DLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DMAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for DMAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for DMBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DMLP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DMRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for DMXF (312 rows, 100% coverage)
  ‚úÖ Cache hit for DNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for DNL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DNLI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DNN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DNOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for DNOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for DNTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for DNUT (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOC (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOCN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOCS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOCU (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOGZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOLE (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DON (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DORM (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DOYU (312 rows, 100% coverage)
  ‚úÖ Cache hit for DPRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DPST (312 rows, 100% coverage)
  ‚úÖ Cache hit for DPZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for DQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRD (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRH (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRLL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRSK (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRUP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DRVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DSEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DSGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DSGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for DSGX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for DSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for DSP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DSTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DSX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DT (312 rows, 100% coverage)
  ‚úÖ Cache hit for DTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for DTCR (312 rows, 100% coverage)
  ‚úÖ Cache hit for DTD (312 rows, 100% coverage)
  ‚úÖ Cache hit for DTE (312 rows, 100% coverage)
  ‚úÖ Cache hit for DTEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for DTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for DTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for DTRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for DTST (312 rows, 100% coverage)
  ‚úÖ Cache hit for DTW (312 rows, 100% coverage)
  ‚úÖ Cache hit for DUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for DUHP (312 rows, 100% coverage)
  ‚úÖ Cache hit for DUK (312 rows, 100% coverage)
  ‚úÖ Cache hit for DUKB (312 rows, 100% coverage)
  ‚úÖ Cache hit for DUO (312 rows, 100% coverage)
  ‚úÖ Cache hit for DUOL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DURA (312 rows, 100% coverage)
  ‚úÖ Cache hit for DUSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for DV (312 rows, 100% coverage)
  ‚úÖ Cache hit for DVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for DVAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DVOL (312 rows, 100% coverage)
  ‚úÖ Cache hit for DVY (312 rows, 100% coverage)
  ‚úÖ Cache hit for DVYE (312 rows, 100% coverage)
  ‚úÖ Cache hit for DWAS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DWAW (312 rows, 100% coverage)
  ‚úÖ Cache hit for DWLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for DWM (312 rows, 100% coverage)
  ‚úÖ Cache hit for DWSH (312 rows, 100% coverage)
  ‚úÖ Cache hit for DWTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DWUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for DWX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DX (312 rows, 100% coverage)
  ‚úÖ Cache hit for DXC (312 rows, 100% coverage)
  ‚úÖ Cache hit for DXCM (312 rows, 100% coverage)
  ‚úÖ Cache hit for DXD (312 rows, 100% coverage)
  ‚úÖ Cache hit for DXJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for DXLG (312 rows, 100% coverage)
  ‚úÖ Cache hit for DXPE (312 rows, 100% coverage)
  ‚úÖ Cache hit for DY (312 rows, 100% coverage)
  ‚úÖ Cache hit for DYN (312 rows, 100% coverage)
  ‚úÖ Cache hit for DYNF (312 rows, 100% coverage)
  ‚úÖ Cache hit for E (312 rows, 100% coverage)
  ‚úÖ Cache hit for EA (312 rows, 100% coverage)
  ‚úÖ Cache hit for EAF (312 rows, 100% coverage)
  ‚úÖ Cache hit for EAGG (312 rows, 100% coverage)
  ‚úÖ Cache hit for EAGL (312 rows, 100% coverage)
  ‚úÖ Cache hit for EAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for EB (312 rows, 100% coverage)
  ‚úÖ Cache hit for EBAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for EBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EBF (312 rows, 100% coverage)
  ‚úÖ Cache hit for EBIZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for EBND (312 rows, 100% coverage)
  ‚úÖ Cache hit for EBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for EC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ECG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ECH (312 rows, 100% coverage)
  ‚úÖ Cache hit for ECL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ECNS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ECO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ECON (312 rows, 100% coverage)
  ‚úÖ Cache hit for ECOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for ECPG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ECVT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ECX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ED (312 rows, 100% coverage)
  ‚úÖ Cache hit for EDAP (312 rows, 100% coverage)
  ‚úÖ Cache hit for EDEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for EDIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for EDIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for EDN (312 rows, 100% coverage)
  ‚úÖ Cache hit for EDOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for EDU (312 rows, 100% coverage)
  ‚úÖ Cache hit for EDV (312 rows, 100% coverage)
  ‚úÖ Cache hit for EE (312 rows, 100% coverage)
  ‚úÖ Cache hit for EEFT (312 rows, 100% coverage)
  ‚úÖ Cache hit for EELV (312 rows, 100% coverage)
  ‚úÖ Cache hit for EEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for EEMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for EEMS (312 rows, 100% coverage)
  ‚úÖ Cache hit for EEMV (312 rows, 100% coverage)
  ‚úÖ Cache hit for EEMX (312 rows, 100% coverage)
  ‚úÖ Cache hit for EES (312 rows, 100% coverage)
  ‚úÖ Cache hit for EET (312 rows, 100% coverage)
  ‚úÖ Cache hit for EETH (312 rows, 100% coverage)
  ‚úÖ Cache hit for EEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFA (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFAD (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFAV (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFNL (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFO (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFV (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFX (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFXT (312 rows, 100% coverage)
  ‚úÖ Cache hit for EFZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for EG (312 rows, 100% coverage)
  ‚úÖ Cache hit for EGAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for EGBN (312 rows, 100% coverage)
  ‚úÖ Cache hit for EGHT (312 rows, 100% coverage)
  ‚úÖ Cache hit for EGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for EGP (312 rows, 100% coverage)
  ‚úÖ Cache hit for EGY (312 rows, 100% coverage)
  ‚úÖ Cache hit for EH (312 rows, 100% coverage)
  ‚úÖ Cache hit for EHAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for EHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EHTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for EIDO (312 rows, 100% coverage)
  ‚úÖ Cache hit for EIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for EINC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EIPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for EIRL (312 rows, 100% coverage)
  ‚úÖ Cache hit for EIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for EIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for EJAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for EL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ELAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ELCV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ELD (312 rows, 100% coverage)
  ‚úÖ Cache hit for ELF (312 rows, 100% coverage)
  ‚úÖ Cache hit for ELME (312 rows, 100% coverage)
  ‚úÖ Cache hit for ELPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ELS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ELV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ELVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMBJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for EME (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMGF (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMLP (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMN (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMPD (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMQQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMR (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMXC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EMXF (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENFR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENPH (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENSG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENTG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENVB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENVX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ENZL (312 rows, 100% coverage)
  ‚úÖ Cache hit for EOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for EOLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for EOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for EOSE (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPD (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPHE (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPM (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPOL (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPP (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPRF (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPS (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPU (312 rows, 100% coverage)
  ‚úÖ Cache hit for EPV (312 rows, 100% coverage)
  ‚úÖ Cache hit for EQAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for EQBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for EQH (312 rows, 100% coverage)
  ‚úÖ Cache hit for EQIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for EQL (312 rows, 100% coverage)
  ‚úÖ Cache hit for EQNR (312 rows, 100% coverage)
  ‚úÖ Cache hit for EQR (312 rows, 100% coverage)
  ‚úÖ Cache hit for EQRR (312 rows, 100% coverage)
  ‚úÖ Cache hit for EQT (312 rows, 100% coverage)
  ‚úÖ Cache hit for EQWL (312 rows, 100% coverage)
  ‚úÖ Cache hit for EQX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ERAS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ERIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ERIE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ERII (312 rows, 100% coverage)
  ‚úÖ Cache hit for ERO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ERTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for ERX (312 rows, 100% coverage)
  ‚úÖ Cache hit for ERY (312 rows, 100% coverage)
  ‚úÖ Cache hit for ES (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESGD (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESGG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESGU (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESGV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESML (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESPO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ESTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ET (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETD (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETH (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETHA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETHE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETHO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETHU (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETHV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETHW (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETHZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETON (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ETSY (312 rows, 100% coverage)
  ‚úÖ Cache hit for EU (312 rows, 100% coverage)
  ‚úÖ Cache hit for EUDG (312 rows, 100% coverage)
  ‚úÖ Cache hit for EUFN (312 rows, 100% coverage)
  ‚úÖ Cache hit for EUHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for EUM (312 rows, 100% coverage)
  ‚úÖ Cache hit for EUSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for EUSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVCM (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVER (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVH (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVO (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVR (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVV (312 rows, 100% coverage)
  ‚úÖ Cache hit for EVX (312 rows, 100% coverage)
  ‚úÖ Cache hit for EW (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWA (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWCZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWD (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWG (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWH (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWI (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWJV (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWK (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWL (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWM (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWN (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWO (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWP (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWS (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWT (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWU (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWW (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWX (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWY (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for EWZS (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXAS (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXE (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXFY (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXK (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXP (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXPD (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXPE (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXPO (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXR (312 rows, 100% coverage)
  ‚úÖ Cache hit for EXTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for EYE (312 rows, 100% coverage)
  ‚úÖ Cache hit for EYLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for EYPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for EZA (312 rows, 100% coverage)
  ‚úÖ Cache hit for EZBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for EZET (312 rows, 100% coverage)
  ‚úÖ Cache hit for EZJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for EZM (312 rows, 100% coverage)
  ‚úÖ Cache hit for EZPW (312 rows, 100% coverage)
  ‚úÖ Cache hit for EZU (312 rows, 100% coverage)
  ‚úÖ Cache hit for F (312 rows, 100% coverage)
  ‚úÖ Cache hit for FA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FAAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FAD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FAF (312 rows, 100% coverage)
  ‚úÖ Cache hit for FALN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FANG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FAPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FARM (312 rows, 100% coverage)
  ‚úÖ Cache hit for FAS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FAST (312 rows, 100% coverage)
  ‚úÖ Cache hit for FATE (312 rows, 100% coverage)
  ‚úÖ Cache hit for FAUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FAZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBCG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBCV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBIZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBND (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBP (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FBY (312 rows, 100% coverage)
  ‚úÖ Cache hit for FC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCF (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCNCA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCVT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FCX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDM (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDNI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDP (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDRR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDVV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FE (312 rows, 100% coverage)
  ‚úÖ Cache hit for FEDU (312 rows, 100% coverage)
  ‚úÖ Cache hit for FELE (312 rows, 100% coverage)
  ‚úÖ Cache hit for FEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for FEMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FEMS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FEMY (312 rows, 100% coverage)
  ‚úÖ Cache hit for FENG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FENY (312 rows, 100% coverage)
  ‚úÖ Cache hit for FEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for FEPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FER (312 rows, 100% coverage)
  ‚úÖ Cache hit for FERG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FET (312 rows, 100% coverage)
  ‚úÖ Cache hit for FETH (312 rows, 100% coverage)
  ‚úÖ Cache hit for FEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FEZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for FFAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FFBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FFEB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FFIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FFIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FFIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FFLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FFLG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FFTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for FFWM (312 rows, 100% coverage)
  ‚úÖ Cache hit for FG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FGD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FGM (312 rows, 100% coverage)
  ‚úÖ Cache hit for FHB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FHLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FHN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FHTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for FICO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FICS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FID (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIDI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIDU (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIHL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FINV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FINX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FISI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FISR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FISV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FITB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FITBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FITBO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FITBP (312 rows, 100% coverage)
  ‚úÖ Cache hit for FITE (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIVE (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIW (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIXD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FIZZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for FJAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FJP (312 rows, 100% coverage)
  ‚úÖ Cache hit for FJUL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FJUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLBL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLCA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLCH (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLDB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLDR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLEE (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLGB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLGC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLGT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLGV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLIA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLJP (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLKR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLNG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLOC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLQL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLQM (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLSP (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLTW (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLUT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLUX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLWS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FLYW (312 rows, 100% coverage)
  ‚úÖ Cache hit for FMAG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FMAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FMAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FMBH (312 rows, 100% coverage)
  ‚úÖ Cache hit for FMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FMF (312 rows, 100% coverage)
  ‚úÖ Cache hit for FMHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FMNB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FMS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FMST (312 rows, 100% coverage)
  ‚úÖ Cache hit for FMX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNCL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FND (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNDA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNDB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNDE (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNDF (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNF (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNGD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNGU (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNK (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNKO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FNY (312 rows, 100% coverage)
  ‚úÖ Cache hit for FOA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FOCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FOLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FORA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FORM (312 rows, 100% coverage)
  ‚úÖ Cache hit for FORR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FOSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FOUR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FOX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FOXA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FOXF (312 rows, 100% coverage)
  ‚úÖ Cache hit for FPE (312 rows, 100% coverage)
  ‚úÖ Cache hit for FPEI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FPH (312 rows, 100% coverage)
  ‚úÖ Cache hit for FPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for FPXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FQAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRBA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRDM (312 rows, 100% coverage)
  ‚úÖ Cache hit for FREL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRGT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRME (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRNW (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FROG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRPH (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRSH (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRST (312 rows, 100% coverage)
  ‚úÖ Cache hit for FRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSK (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSLR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSP (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FSZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTCS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTDR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTGC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTQI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTSD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTW (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTXL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTXN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTXO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FTXR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FUBO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FUFU (312 rows, 100% coverage)
  ‚úÖ Cache hit for FUL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FULC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FULT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FUNL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FUTU (312 rows, 100% coverage)
  ‚úÖ Cache hit for FUTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for FV (312 rows, 100% coverage)
  ‚úÖ Cache hit for FVAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FVC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FVD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FVRR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FWD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FWONA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FWONK (312 rows, 100% coverage)
  ‚úÖ Cache hit for FWRD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FWRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXA (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXB (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXE (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXF (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXG (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXH (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXL (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXN (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXO (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXU (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXY (312 rows, 100% coverage)
  ‚úÖ Cache hit for FXZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for FYBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for FYC (312 rows, 100% coverage)
  ‚úÖ Cache hit for FYLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for FYT (312 rows, 100% coverage)
  ‚úÖ Cache hit for FYX (312 rows, 100% coverage)
  ‚úÖ Cache hit for G (312 rows, 100% coverage)
  ‚úÖ Cache hit for GABC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GAIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for GAMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for GAP (312 rows, 100% coverage)
  ‚úÖ Cache hit for GAPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for GARP (312 rows, 100% coverage)
  ‚úÖ Cache hit for GASS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GATX (312 rows, 100% coverage)
  ‚úÖ Cache hit for GBCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for GBDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GBF (312 rows, 100% coverage)
  ‚úÖ Cache hit for GBIL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GBIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for GBTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GBTG (312 rows, 100% coverage)
  ‚úÖ Cache hit for GBX (312 rows, 100% coverage)
  ‚úÖ Cache hit for GCBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GCMG (312 rows, 100% coverage)
  ‚úÖ Cache hit for GCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for GCOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for GCOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for GCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for GD (312 rows, 100% coverage)
  ‚úÖ Cache hit for GDDY (312 rows, 100% coverage)
  ‚úÖ Cache hit for GDEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GDEV (312 rows, 100% coverage)
  ‚úÖ Cache hit for GDOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for GDRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for GDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for GDXD (312 rows, 100% coverage)
  ‚úÖ Cache hit for GDXJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for GDXU (312 rows, 100% coverage)
  ‚úÖ Cache hit for GDYN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GE (312 rows, 100% coverage)
  ‚úÖ Cache hit for GEF (312 rows, 100% coverage)
  ‚úÖ Cache hit for GEHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for GEMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for GEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GENI (312 rows, 100% coverage)
  ‚úÖ Cache hit for GEO (312 rows, 100% coverage)
  ‚úÖ Cache hit for GEOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GERN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GES (312 rows, 100% coverage)
  ‚úÖ Cache hit for GETY (312 rows, 100% coverage)
  ‚úÖ Cache hit for GEV (312 rows, 100% coverage)
  ‚úÖ Cache hit for GEVO (312 rows, 100% coverage)
  ‚úÖ Cache hit for GFEB (312 rows, 100% coverage)
  ‚úÖ Cache hit for GFF (312 rows, 100% coverage)
  ‚úÖ Cache hit for GFI (312 rows, 100% coverage)
  ‚úÖ Cache hit for GFL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GFR (312 rows, 100% coverage)
  ‚úÖ Cache hit for GFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GGAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GGB (312 rows, 100% coverage)
  ‚úÖ Cache hit for GGG (312 rows, 100% coverage)
  ‚úÖ Cache hit for GGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for GH (312 rows, 100% coverage)
  ‚úÖ Cache hit for GHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GHG (312 rows, 100% coverage)
  ‚úÖ Cache hit for GHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for GHM (312 rows, 100% coverage)
  ‚úÖ Cache hit for GHRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GHYB (312 rows, 100% coverage)
  ‚úÖ Cache hit for GHYG (312 rows, 100% coverage)
  ‚úÖ Cache hit for GIAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for GIB (312 rows, 100% coverage)
  ‚úÖ Cache hit for GIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for GIGB (312 rows, 100% coverage)
  ‚úÖ Cache hit for GII (312 rows, 100% coverage)
  ‚úÖ Cache hit for GIII (312 rows, 100% coverage)
  ‚úÖ Cache hit for GIL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GILD (312 rows, 100% coverage)
  ‚úÖ Cache hit for GILT (312 rows, 100% coverage)
  ‚úÖ Cache hit for GINN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GJAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GJUL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GJUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GKOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLAD (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLBE (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLDD (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLDI (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLDM (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLNG (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLOB (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLOF (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLP (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLPG (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLUE (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLW (312 rows, 100% coverage)
  ‚úÖ Cache hit for GLXY (312 rows, 100% coverage)
  ‚úÖ Cache hit for GM (312 rows, 100% coverage)
  ‚úÖ Cache hit for GMAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for GMAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for GMAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for GME (312 rows, 100% coverage)
  ‚úÖ Cache hit for GMED (312 rows, 100% coverage)
  ‚úÖ Cache hit for GMF (312 rows, 100% coverage)
  ‚úÖ Cache hit for GMOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for GMRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for GNE (312 rows, 100% coverage)
  ‚úÖ Cache hit for GNK (312 rows, 100% coverage)
  ‚úÖ Cache hit for GNL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GNLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GNMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for GNOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for GNR (312 rows, 100% coverage)
  ‚úÖ Cache hit for GNRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GNTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for GNW (312 rows, 100% coverage)
  ‚úÖ Cache hit for GO (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOAU (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOLF (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOOD (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOOGL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOTU (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOVI (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOVT (312 rows, 100% coverage)
  ‚úÖ Cache hit for GOVZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for GP (312 rows, 100% coverage)
  ‚úÖ Cache hit for GPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for GPIQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for GPIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for GPK (312 rows, 100% coverage)
  ‚úÖ Cache hit for GPMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for GPN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GPOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for GPRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for GPRK (312 rows, 100% coverage)
  ‚úÖ Cache hit for GPRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for GPTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for GQI (312 rows, 100% coverage)
  ‚úÖ Cache hit for GQRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRDN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GREK (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRID (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRMN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRNB (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRND (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRNQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRPM (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRPN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRRR (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRVY (312 rows, 100% coverage)
  ‚úÖ Cache hit for GRWG (312 rows, 100% coverage)
  ‚úÖ Cache hit for GS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSEE (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSEW (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSG (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSHD (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSID (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSIE (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSK (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSST (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GSY (312 rows, 100% coverage)
  ‚úÖ Cache hit for GT (312 rows, 100% coverage)
  ‚úÖ Cache hit for GTBP (312 rows, 100% coverage)
  ‚úÖ Cache hit for GTEK (312 rows, 100% coverage)
  ‚úÖ Cache hit for GTES (312 rows, 100% coverage)
  ‚úÖ Cache hit for GTIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for GTLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for GTLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for GTN (312 rows, 100% coverage)
  ‚úÖ Cache hit for GTO (312 rows, 100% coverage)
  ‚úÖ Cache hit for GTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for GTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for GUNR (312 rows, 100% coverage)
  ‚úÖ Cache hit for GURU (312 rows, 100% coverage)
  ‚úÖ Cache hit for GUSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for GUSH (312 rows, 100% coverage)
  ‚úÖ Cache hit for GVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for GVAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for GVI (312 rows, 100% coverage)
  ‚úÖ Cache hit for GVIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for GWH (312 rows, 100% coverage)
  ‚úÖ Cache hit for GWRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for GWRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GWW (312 rows, 100% coverage)
  ‚úÖ Cache hit for GWX (312 rows, 100% coverage)
  ‚úÖ Cache hit for GXC (312 rows, 100% coverage)
  ‚úÖ Cache hit for GXDW (312 rows, 100% coverage)
  ‚úÖ Cache hit for GXO (312 rows, 100% coverage)
  ‚úÖ Cache hit for GXUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for GYRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for H (312 rows, 100% coverage)
  ‚úÖ Cache hit for HACK (312 rows, 100% coverage)
  ‚úÖ Cache hit for HAE (312 rows, 100% coverage)
  ‚úÖ Cache hit for HAFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for HAFN (312 rows, 100% coverage)
  ‚úÖ Cache hit for HAIL (312 rows, 100% coverage)
  ‚úÖ Cache hit for HAIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for HAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for HALO (312 rows, 100% coverage)
  ‚úÖ Cache hit for HAP (312 rows, 100% coverage)
  ‚úÖ Cache hit for HAPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for HAS (312 rows, 100% coverage)
  ‚úÖ Cache hit for HASI (312 rows, 100% coverage)
  ‚úÖ Cache hit for HAUZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for HAWX (312 rows, 100% coverage)
  ‚úÖ Cache hit for HAYW (312 rows, 100% coverage)
  ‚úÖ Cache hit for HBAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for HBIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for HBM (312 rows, 100% coverage)
  ‚úÖ Cache hit for HBNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for HBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HCA (312 rows, 100% coverage)
  ‚úÖ Cache hit for HCAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for HCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for HCKT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HCM (312 rows, 100% coverage)
  ‚úÖ Cache hit for HCRB (312 rows, 100% coverage)
  ‚úÖ Cache hit for HCSG (312 rows, 100% coverage)
  ‚úÖ Cache hit for HD (312 rows, 100% coverage)
  ‚úÖ Cache hit for HDB (312 rows, 100% coverage)
  ‚úÖ Cache hit for HDEF (312 rows, 100% coverage)
  ‚úÖ Cache hit for HDG (312 rows, 100% coverage)
  ‚úÖ Cache hit for HDGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for HDSN (312 rows, 100% coverage)
  ‚úÖ Cache hit for HDUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for HDV (312 rows, 100% coverage)
  ‚úÖ Cache hit for HE (312 rows, 100% coverage)
  ‚úÖ Cache hit for HEAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for HEDJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for HEEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for HEFA (312 rows, 100% coverage)
  ‚úÖ Cache hit for HEGD (312 rows, 100% coverage)
  ‚úÖ Cache hit for HEI (312 rows, 100% coverage)
  ‚úÖ Cache hit for HEI-A (312 rows, 100% coverage)
  ‚úÖ Cache hit for HELE (312 rows, 100% coverage)
  ‚úÖ Cache hit for HELO (312 rows, 100% coverage)
  ‚úÖ Cache hit for HEPS (312 rows, 100% coverage)
  ‚úÖ Cache hit for HEQT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HERO (312 rows, 100% coverage)
  ‚úÖ Cache hit for HESM (312 rows, 100% coverage)
  ‚úÖ Cache hit for HEWJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for HEZU (312 rows, 100% coverage)
  ‚úÖ Cache hit for HFGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for HFWA (312 rows, 100% coverage)
  ‚úÖ Cache hit for HFXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for HG (312 rows, 100% coverage)
  ‚úÖ Cache hit for HGER (312 rows, 100% coverage)
  ‚úÖ Cache hit for HGTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for HGV (312 rows, 100% coverage)
  ‚úÖ Cache hit for HHH (312 rows, 100% coverage)
  ‚úÖ Cache hit for HI (312 rows, 100% coverage)
  ‚úÖ Cache hit for HIBL (312 rows, 100% coverage)
  ‚úÖ Cache hit for HIFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for HIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for HIGH (312 rows, 100% coverage)
  ‚úÖ Cache hit for HII (312 rows, 100% coverage)
  ‚úÖ Cache hit for HIMS (312 rows, 100% coverage)
  ‚úÖ Cache hit for HIMX (312 rows, 100% coverage)
  ‚úÖ Cache hit for HIPO (312 rows, 100% coverage)
  ‚úÖ Cache hit for HIPS (312 rows, 100% coverage)
  ‚úÖ Cache hit for HISF (312 rows, 100% coverage)
  ‚úÖ Cache hit for HIVE (312 rows, 100% coverage)
  ‚úÖ Cache hit for HIW (312 rows, 100% coverage)
  ‚úÖ Cache hit for HKD (312 rows, 100% coverage)
  ‚úÖ Cache hit for HL (312 rows, 100% coverage)
  ‚úÖ Cache hit for HLAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for HLF (312 rows, 100% coverage)
  ‚úÖ Cache hit for HLI (312 rows, 100% coverage)
  ‚úÖ Cache hit for HLIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for HLIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HLLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for HLMN (312 rows, 100% coverage)
  ‚úÖ Cache hit for HLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for HLNE (312 rows, 100% coverage)
  ‚úÖ Cache hit for HLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for HMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for HMN (312 rows, 100% coverage)
  ‚úÖ Cache hit for HMOP (312 rows, 100% coverage)
  ‚úÖ Cache hit for HMY (312 rows, 100% coverage)
  ‚úÖ Cache hit for HNDL (312 rows, 100% coverage)
  ‚úÖ Cache hit for HNI (312 rows, 100% coverage)
  ‚úÖ Cache hit for HNRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for HNST (312 rows, 100% coverage)
  ‚úÖ Cache hit for HODL (312 rows, 100% coverage)
  ‚úÖ Cache hit for HOFT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for HOLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for HOMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for HOMZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for HON (312 rows, 100% coverage)
  ‚úÖ Cache hit for HOOD (312 rows, 100% coverage)
  ‚úÖ Cache hit for HOPE (312 rows, 100% coverage)
  ‚úÖ Cache hit for HOUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for HOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for HOWL (312 rows, 100% coverage)
  ‚úÖ Cache hit for HP (312 rows, 100% coverage)
  ‚úÖ Cache hit for HPE (312 rows, 100% coverage)
  ‚úÖ Cache hit for HPK (312 rows, 100% coverage)
  ‚úÖ Cache hit for HPP (312 rows, 100% coverage)
  ‚úÖ Cache hit for HPQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for HQH (312 rows, 100% coverage)
  ‚úÖ Cache hit for HQY (312 rows, 100% coverage)
  ‚úÖ Cache hit for HR (312 rows, 100% coverage)
  ‚úÖ Cache hit for HRB (312 rows, 100% coverage)
  ‚úÖ Cache hit for HRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for HRL (312 rows, 100% coverage)
  ‚úÖ Cache hit for HRMY (312 rows, 100% coverage)
  ‚úÖ Cache hit for HROW (312 rows, 100% coverage)
  ‚úÖ Cache hit for HRTG (312 rows, 100% coverage)
  ‚úÖ Cache hit for HRTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for HRZN (312 rows, 100% coverage)
  ‚úÖ Cache hit for HSAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for HSBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for HSCZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for HSDT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HSIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for HST (312 rows, 100% coverage)
  ‚úÖ Cache hit for HSTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for HSY (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTD (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTGC (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTHT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTO (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTOO (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTRB (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HTZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for HUBB (312 rows, 100% coverage)
  ‚úÖ Cache hit for HUBG (312 rows, 100% coverage)
  ‚úÖ Cache hit for HUBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for HUM (312 rows, 100% coverage)
  ‚úÖ Cache hit for HUMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for HUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for HURN (312 rows, 100% coverage)
  ‚úÖ Cache hit for HUSV (312 rows, 100% coverage)
  ‚úÖ Cache hit for HUT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HUYA (312 rows, 100% coverage)
  ‚úÖ Cache hit for HVT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HWC (312 rows, 100% coverage)
  ‚úÖ Cache hit for HWKN (312 rows, 100% coverage)
  ‚úÖ Cache hit for HWM (312 rows, 100% coverage)
  ‚úÖ Cache hit for HXL (312 rows, 100% coverage)
  ‚úÖ Cache hit for HY (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYBB (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYBL (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYD (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYDB (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYDW (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYG (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYGH (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYGV (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYHG (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYI (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYS (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYT (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYUP (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYXF (312 rows, 100% coverage)
  ‚úÖ Cache hit for HYZD (312 rows, 100% coverage)
  ‚úÖ Cache hit for HZO (312 rows, 100% coverage)
  ‚úÖ Cache hit for IAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for IAG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IAGG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for IAK (312 rows, 100% coverage)
  ‚úÖ Cache hit for IAPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IART (312 rows, 100% coverage)
  ‚úÖ Cache hit for IAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IAU (312 rows, 100% coverage)
  ‚úÖ Cache hit for IAUM (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBB (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBCP (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBDR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBDT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBDU (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBDV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBDW (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBHF (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBHG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBKR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBM (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBMP (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBMQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBN (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBND (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBOC (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBP (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBTK (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for IBUY (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICCM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICE (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICF (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICFI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICLR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICSH (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICUI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ICVT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDA (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDEV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDGT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDHQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDRV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDU (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDUB (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDVO (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDXX (312 rows, 100% coverage)
  ‚úÖ Cache hit for IDYA (312 rows, 100% coverage)
  ‚úÖ Cache hit for IEF (312 rows, 100% coverage)
  ‚úÖ Cache hit for IEFA (312 rows, 100% coverage)
  ‚úÖ Cache hit for IEI (312 rows, 100% coverage)
  ‚úÖ Cache hit for IEMG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IEO (312 rows, 100% coverage)
  ‚úÖ Cache hit for IEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for IESC (312 rows, 100% coverage)
  ‚úÖ Cache hit for IETC (312 rows, 100% coverage)
  ‚úÖ Cache hit for IEUR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IEUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for IEV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for IEZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for IFBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for IFF (312 rows, 100% coverage)
  ‚úÖ Cache hit for IFGL (312 rows, 100% coverage)
  ‚úÖ Cache hit for IFRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for IFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for IFV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGBH (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGEB (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGF (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGHG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGIB (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGM (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IGV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IHAK (312 rows, 100% coverage)
  ‚úÖ Cache hit for IHDG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IHE (312 rows, 100% coverage)
  ‚úÖ Cache hit for IHF (312 rows, 100% coverage)
  ‚úÖ Cache hit for IHG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for IHRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IHS (312 rows, 100% coverage)
  ‚úÖ Cache hit for IHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for IIGD (312 rows, 100% coverage)
  ‚úÖ Cache hit for IIIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for IIIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IIM (312 rows, 100% coverage)
  ‚úÖ Cache hit for IIPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IJAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for IJH (312 rows, 100% coverage)
  ‚úÖ Cache hit for IJJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for IJK (312 rows, 100% coverage)
  ‚úÖ Cache hit for IJR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IJS (312 rows, 100% coverage)
  ‚úÖ Cache hit for IJT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IJUL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ILCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ILCG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ILCV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ILF (312 rows, 100% coverage)
  ‚úÖ Cache hit for ILMN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ILPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ILTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMCG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMCR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMCV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMFL (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMKTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMMR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMNM (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMPP (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMVT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IMXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for INBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for INBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for INBX (312 rows, 100% coverage)
  ‚úÖ Cache hit for INCE (312 rows, 100% coverage)
  ‚úÖ Cache hit for INCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for INCR (312 rows, 100% coverage)
  ‚úÖ Cache hit for INCY (312 rows, 100% coverage)
  ‚úÖ Cache hit for INDA (312 rows, 100% coverage)
  ‚úÖ Cache hit for INDB (312 rows, 100% coverage)
  ‚úÖ Cache hit for INDI (312 rows, 100% coverage)
  ‚úÖ Cache hit for INDO (312 rows, 100% coverage)
  ‚úÖ Cache hit for INDP (312 rows, 100% coverage)
  ‚úÖ Cache hit for INDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for INDV (312 rows, 100% coverage)
  ‚úÖ Cache hit for INDY (312 rows, 100% coverage)
  ‚úÖ Cache hit for INFL (312 rows, 100% coverage)
  ‚úÖ Cache hit for INFU (312 rows, 100% coverage)
  ‚úÖ Cache hit for INFY (312 rows, 100% coverage)
  ‚úÖ Cache hit for ING (312 rows, 100% coverage)
  ‚úÖ Cache hit for INGM (312 rows, 100% coverage)
  ‚úÖ Cache hit for INGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for INGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for INKM (312 rows, 100% coverage)
  ‚úÖ Cache hit for INMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for INN (312 rows, 100% coverage)
  ‚úÖ Cache hit for INNV (312 rows, 100% coverage)
  ‚úÖ Cache hit for INO (312 rows, 100% coverage)
  ‚úÖ Cache hit for INOD (312 rows, 100% coverage)
  ‚úÖ Cache hit for INR (312 rows, 100% coverage)
  ‚úÖ Cache hit for INSG (312 rows, 100% coverage)
  ‚úÖ Cache hit for INSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for INSP (312 rows, 100% coverage)
  ‚úÖ Cache hit for INSW (312 rows, 100% coverage)
  ‚úÖ Cache hit for INTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for INTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for INTF (312 rows, 100% coverage)
  ‚úÖ Cache hit for INTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for INTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for INTU (312 rows, 100% coverage)
  ‚úÖ Cache hit for INV (312 rows, 100% coverage)
  ‚úÖ Cache hit for INVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for INVE (312 rows, 100% coverage)
  ‚úÖ Cache hit for INVH (312 rows, 100% coverage)
  ‚úÖ Cache hit for INVX (312 rows, 100% coverage)
  ‚úÖ Cache hit for INVZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for IONQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for IONS (312 rows, 100% coverage)
  ‚úÖ Cache hit for IOO (312 rows, 100% coverage)
  ‚úÖ Cache hit for IOSP (312 rows, 100% coverage)
  ‚úÖ Cache hit for IOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IOVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for IP (312 rows, 100% coverage)
  ‚úÖ Cache hit for IPAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for IPAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IPAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for IPGP (312 rows, 100% coverage)
  ‚úÖ Cache hit for IPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for IPKW (312 rows, 100% coverage)
  ‚úÖ Cache hit for IPO (312 rows, 100% coverage)
  ‚úÖ Cache hit for IPSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for IPWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for IQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for IQDF (312 rows, 100% coverage)
  ‚úÖ Cache hit for IQDG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IQDY (312 rows, 100% coverage)
  ‚úÖ Cache hit for IQLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IQM (312 rows, 100% coverage)
  ‚úÖ Cache hit for IQSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for IQSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for IQSU (312 rows, 100% coverage)
  ‚úÖ Cache hit for IQV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IRDM (312 rows, 100% coverage)
  ‚úÖ Cache hit for IREN (312 rows, 100% coverage)
  ‚úÖ Cache hit for IRM (312 rows, 100% coverage)
  ‚úÖ Cache hit for IRMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for IRON (312 rows, 100% coverage)
  ‚úÖ Cache hit for IRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for IRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IRTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for IRWD (312 rows, 100% coverage)
  ‚úÖ Cache hit for ISCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ISCF (312 rows, 100% coverage)
  ‚úÖ Cache hit for ISCG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ISCV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ISHG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ISMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for ISPO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ISPY (312 rows, 100% coverage)
  ‚úÖ Cache hit for ISRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ISRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ISTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ISVL (312 rows, 100% coverage)
  ‚úÖ Cache hit for IT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ITA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ITB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ITGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ITOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ITRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ITRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ITT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ITUB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ITW (312 rows, 100% coverage)
  ‚úÖ Cache hit for IUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for IUSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for IUSG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IUSV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for IVAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for IVE (312 rows, 100% coverage)
  ‚úÖ Cache hit for IVLU (312 rows, 100% coverage)
  ‚úÖ Cache hit for IVOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IVOL (312 rows, 100% coverage)
  ‚úÖ Cache hit for IVOO (312 rows, 100% coverage)
  ‚úÖ Cache hit for IVOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IVR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IVV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IVW (312 rows, 100% coverage)
  ‚úÖ Cache hit for IVZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWB (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWC (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWD (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWF (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWL (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWM (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWMY (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWN (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWO (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWP (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWS (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWV (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWX (312 rows, 100% coverage)
  ‚úÖ Cache hit for IWY (312 rows, 100% coverage)
  ‚úÖ Cache hit for IX (312 rows, 100% coverage)
  ‚úÖ Cache hit for IXC (312 rows, 100% coverage)
  ‚úÖ Cache hit for IXG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IXJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for IXN (312 rows, 100% coverage)
  ‚úÖ Cache hit for IXP (312 rows, 100% coverage)
  ‚úÖ Cache hit for IXUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYC (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYE (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYF (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYG (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYH (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYK (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYM (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYR (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYT (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYW (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYY (312 rows, 100% coverage)
  ‚úÖ Cache hit for IYZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for IZRL (312 rows, 100% coverage)
  ‚úÖ Cache hit for J (312 rows, 100% coverage)
  ‚úÖ Cache hit for JAAA (312 rows, 100% coverage)
  ‚úÖ Cache hit for JACK (312 rows, 100% coverage)
  ‚úÖ Cache hit for JAKK (312 rows, 100% coverage)
  ‚úÖ Cache hit for JAMF (312 rows, 100% coverage)
  ‚úÖ Cache hit for JANT (312 rows, 100% coverage)
  ‚úÖ Cache hit for JANW (312 rows, 100% coverage)
  ‚úÖ Cache hit for JANX (312 rows, 100% coverage)
  ‚úÖ Cache hit for JAVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for JAZZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for JBBB (312 rows, 100% coverage)
  ‚úÖ Cache hit for JBGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for JBHT (312 rows, 100% coverage)
  ‚úÖ Cache hit for JBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for JBIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for JBL (312 rows, 100% coverage)
  ‚úÖ Cache hit for JBLU (312 rows, 100% coverage)
  ‚úÖ Cache hit for JBND (312 rows, 100% coverage)
  ‚úÖ Cache hit for JBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for JBSS (312 rows, 100% coverage)
  ‚úÖ Cache hit for JBTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for JCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for JCPB (312 rows, 100% coverage)
  ‚úÖ Cache hit for JCPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for JD (312 rows, 100% coverage)
  ‚úÖ Cache hit for JEF (312 rows, 100% coverage)
  ‚úÖ Cache hit for JELD (312 rows, 100% coverage)
  ‚úÖ Cache hit for JEMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for JEPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for JEPQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for JETS (312 rows, 100% coverage)
  ‚úÖ Cache hit for JFIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for JGLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for JGRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for JHEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for JHG (312 rows, 100% coverage)
  ‚úÖ Cache hit for JHMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for JHML (312 rows, 100% coverage)
  ‚úÖ Cache hit for JHMM (312 rows, 100% coverage)
  ‚úÖ Cache hit for JHSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for JIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for JILL (312 rows, 100% coverage)
  ‚úÖ Cache hit for JIRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for JJSF (312 rows, 100% coverage)
  ‚úÖ Cache hit for JKHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for JKS (312 rows, 100% coverage)
  ‚úÖ Cache hit for JLL (312 rows, 100% coverage)
  ‚úÖ Cache hit for JMBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for JMEE (312 rows, 100% coverage)
  ‚úÖ Cache hit for JMIA (312 rows, 100% coverage)
  ‚úÖ Cache hit for JMOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for JMST (312 rows, 100% coverage)
  ‚úÖ Cache hit for JMUB (312 rows, 100% coverage)
  ‚úÖ Cache hit for JNJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for JNK (312 rows, 100% coverage)
  ‚úÖ Cache hit for JNUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for JOBY (312 rows, 100% coverage)
  ‚úÖ Cache hit for JOE (312 rows, 100% coverage)
  ‚úÖ Cache hit for JOET (312 rows, 100% coverage)
  ‚úÖ Cache hit for JOUT (312 rows, 100% coverage)
  ‚úÖ Cache hit for JOYY (312 rows, 100% coverage)
  ‚úÖ Cache hit for JPEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for JPIB (312 rows, 100% coverage)
  ‚úÖ Cache hit for JPIE (312 rows, 100% coverage)
  ‚úÖ Cache hit for JPIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for JPM (312 rows, 100% coverage)
  ‚úÖ Cache hit for JPMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for JPME (312 rows, 100% coverage)
  ‚úÖ Cache hit for JPRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for JPSE (312 rows, 100% coverage)
  ‚úÖ Cache hit for JPST (312 rows, 100% coverage)
  ‚úÖ Cache hit for JPUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for JQUA (312 rows, 100% coverage)
  ‚úÖ Cache hit for JRVR (312 rows, 100% coverage)
  ‚úÖ Cache hit for JSCP (312 rows, 100% coverage)
  ‚úÖ Cache hit for JSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for JSMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for JSML (312 rows, 100% coverage)
  ‚úÖ Cache hit for JSTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for JTEK (312 rows, 100% coverage)
  ‚úÖ Cache hit for JUCY (312 rows, 100% coverage)
  ‚úÖ Cache hit for JUST (312 rows, 100% coverage)
  ‚úÖ Cache hit for JVAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for JXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for JXN (312 rows, 100% coverage)
  ‚úÖ Cache hit for JYD (312 rows, 100% coverage)
  ‚úÖ Cache hit for JYNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for KAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for KALA (312 rows, 100% coverage)
  ‚úÖ Cache hit for KALU (312 rows, 100% coverage)
  ‚úÖ Cache hit for KALV (312 rows, 100% coverage)
  ‚úÖ Cache hit for KAPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for KARO (312 rows, 100% coverage)
  ‚úÖ Cache hit for KARS (312 rows, 100% coverage)
  ‚úÖ Cache hit for KB (312 rows, 100% coverage)
  ‚úÖ Cache hit for KBA (312 rows, 100% coverage)
  ‚úÖ Cache hit for KBDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for KBE (312 rows, 100% coverage)
  ‚úÖ Cache hit for KBH (312 rows, 100% coverage)
  ‚úÖ Cache hit for KBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for KBWB (312 rows, 100% coverage)
  ‚úÖ Cache hit for KBWD (312 rows, 100% coverage)
  ‚úÖ Cache hit for KBWP (312 rows, 100% coverage)
  ‚úÖ Cache hit for KBWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for KBWY (312 rows, 100% coverage)
  ‚úÖ Cache hit for KC (312 rows, 100% coverage)
  ‚úÖ Cache hit for KCCA (312 rows, 100% coverage)
  ‚úÖ Cache hit for KCE (312 rows, 100% coverage)
  ‚úÖ Cache hit for KD (312 rows, 100% coverage)
  ‚úÖ Cache hit for KDK (312 rows, 100% coverage)
  ‚úÖ Cache hit for KDP (312 rows, 100% coverage)
  ‚úÖ Cache hit for KE (312 rows, 100% coverage)
  ‚úÖ Cache hit for KELYA (312 rows, 100% coverage)
  ‚úÖ Cache hit for KEMQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for KEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for KEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for KEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for KEY (312 rows, 100% coverage)
  ‚úÖ Cache hit for KEYS (312 rows, 100% coverage)
  ‚úÖ Cache hit for KFRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for KFY (312 rows, 100% coverage)
  ‚úÖ Cache hit for KGC (312 rows, 100% coverage)
  ‚úÖ Cache hit for KGRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for KGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for KHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for KIDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for KIE (312 rows, 100% coverage)
  ‚úÖ Cache hit for KIM (312 rows, 100% coverage)
  ‚úÖ Cache hit for KJAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for KJUL (312 rows, 100% coverage)
  ‚úÖ Cache hit for KKR (312 rows, 100% coverage)
  ‚úÖ Cache hit for KLAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for KLAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for KLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for KLIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for KLIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for KLRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for KLTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for KLXE (312 rows, 100% coverage)
  ‚úÖ Cache hit for KMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for KMDA (312 rows, 100% coverage)
  ‚úÖ Cache hit for KMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for KMLM (312 rows, 100% coverage)
  ‚úÖ Cache hit for KMPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for KMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for KMX (312 rows, 100% coverage)
  ‚úÖ Cache hit for KN (312 rows, 100% coverage)
  ‚úÖ Cache hit for KNDI (312 rows, 100% coverage)
  ‚úÖ Cache hit for KNF (312 rows, 100% coverage)
  ‚úÖ Cache hit for KNG (312 rows, 100% coverage)
  ‚úÖ Cache hit for KNO (312 rows, 100% coverage)
  ‚úÖ Cache hit for KNOP (312 rows, 100% coverage)
  ‚úÖ Cache hit for KNSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for KNSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for KNTK (312 rows, 100% coverage)
  ‚úÖ Cache hit for KNX (312 rows, 100% coverage)
  ‚úÖ Cache hit for KO (312 rows, 100% coverage)
  ‚úÖ Cache hit for KOD (312 rows, 100% coverage)
  ‚úÖ Cache hit for KODK (312 rows, 100% coverage)
  ‚úÖ Cache hit for KOF (312 rows, 100% coverage)
  ‚úÖ Cache hit for KOKU (312 rows, 100% coverage)
  ‚úÖ Cache hit for KOLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for KOMP (312 rows, 100% coverage)
  ‚úÖ Cache hit for KOP (312 rows, 100% coverage)
  ‚úÖ Cache hit for KOPN (312 rows, 100% coverage)
  ‚úÖ Cache hit for KORP (312 rows, 100% coverage)
  ‚úÖ Cache hit for KOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for KOSS (312 rows, 100% coverage)
  ‚úÖ Cache hit for KPTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for KR (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRBN (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for KREF (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRNY (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for KROS (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRP (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for KRYS (312 rows, 100% coverage)
  ‚úÖ Cache hit for KSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for KSPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for KSS (312 rows, 100% coverage)
  ‚úÖ Cache hit for KSTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for KT (312 rows, 100% coverage)
  ‚úÖ Cache hit for KTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for KTOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for KURA (312 rows, 100% coverage)
  ‚úÖ Cache hit for KURE (312 rows, 100% coverage)
  ‚úÖ Cache hit for KVUE (312 rows, 100% coverage)
  ‚úÖ Cache hit for KVYO (312 rows, 100% coverage)
  ‚úÖ Cache hit for KW (312 rows, 100% coverage)
  ‚úÖ Cache hit for KWEB (312 rows, 100% coverage)
  ‚úÖ Cache hit for KWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for KXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for KYIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for KYMR (312 rows, 100% coverage)
  ‚úÖ Cache hit for KZR (312 rows, 100% coverage)
  ‚úÖ Cache hit for L (312 rows, 100% coverage)
  ‚úÖ Cache hit for LABD (312 rows, 100% coverage)
  ‚úÖ Cache hit for LABU (312 rows, 100% coverage)
  ‚úÖ Cache hit for LAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for LAD (312 rows, 100% coverage)
  ‚úÖ Cache hit for LADR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LAES (312 rows, 100% coverage)
  ‚úÖ Cache hit for LAKE (312 rows, 100% coverage)
  ‚úÖ Cache hit for LAMR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LAND (312 rows, 100% coverage)
  ‚úÖ Cache hit for LANV (312 rows, 100% coverage)
  ‚úÖ Cache hit for LAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LASR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LAUR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LAW (312 rows, 100% coverage)
  ‚úÖ Cache hit for LAZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for LB (312 rows, 100% coverage)
  ‚úÖ Cache hit for LBAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for LBRDA (312 rows, 100% coverage)
  ‚úÖ Cache hit for LBRDK (312 rows, 100% coverage)
  ‚úÖ Cache hit for LBRDP (312 rows, 100% coverage)
  ‚úÖ Cache hit for LBRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for LBTYA (312 rows, 100% coverage)
  ‚úÖ Cache hit for LBTYK (312 rows, 100% coverage)
  ‚úÖ Cache hit for LC (312 rows, 100% coverage)
  ‚úÖ Cache hit for LCID (312 rows, 100% coverage)
  ‚úÖ Cache hit for LCII (312 rows, 100% coverage)
  ‚úÖ Cache hit for LCTD (312 rows, 100% coverage)
  ‚úÖ Cache hit for LCTU (312 rows, 100% coverage)
  ‚úÖ Cache hit for LDEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for LDI (312 rows, 100% coverage)
  ‚úÖ Cache hit for LDOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for LDSF (312 rows, 100% coverage)
  ‚úÖ Cache hit for LDUR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LE (312 rows, 100% coverage)
  ‚úÖ Cache hit for LEA (312 rows, 100% coverage)
  ‚úÖ Cache hit for LECO (312 rows, 100% coverage)
  ‚úÖ Cache hit for LEG (312 rows, 100% coverage)
  ‚úÖ Cache hit for LEGH (312 rows, 100% coverage)
  ‚úÖ Cache hit for LEGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for LEGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LEMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for LEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for LEN-B (312 rows, 100% coverage)
  ‚úÖ Cache hit for LENZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for LEO (312 rows, 100% coverage)
  ‚úÖ Cache hit for LESL (312 rows, 100% coverage)
  ‚úÖ Cache hit for LEU (312 rows, 100% coverage)
  ‚úÖ Cache hit for LEVI (312 rows, 100% coverage)
  ‚úÖ Cache hit for LFCR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LFEQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for LFGY (312 rows, 100% coverage)
  ‚úÖ Cache hit for LFMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for LFST (312 rows, 100% coverage)
  ‚úÖ Cache hit for LFUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for LFVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for LGCY (312 rows, 100% coverage)
  ‚úÖ Cache hit for LGH (312 rows, 100% coverage)
  ‚úÖ Cache hit for LGIH (312 rows, 100% coverage)
  ‚úÖ Cache hit for LGLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for LGND (312 rows, 100% coverage)
  ‚úÖ Cache hit for LGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for LH (312 rows, 100% coverage)
  ‚úÖ Cache hit for LHX (312 rows, 100% coverage)
  ‚úÖ Cache hit for LI (312 rows, 100% coverage)
  ‚úÖ Cache hit for LIF (312 rows, 100% coverage)
  ‚úÖ Cache hit for LII (312 rows, 100% coverage)
  ‚úÖ Cache hit for LILA (312 rows, 100% coverage)
  ‚úÖ Cache hit for LILAK (312 rows, 100% coverage)
  ‚úÖ Cache hit for LIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for LINC (312 rows, 100% coverage)
  ‚úÖ Cache hit for LIND (312 rows, 100% coverage)
  ‚úÖ Cache hit for LINE (312 rows, 100% coverage)
  ‚úÖ Cache hit for LION (312 rows, 100% coverage)
  ‚úÖ Cache hit for LIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for LITE (312 rows, 100% coverage)
  ‚úÖ Cache hit for LIVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for LKFN (312 rows, 100% coverage)
  ‚úÖ Cache hit for LKOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LKQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for LLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for LLYVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for LLYVK (312 rows, 100% coverage)
  ‚úÖ Cache hit for LMAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for LMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for LMBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for LMND (312 rows, 100% coverage)
  ‚úÖ Cache hit for LMNR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for LNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for LND (312 rows, 100% coverage)
  ‚úÖ Cache hit for LNG (312 rows, 100% coverage)
  ‚úÖ Cache hit for LNN (312 rows, 100% coverage)
  ‚úÖ Cache hit for LNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for LNTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for LOAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LOB (312 rows, 100% coverage)
  ‚úÖ Cache hit for LOBO (312 rows, 100% coverage)
  ‚úÖ Cache hit for LOCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for LOGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for LOMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for LONZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for LOOP (312 rows, 100% coverage)
  ‚úÖ Cache hit for LOPE (312 rows, 100% coverage)
  ‚úÖ Cache hit for LOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for LOUP (312 rows, 100% coverage)
  ‚úÖ Cache hit for LOVE (312 rows, 100% coverage)
  ‚úÖ Cache hit for LOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for LPG (312 rows, 100% coverage)
  ‚úÖ Cache hit for LPL (312 rows, 100% coverage)
  ‚úÖ Cache hit for LPLA (312 rows, 100% coverage)
  ‚úÖ Cache hit for LPRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for LPSN (312 rows, 100% coverage)
  ‚úÖ Cache hit for LPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for LQD (312 rows, 100% coverage)
  ‚úÖ Cache hit for LQDA (312 rows, 100% coverage)
  ‚úÖ Cache hit for LQDH (312 rows, 100% coverage)
  ‚úÖ Cache hit for LQDI (312 rows, 100% coverage)
  ‚úÖ Cache hit for LQDT (312 rows, 100% coverage)
  ‚úÖ Cache hit for LQDW (312 rows, 100% coverage)
  ‚úÖ Cache hit for LRCX (312 rows, 100% coverage)
  ‚úÖ Cache hit for LRGC (312 rows, 100% coverage)
  ‚úÖ Cache hit for LRGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for LRGF (312 rows, 100% coverage)
  ‚úÖ Cache hit for LRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for LRNZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for LSAF (312 rows, 100% coverage)
  ‚úÖ Cache hit for LSAK (312 rows, 100% coverage)
  ‚úÖ Cache hit for LSAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for LSCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for LSPD (312 rows, 100% coverage)
  ‚úÖ Cache hit for LSTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for LTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for LTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for LTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for LTPZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for LTRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for LU (312 rows, 100% coverage)
  ‚úÖ Cache hit for LUCK (312 rows, 100% coverage)
  ‚úÖ Cache hit for LULU (312 rows, 100% coverage)
  ‚úÖ Cache hit for LUMN (312 rows, 100% coverage)
  ‚úÖ Cache hit for LUNG (312 rows, 100% coverage)
  ‚úÖ Cache hit for LUNR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LUV (312 rows, 100% coverage)
  ‚úÖ Cache hit for LUXE (312 rows, 100% coverage)
  ‚úÖ Cache hit for LVHD (312 rows, 100% coverage)
  ‚úÖ Cache hit for LVHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for LVLU (312 rows, 100% coverage)
  ‚úÖ Cache hit for LVS (312 rows, 100% coverage)
  ‚úÖ Cache hit for LVWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LW (312 rows, 100% coverage)
  ‚úÖ Cache hit for LWAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for LWLG (312 rows, 100% coverage)
  ‚úÖ Cache hit for LX (312 rows, 100% coverage)
  ‚úÖ Cache hit for LXEH (312 rows, 100% coverage)
  ‚úÖ Cache hit for LXFR (312 rows, 100% coverage)
  ‚úÖ Cache hit for LXP (312 rows, 100% coverage)
  ‚úÖ Cache hit for LXRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for LXU (312 rows, 100% coverage)
  ‚úÖ Cache hit for LYB (312 rows, 100% coverage)
  ‚úÖ Cache hit for LYEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for LYFT (312 rows, 100% coverage)
  ‚úÖ Cache hit for LYG (312 rows, 100% coverage)
  ‚úÖ Cache hit for LYTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for LYV (312 rows, 100% coverage)
  ‚úÖ Cache hit for LZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for LZB (312 rows, 100% coverage)
  ‚úÖ Cache hit for LZM (312 rows, 100% coverage)
  ‚úÖ Cache hit for M (312 rows, 100% coverage)
  ‚úÖ Cache hit for MA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAGA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAGY (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MANH (312 rows, 100% coverage)
  ‚úÖ Cache hit for MANU (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for MARA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MARB (312 rows, 100% coverage)
  ‚úÖ Cache hit for MARM (312 rows, 100% coverage)
  ‚úÖ Cache hit for MART (312 rows, 100% coverage)
  ‚úÖ Cache hit for MARW (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MASI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MASS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MATV (312 rows, 100% coverage)
  ‚úÖ Cache hit for MATW (312 rows, 100% coverage)
  ‚úÖ Cache hit for MATX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MAXN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MBB (312 rows, 100% coverage)
  ‚úÖ Cache hit for MBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MBIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MBLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for MBSD (312 rows, 100% coverage)
  ‚úÖ Cache hit for MBUU (312 rows, 100% coverage)
  ‚úÖ Cache hit for MBWM (312 rows, 100% coverage)
  ‚úÖ Cache hit for MBX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCD (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCFT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCHB (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCHP (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCK (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCW (312 rows, 100% coverage)
  ‚úÖ Cache hit for MCY (312 rows, 100% coverage)
  ‚úÖ Cache hit for MD (312 rows, 100% coverage)
  ‚úÖ Cache hit for MDB (312 rows, 100% coverage)
  ‚úÖ Cache hit for MDGL (312 rows, 100% coverage)
  ‚úÖ Cache hit for MDIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for MDLZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for MDT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MDU (312 rows, 100% coverage)
  ‚úÖ Cache hit for MDXG (312 rows, 100% coverage)
  ‚úÖ Cache hit for MDXH (312 rows, 100% coverage)
  ‚úÖ Cache hit for MDY (312 rows, 100% coverage)
  ‚úÖ Cache hit for MDYG (312 rows, 100% coverage)
  ‚úÖ Cache hit for MDYV (312 rows, 100% coverage)
  ‚úÖ Cache hit for MEAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for MEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MED (312 rows, 100% coverage)
  ‚úÖ Cache hit for MEDP (312 rows, 100% coverage)
  ‚úÖ Cache hit for MEG (312 rows, 100% coverage)
  ‚úÖ Cache hit for MEI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MELI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MEOH (312 rows, 100% coverage)
  ‚úÖ Cache hit for MERC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MESO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MET (312 rows, 100% coverage)
  ‚úÖ Cache hit for META (312 rows, 100% coverage)
  ‚úÖ Cache hit for METC (312 rows, 100% coverage)
  ‚úÖ Cache hit for METCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for METV (312 rows, 100% coverage)
  ‚úÖ Cache hit for MEXX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MFA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MFDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MFEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for MFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for MFIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MFUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MG (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGEE (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGK (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGM (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGNI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGNX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGV (312 rows, 100% coverage)
  ‚úÖ Cache hit for MGY (312 rows, 100% coverage)
  ‚úÖ Cache hit for MHK (312 rows, 100% coverage)
  ‚úÖ Cache hit for MHO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MID (312 rows, 100% coverage)
  ‚úÖ Cache hit for MIDD (312 rows, 100% coverage)
  ‚úÖ Cache hit for MILN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MINT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MIR (312 rows, 100% coverage)
  ‚úÖ Cache hit for MIRM (312 rows, 100% coverage)
  ‚úÖ Cache hit for MITK (312 rows, 100% coverage)
  ‚úÖ Cache hit for MITT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for MKC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MKC-V (312 rows, 100% coverage)
  ‚úÖ Cache hit for MKL (312 rows, 100% coverage)
  ‚úÖ Cache hit for MKSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MKTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MLAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for MLCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MLI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MLKN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MLM (312 rows, 100% coverage)
  ‚úÖ Cache hit for MLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MLPA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MLPB (312 rows, 100% coverage)
  ‚úÖ Cache hit for MLPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MLR (312 rows, 100% coverage)
  ‚úÖ Cache hit for MLTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MLYS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MMIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MMIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MMKT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MMLG (312 rows, 100% coverage)
  ‚úÖ Cache hit for MMM (312 rows, 100% coverage)
  ‚úÖ Cache hit for MMS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MMSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MMTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for MMYT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MNDY (312 rows, 100% coverage)
  ‚úÖ Cache hit for MNKD (312 rows, 100% coverage)
  ‚úÖ Cache hit for MNMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for MNOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for MNR (312 rows, 100% coverage)
  ‚úÖ Cache hit for MNRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MNSO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MNST (312 rows, 100% coverage)
  ‚úÖ Cache hit for MNTK (312 rows, 100% coverage)
  ‚úÖ Cache hit for MNY (312 rows, 100% coverage)
  ‚úÖ Cache hit for MO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MOAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MOD (312 rows, 100% coverage)
  ‚úÖ Cache hit for MODG (312 rows, 100% coverage)
  ‚úÖ Cache hit for MODL (312 rows, 100% coverage)
  ‚úÖ Cache hit for MOFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for MOG-A (312 rows, 100% coverage)
  ‚úÖ Cache hit for MOH (312 rows, 100% coverage)
  ‚úÖ Cache hit for MOMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MOO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MORN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MORT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MOTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MOTO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for MP (312 rows, 100% coverage)
  ‚úÖ Cache hit for MPAA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MPB (312 rows, 100% coverage)
  ‚úÖ Cache hit for MPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MPLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MPRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MPU (312 rows, 100% coverage)
  ‚úÖ Cache hit for MPW (312 rows, 100% coverage)
  ‚úÖ Cache hit for MPWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for MPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for MRCY (312 rows, 100% coverage)
  ‚úÖ Cache hit for MREO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MRGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for MRK (312 rows, 100% coverage)
  ‚úÖ Cache hit for MRNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MRP (312 rows, 100% coverage)
  ‚úÖ Cache hit for MRSK (312 rows, 100% coverage)
  ‚úÖ Cache hit for MRSN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MRTN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MRUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MRVI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MRVL (312 rows, 100% coverage)
  ‚úÖ Cache hit for MRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSDL (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSFO (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSFT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for MSTZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for MT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTCH (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTD (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTDR (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTG (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTGP (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTUM (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTW (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MTZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for MU (312 rows, 100% coverage)
  ‚úÖ Cache hit for MUB (312 rows, 100% coverage)
  ‚úÖ Cache hit for MUC (312 rows, 100% coverage)
  ‚úÖ Cache hit for MUFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for MUNI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MUR (312 rows, 100% coverage)
  ‚úÖ Cache hit for MUSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MUSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MUST (312 rows, 100% coverage)
  ‚úÖ Cache hit for MUX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MVBF (312 rows, 100% coverage)
  ‚úÖ Cache hit for MVIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MVV (312 rows, 100% coverage)
  ‚úÖ Cache hit for MWA (312 rows, 100% coverage)
  ‚úÖ Cache hit for MX (312 rows, 100% coverage)
  ‚úÖ Cache hit for MXCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for MXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for MXL (312 rows, 100% coverage)
  ‚úÖ Cache hit for MYE (312 rows, 100% coverage)
  ‚úÖ Cache hit for MYGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for MYPS (312 rows, 100% coverage)
  ‚úÖ Cache hit for MYRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for MYY (312 rows, 100% coverage)
  ‚úÖ Cache hit for MZTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for NABL (312 rows, 100% coverage)
  ‚úÖ Cache hit for NAGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NAMS (312 rows, 100% coverage)
  ‚úÖ Cache hit for NANR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NAPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NATL (312 rows, 100% coverage)
  ‚úÖ Cache hit for NATR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NAUT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NAVI (312 rows, 100% coverage)
  ‚úÖ Cache hit for NBBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for NBHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for NBIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for NBIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for NBN (312 rows, 100% coverage)
  ‚úÖ Cache hit for NBP (312 rows, 100% coverage)
  ‚úÖ Cache hit for NBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NBSD (312 rows, 100% coverage)
  ‚úÖ Cache hit for NBSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for NBTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for NBTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for NCDL (312 rows, 100% coverage)
  ‚úÖ Cache hit for NCEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for NCLH (312 rows, 100% coverage)
  ‚úÖ Cache hit for NCMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for NCNO (312 rows, 100% coverage)
  ‚úÖ Cache hit for NDAQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for NDLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for NDSN (312 rows, 100% coverage)
  ‚úÖ Cache hit for NE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NEAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NECB (312 rows, 100% coverage)
  ‚úÖ Cache hit for NEE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for NEO (312 rows, 100% coverage)
  ‚úÖ Cache hit for NEOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NERD (312 rows, 100% coverage)
  ‚úÖ Cache hit for NERV (312 rows, 100% coverage)
  ‚úÖ Cache hit for NESR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NET (312 rows, 100% coverage)
  ‚úÖ Cache hit for NETL (312 rows, 100% coverage)
  ‚úÖ Cache hit for NEU (312 rows, 100% coverage)
  ‚úÖ Cache hit for NEUP (312 rows, 100% coverage)
  ‚úÖ Cache hit for NEWT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NEXA (312 rows, 100% coverage)
  ‚úÖ Cache hit for NEXT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NFBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for NFE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NFLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NFLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for NFLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for NFRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for NG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NGD (312 rows, 100% coverage)
  ‚úÖ Cache hit for NGG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NGL (312 rows, 100% coverage)
  ‚úÖ Cache hit for NGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for NGVC (312 rows, 100% coverage)
  ‚úÖ Cache hit for NGVT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for NHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for NHTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for NI (312 rows, 100% coverage)
  ‚úÖ Cache hit for NIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for NICE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for NIPG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NIU (312 rows, 100% coverage)
  ‚úÖ Cache hit for NJAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for NJR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NJUL (312 rows, 100% coverage)
  ‚úÖ Cache hit for NKE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NKTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for NL (312 rows, 100% coverage)
  ‚úÖ Cache hit for NLOP (312 rows, 100% coverage)
  ‚úÖ Cache hit for NLR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for NMFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for NMG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NMIH (312 rows, 100% coverage)
  ‚úÖ Cache hit for NMM (312 rows, 100% coverage)
  ‚úÖ Cache hit for NMR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NMRK (312 rows, 100% coverage)
  ‚úÖ Cache hit for NN (312 rows, 100% coverage)
  ‚úÖ Cache hit for NNDM (312 rows, 100% coverage)
  ‚úÖ Cache hit for NNE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NNI (312 rows, 100% coverage)
  ‚úÖ Cache hit for NNN (312 rows, 100% coverage)
  ‚úÖ Cache hit for NNOX (312 rows, 100% coverage)
  ‚úÖ Cache hit for NOA (312 rows, 100% coverage)
  ‚úÖ Cache hit for NOAH (312 rows, 100% coverage)
  ‚úÖ Cache hit for NOBL (312 rows, 100% coverage)
  ‚úÖ Cache hit for NOC (312 rows, 100% coverage)
  ‚úÖ Cache hit for NOCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NODK (312 rows, 100% coverage)
  ‚úÖ Cache hit for NOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NOK (312 rows, 100% coverage)
  ‚úÖ Cache hit for NOMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for NORW (312 rows, 100% coverage)
  ‚úÖ Cache hit for NOTV (312 rows, 100% coverage)
  ‚úÖ Cache hit for NOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for NOVT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for NPCE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NPK (312 rows, 100% coverage)
  ‚úÖ Cache hit for NPKI (312 rows, 100% coverage)
  ‚úÖ Cache hit for NPO (312 rows, 100% coverage)
  ‚úÖ Cache hit for NPWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for NRDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for NRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NRGV (312 rows, 100% coverage)
  ‚úÖ Cache hit for NRIM (312 rows, 100% coverage)
  ‚úÖ Cache hit for NRIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for NRP (312 rows, 100% coverage)
  ‚úÖ Cache hit for NSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for NSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for NSIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NSP (312 rows, 100% coverage)
  ‚úÖ Cache hit for NSSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTAP (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTES (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTLA (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTNX (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTRSO (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTST (312 rows, 100% coverage)
  ‚úÖ Cache hit for NTSX (312 rows, 100% coverage)
  ‚úÖ Cache hit for NU (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUAG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUDM (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUGT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for NULG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NULV (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUMG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUMV (312 rows, 100% coverage)
  ‚úÖ Cache hit for NURE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUVB (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUVL (312 rows, 100% coverage)
  ‚úÖ Cache hit for NUWE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVCR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVD (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVDA (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVDL (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVDU (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVDY (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVO (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVS (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVST (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for NVX (312 rows, 100% coverage)
  ‚úÖ Cache hit for NWBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for NWE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NWG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NWL (312 rows, 100% coverage)
  ‚úÖ Cache hit for NWN (312 rows, 100% coverage)
  ‚úÖ Cache hit for NWPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for NWS (312 rows, 100% coverage)
  ‚úÖ Cache hit for NWSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for NX (312 rows, 100% coverage)
  ‚úÖ Cache hit for NXDR (312 rows, 100% coverage)
  ‚úÖ Cache hit for NXDT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NXE (312 rows, 100% coverage)
  ‚úÖ Cache hit for NXP (312 rows, 100% coverage)
  ‚úÖ Cache hit for NXPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for NXRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NXST (312 rows, 100% coverage)
  ‚úÖ Cache hit for NXT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NXTG (312 rows, 100% coverage)
  ‚úÖ Cache hit for NYF (312 rows, 100% coverage)
  ‚úÖ Cache hit for NYT (312 rows, 100% coverage)
  ‚úÖ Cache hit for NYXH (312 rows, 100% coverage)
  ‚úÖ Cache hit for NZAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for O (312 rows, 100% coverage)
  ‚úÖ Cache hit for OABI (312 rows, 100% coverage)
  ‚úÖ Cache hit for OACP (312 rows, 100% coverage)
  ‚úÖ Cache hit for OAEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for OAIM (312 rows, 100% coverage)
  ‚úÖ Cache hit for OALC (312 rows, 100% coverage)
  ‚úÖ Cache hit for OASC (312 rows, 100% coverage)
  ‚úÖ Cache hit for OBDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for OBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for OC (312 rows, 100% coverage)
  ‚úÖ Cache hit for OCFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for OCIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for OCS (312 rows, 100% coverage)
  ‚úÖ Cache hit for OCSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for OCTW (312 rows, 100% coverage)
  ‚úÖ Cache hit for OCUL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ODC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ODD (312 rows, 100% coverage)
  ‚úÖ Cache hit for ODFL (312 rows, 100% coverage)
  ‚úÖ Cache hit for OEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for OEF (312 rows, 100% coverage)
  ‚úÖ Cache hit for OEFA (312 rows, 100% coverage)
  ‚úÖ Cache hit for OFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for OFIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for OFLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for OGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for OGIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for OGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for OGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for OHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for OI (312 rows, 100% coverage)
  ‚úÖ Cache hit for OIH (312 rows, 100% coverage)
  ‚úÖ Cache hit for OII (312 rows, 100% coverage)
  ‚úÖ Cache hit for OILD (312 rows, 100% coverage)
  ‚úÖ Cache hit for OILK (312 rows, 100% coverage)
  ‚úÖ Cache hit for OIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for OKE (312 rows, 100% coverage)
  ‚úÖ Cache hit for OKLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for OKTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for OKUR (312 rows, 100% coverage)
  ‚úÖ Cache hit for OLED (312 rows, 100% coverage)
  ‚úÖ Cache hit for OLLI (312 rows, 100% coverage)
  ‚úÖ Cache hit for OLMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for OLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for OLP (312 rows, 100% coverage)
  ‚úÖ Cache hit for OLPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for OM (312 rows, 100% coverage)
  ‚úÖ Cache hit for OMAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for OMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for OMCL (312 rows, 100% coverage)
  ‚úÖ Cache hit for OMER (312 rows, 100% coverage)
  ‚úÖ Cache hit for OMF (312 rows, 100% coverage)
  ‚úÖ Cache hit for OMFL (312 rows, 100% coverage)
  ‚úÖ Cache hit for OMFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for OMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ON (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONBPO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONEO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONEQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONEV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONEW (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONEY (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONOF (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONON (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONTF (312 rows, 100% coverage)
  ‚úÖ Cache hit for ONTO (312 rows, 100% coverage)
  ‚úÖ Cache hit for OOMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPCH (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPER (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPFI (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPK (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPPE (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPTU (312 rows, 100% coverage)
  ‚úÖ Cache hit for OPY (312 rows, 100% coverage)
  ‚úÖ Cache hit for OR (312 rows, 100% coverage)
  ‚úÖ Cache hit for ORA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ORC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ORCL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ORGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ORI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ORIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ORKA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ORLA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ORLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for ORMP (312 rows, 100% coverage)
  ‚úÖ Cache hit for ORN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ORRF (312 rows, 100% coverage)
  ‚úÖ Cache hit for OS (312 rows, 100% coverage)
  ‚úÖ Cache hit for OSBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for OSCR (312 rows, 100% coverage)
  ‚úÖ Cache hit for OSCV (312 rows, 100% coverage)
  ‚úÖ Cache hit for OSEA (312 rows, 100% coverage)
  ‚úÖ Cache hit for OSG (312 rows, 100% coverage)
  ‚úÖ Cache hit for OSIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for OSK (312 rows, 100% coverage)
  ‚úÖ Cache hit for OSPN (312 rows, 100% coverage)
  ‚úÖ Cache hit for OSS (312 rows, 100% coverage)
  ‚úÖ Cache hit for OSUR (312 rows, 100% coverage)
  ‚úÖ Cache hit for OSW (312 rows, 100% coverage)
  ‚úÖ Cache hit for OTEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for OTIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for OTTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for OUNZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for OUSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for OUSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for OUST (312 rows, 100% coverage)
  ‚úÖ Cache hit for OUT (312 rows, 100% coverage)
  ‚úÖ Cache hit for OVB (312 rows, 100% coverage)
  ‚úÖ Cache hit for OVL (312 rows, 100% coverage)
  ‚úÖ Cache hit for OVV (312 rows, 100% coverage)
  ‚úÖ Cache hit for OWL (312 rows, 100% coverage)
  ‚úÖ Cache hit for OWNS (312 rows, 100% coverage)
  ‚úÖ Cache hit for OXLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for OXM (312 rows, 100% coverage)
  ‚úÖ Cache hit for OXSQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for OXY (312 rows, 100% coverage)
  ‚úÖ Cache hit for OZK (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAA (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAAS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PABU (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PACB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PACK (312 rows, 100% coverage)
  ‚úÖ Cache hit for PACS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAGP (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PALC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PALL (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PANL (312 rows, 100% coverage)
  ‚úÖ Cache hit for PANW (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PARR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PATH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PATK (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAVE (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAWZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAYC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAYO (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAYS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PAYX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBA (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBE (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBF (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBP (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBR-A (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBTP (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBW (312 rows, 100% coverage)
  ‚úÖ Cache hit for PBYI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PCAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PCEF (312 rows, 100% coverage)
  ‚úÖ Cache hit for PCG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PCH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PCOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PCRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PCTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PCVX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PCY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PCYO (312 rows, 100% coverage)
  ‚úÖ Cache hit for PD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PDBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PDD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PDEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PDFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PDLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PDM (312 rows, 100% coverage)
  ‚úÖ Cache hit for PDN (312 rows, 100% coverage)
  ‚úÖ Cache hit for PDP (312 rows, 100% coverage)
  ‚úÖ Cache hit for PDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PDSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PEB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PEBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for PEBO (312 rows, 100% coverage)
  ‚úÖ Cache hit for PECO (312 rows, 100% coverage)
  ‚úÖ Cache hit for PEG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PEGA (312 rows, 100% coverage)
  ‚úÖ Cache hit for PEJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for PEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for PENG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PENN (312 rows, 100% coverage)
  ‚úÖ Cache hit for PEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for PERI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PETS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PETZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for PEY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PEZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFE (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFEB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFF (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFFA (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFFD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFFR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFFV (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFGC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFM (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFUT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PFXF (312 rows, 100% coverage)
  ‚úÖ Cache hit for PG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PGC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PGF (312 rows, 100% coverage)
  ‚úÖ Cache hit for PGHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PGJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for PGNY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PGX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PGY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PHAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PHB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PHDG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PHG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PHIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for PHM (312 rows, 100% coverage)
  ‚úÖ Cache hit for PHO (312 rows, 100% coverage)
  ‚úÖ Cache hit for PHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PHVS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PHYL (312 rows, 100% coverage)
  ‚úÖ Cache hit for PHYS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PICB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PICK (312 rows, 100% coverage)
  ‚úÖ Cache hit for PID (312 rows, 100% coverage)
  ‚úÖ Cache hit for PIE (312 rows, 100% coverage)
  ‚úÖ Cache hit for PIFI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PII (312 rows, 100% coverage)
  ‚úÖ Cache hit for PIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for PINK (312 rows, 100% coverage)
  ‚úÖ Cache hit for PINS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for PIPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PIZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for PJAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for PJP (312 rows, 100% coverage)
  ‚úÖ Cache hit for PJT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PJUL (312 rows, 100% coverage)
  ‚úÖ Cache hit for PJUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for PK (312 rows, 100% coverage)
  ‚úÖ Cache hit for PKB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PKG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PKOH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PKST (312 rows, 100% coverage)
  ‚úÖ Cache hit for PKW (312 rows, 100% coverage)
  ‚úÖ Cache hit for PKX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PL (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLCE (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLDR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLMR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLSE (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLTK (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLXS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PLYM (312 rows, 100% coverage)
  ‚úÖ Cache hit for PM (312 rows, 100% coverage)
  ‚úÖ Cache hit for PMAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PMAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PMMF (312 rows, 100% coverage)
  ‚úÖ Cache hit for PMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PMTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PMVP (312 rows, 100% coverage)
  ‚úÖ Cache hit for PNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PNFP (312 rows, 100% coverage)
  ‚úÖ Cache hit for PNNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PNOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for PNQI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PNR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PNTG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PNW (312 rows, 100% coverage)
  ‚úÖ Cache hit for POCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PODD (312 rows, 100% coverage)
  ‚úÖ Cache hit for POET (312 rows, 100% coverage)
  ‚úÖ Cache hit for PONY (312 rows, 100% coverage)
  ‚úÖ Cache hit for POOL (312 rows, 100% coverage)
  ‚úÖ Cache hit for POR (312 rows, 100% coverage)
  ‚úÖ Cache hit for POST (312 rows, 100% coverage)
  ‚úÖ Cache hit for POWA (312 rows, 100% coverage)
  ‚úÖ Cache hit for POWI (312 rows, 100% coverage)
  ‚úÖ Cache hit for POWL (312 rows, 100% coverage)
  ‚úÖ Cache hit for POWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for POWW (312 rows, 100% coverage)
  ‚úÖ Cache hit for PPA (312 rows, 100% coverage)
  ‚úÖ Cache hit for PPBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PPG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PPH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PPL (312 rows, 100% coverage)
  ‚úÖ Cache hit for PPLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PPTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for PPTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRAA (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRCH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRDO (312 rows, 100% coverage)
  ‚úÖ Cache hit for PREF (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRF (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRFZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRIM (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRK (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRKS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRM (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRME (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRPL (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRSU (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRU (312 rows, 100% coverage)
  ‚úÖ Cache hit for PRVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSCD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSCE (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSCF (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSCH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSCM (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSCU (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSET (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSFD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSFE (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSFF (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSK (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSKY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSN (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSNL (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSNY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSO (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSP (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSTG (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for PSX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTF (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTGX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTN (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTNQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTON (312 rows, 100% coverage)
  ‚úÖ Cache hit for PTRB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PUBM (312 rows, 100% coverage)
  ‚úÖ Cache hit for PUK (312 rows, 100% coverage)
  ‚úÖ Cache hit for PULS (312 rows, 100% coverage)
  ‚úÖ Cache hit for PUMP (312 rows, 100% coverage)
  ‚úÖ Cache hit for PVAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for PVH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PVI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PW (312 rows, 100% coverage)
  ‚úÖ Cache hit for PWB (312 rows, 100% coverage)
  ‚úÖ Cache hit for PWP (312 rows, 100% coverage)
  ‚úÖ Cache hit for PWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for PWRD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PWV (312 rows, 100% coverage)
  ‚úÖ Cache hit for PWZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for PX (312 rows, 100% coverage)
  ‚úÖ Cache hit for PXE (312 rows, 100% coverage)
  ‚úÖ Cache hit for PXF (312 rows, 100% coverage)
  ‚úÖ Cache hit for PXH (312 rows, 100% coverage)
  ‚úÖ Cache hit for PXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for PY (312 rows, 100% coverage)
  ‚úÖ Cache hit for PYLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for PYPL (312 rows, 100% coverage)
  ‚úÖ Cache hit for PYZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for PZA (312 rows, 100% coverage)
  ‚úÖ Cache hit for PZT (312 rows, 100% coverage)
  ‚úÖ Cache hit for PZZA (312 rows, 100% coverage)
  ‚úÖ Cache hit for QABA (312 rows, 100% coverage)
  ‚úÖ Cache hit for QAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for QAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for QBTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for QCLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for QCLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for QCOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for QCRH (312 rows, 100% coverage)
  ‚úÖ Cache hit for QDEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for QDEF (312 rows, 100% coverage)
  ‚úÖ Cache hit for QDEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for QDF (312 rows, 100% coverage)
  ‚úÖ Cache hit for QDPL (312 rows, 100% coverage)
  ‚úÖ Cache hit for QDTE (312 rows, 100% coverage)
  ‚úÖ Cache hit for QEFA (312 rows, 100% coverage)
  ‚úÖ Cache hit for QEMM (312 rows, 100% coverage)
  ‚úÖ Cache hit for QETH (312 rows, 100% coverage)
  ‚úÖ Cache hit for QFIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for QFLR (312 rows, 100% coverage)
  ‚úÖ Cache hit for QGEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for QGRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for QGRW (312 rows, 100% coverage)
  ‚úÖ Cache hit for QHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for QID (312 rows, 100% coverage)
  ‚úÖ Cache hit for QIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for QINT (312 rows, 100% coverage)
  ‚úÖ Cache hit for QJUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for QLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for QLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for QLTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for QLTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for QLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for QLVD (312 rows, 100% coverage)
  ‚úÖ Cache hit for QLYS (312 rows, 100% coverage)
  ‚úÖ Cache hit for QMAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for QMCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for QMOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for QNST (312 rows, 100% coverage)
  ‚úÖ Cache hit for QNTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for QPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for QQEW (312 rows, 100% coverage)
  ‚úÖ Cache hit for QQH (312 rows, 100% coverage)
  ‚úÖ Cache hit for QQQE (312 rows, 100% coverage)
  ‚úÖ Cache hit for QQQH (312 rows, 100% coverage)
  ‚úÖ Cache hit for QQQI (312 rows, 100% coverage)
  ‚úÖ Cache hit for QQQJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for QQQM (312 rows, 100% coverage)
  ‚úÖ Cache hit for QQQX (312 rows, 100% coverage)
  ‚úÖ Cache hit for QQQY (312 rows, 100% coverage)
  ‚úÖ Cache hit for QQXT (312 rows, 100% coverage)
  ‚úÖ Cache hit for QRHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for QRVO (312 rows, 100% coverage)
  ‚úÖ Cache hit for QS (312 rows, 100% coverage)
  ‚úÖ Cache hit for QSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for QSIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for QSPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for QSR (312 rows, 100% coverage)
  ‚úÖ Cache hit for QTEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for QTRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for QTTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for QTUM (312 rows, 100% coverage)
  ‚úÖ Cache hit for QTWO (312 rows, 100% coverage)
  ‚úÖ Cache hit for QUAD (312 rows, 100% coverage)
  ‚úÖ Cache hit for QUAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for QUBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for QUIK (312 rows, 100% coverage)
  ‚úÖ Cache hit for QURE (312 rows, 100% coverage)
  ‚úÖ Cache hit for QUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for QVAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for QVML (312 rows, 100% coverage)
  ‚úÖ Cache hit for QVMM (312 rows, 100% coverage)
  ‚úÖ Cache hit for QVMS (312 rows, 100% coverage)
  ‚úÖ Cache hit for QWLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for QXO (312 rows, 100% coverage)
  ‚úÖ Cache hit for QYLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for QYLG (312 rows, 100% coverage)
  ‚úÖ Cache hit for R (312 rows, 100% coverage)
  ‚úÖ Cache hit for RA (312 rows, 100% coverage)
  ‚úÖ Cache hit for RAAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RACE (312 rows, 100% coverage)
  ‚úÖ Cache hit for RAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for RAMP (312 rows, 100% coverage)
  ‚úÖ Cache hit for RANI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RAPP (312 rows, 100% coverage)
  ‚úÖ Cache hit for RAPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RARE (312 rows, 100% coverage)
  ‚úÖ Cache hit for RAVI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RBA (312 rows, 100% coverage)
  ‚úÖ Cache hit for RBB (312 rows, 100% coverage)
  ‚úÖ Cache hit for RBBN (312 rows, 100% coverage)
  ‚úÖ Cache hit for RBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for RBCAA (312 rows, 100% coverage)
  ‚úÖ Cache hit for RBLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for RBLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RBOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RBRK (312 rows, 100% coverage)
  ‚úÖ Cache hit for RC (312 rows, 100% coverage)
  ‚úÖ Cache hit for RCAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RCEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for RCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RCKT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RCKY (312 rows, 100% coverage)
  ‚úÖ Cache hit for RCL (312 rows, 100% coverage)
  ‚úÖ Cache hit for RCUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for RDDT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RDIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for RDN (312 rows, 100% coverage)
  ‚úÖ Cache hit for RDNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RDNW (312 rows, 100% coverage)
  ‚úÖ Cache hit for RDTE (312 rows, 100% coverage)
  ‚úÖ Cache hit for RDVT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RDVY (312 rows, 100% coverage)
  ‚úÖ Cache hit for RDW (312 rows, 100% coverage)
  ‚úÖ Cache hit for RDWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for RDY (312 rows, 100% coverage)
  ‚úÖ Cache hit for REAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for REAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RECS (312 rows, 100% coverage)
  ‚úÖ Cache hit for REET (312 rows, 100% coverage)
  ‚úÖ Cache hit for REFI (312 rows, 100% coverage)
  ‚úÖ Cache hit for REFR (312 rows, 100% coverage)
  ‚úÖ Cache hit for REG (312 rows, 100% coverage)
  ‚úÖ Cache hit for REGL (312 rows, 100% coverage)
  ‚úÖ Cache hit for REGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for REI (312 rows, 100% coverage)
  ‚úÖ Cache hit for REK (312 rows, 100% coverage)
  ‚úÖ Cache hit for RELI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RELX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RELY (312 rows, 100% coverage)
  ‚úÖ Cache hit for REM (312 rows, 100% coverage)
  ‚úÖ Cache hit for REMX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RENT (312 rows, 100% coverage)
  ‚úÖ Cache hit for REPL (312 rows, 100% coverage)
  ‚úÖ Cache hit for REPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RERE (312 rows, 100% coverage)
  ‚úÖ Cache hit for RES (312 rows, 100% coverage)
  ‚úÖ Cache hit for RETL (312 rows, 100% coverage)
  ‚úÖ Cache hit for REVB (312 rows, 100% coverage)
  ‚úÖ Cache hit for REVG (312 rows, 100% coverage)
  ‚úÖ Cache hit for REVS (312 rows, 100% coverage)
  ‚úÖ Cache hit for REX (312 rows, 100% coverage)
  ‚úÖ Cache hit for REXR (312 rows, 100% coverage)
  ‚úÖ Cache hit for REYN (312 rows, 100% coverage)
  ‚úÖ Cache hit for REZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for REZI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RF (312 rows, 100% coverage)
  ‚úÖ Cache hit for RFDI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RFEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for RFEU (312 rows, 100% coverage)
  ‚úÖ Cache hit for RFFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for RFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for RFV (312 rows, 100% coverage)
  ‚úÖ Cache hit for RGA (312 rows, 100% coverage)
  ‚úÖ Cache hit for RGEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for RGLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for RGNX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RGP (312 rows, 100% coverage)
  ‚úÖ Cache hit for RGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for RGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for RGTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RH (312 rows, 100% coverage)
  ‚úÖ Cache hit for RHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RHP (312 rows, 100% coverage)
  ‚úÖ Cache hit for RHRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RHTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RICK (312 rows, 100% coverage)
  ‚úÖ Cache hit for RIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for RIGL (312 rows, 100% coverage)
  ‚úÖ Cache hit for RIGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for RILY (312 rows, 100% coverage)
  ‚úÖ Cache hit for RING (312 rows, 100% coverage)
  ‚úÖ Cache hit for RIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for RIOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RISN (312 rows, 100% coverage)
  ‚úÖ Cache hit for RITM (312 rows, 100% coverage)
  ‚úÖ Cache hit for RIVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for RJF (312 rows, 100% coverage)
  ‚úÖ Cache hit for RKLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for RKT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RL (312 rows, 100% coverage)
  ‚úÖ Cache hit for RLAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for RLI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RLJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for RLMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for RLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for RM (312 rows, 100% coverage)
  ‚úÖ Cache hit for RMAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RMBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for RMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for RMNI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RMR (312 rows, 100% coverage)
  ‚úÖ Cache hit for RNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for RNAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for RNAZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for RNEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for RNG (312 rows, 100% coverage)
  ‚úÖ Cache hit for RNGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for RNR (312 rows, 100% coverage)
  ‚úÖ Cache hit for RNRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for RNST (312 rows, 100% coverage)
  ‚úÖ Cache hit for RNW (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROAD (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROBO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROCK (312 rows, 100% coverage)
  ‚úÖ Cache hit for RODM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROK (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROKU (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROP (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROST (312 rows, 100% coverage)
  ‚úÖ Cache hit for ROUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for RPAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for RPAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for RPD (312 rows, 100% coverage)
  ‚úÖ Cache hit for RPG (312 rows, 100% coverage)
  ‚úÖ Cache hit for RPID (312 rows, 100% coverage)
  ‚úÖ Cache hit for RPM (312 rows, 100% coverage)
  ‚úÖ Cache hit for RPRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RPTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RPV (312 rows, 100% coverage)
  ‚úÖ Cache hit for RQI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for RRGB (312 rows, 100% coverage)
  ‚úÖ Cache hit for RRR (312 rows, 100% coverage)
  ‚úÖ Cache hit for RRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RS (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSG (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSKD (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSP (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSPD (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSPF (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSPG (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSPH (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSPM (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSPN (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSPS (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSPU (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSSS (312 rows, 100% coverage)
  ‚úÖ Cache hit for RSVR (312 rows, 100% coverage)
  ‚úÖ Cache hit for RTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for RTO (312 rows, 100% coverage)
  ‚úÖ Cache hit for RTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RUM (312 rows, 100% coverage)
  ‚úÖ Cache hit for RUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for RUNN (312 rows, 100% coverage)
  ‚úÖ Cache hit for RUSHA (312 rows, 100% coverage)
  ‚úÖ Cache hit for RUSHB (312 rows, 100% coverage)
  ‚úÖ Cache hit for RVLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for RVMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for RVNU (312 rows, 100% coverage)
  ‚úÖ Cache hit for RVTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for RWAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for RWJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for RWK (312 rows, 100% coverage)
  ‚úÖ Cache hit for RWL (312 rows, 100% coverage)
  ‚úÖ Cache hit for RWM (312 rows, 100% coverage)
  ‚úÖ Cache hit for RWO (312 rows, 100% coverage)
  ‚úÖ Cache hit for RWR (312 rows, 100% coverage)
  ‚úÖ Cache hit for RWT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RWX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RXL (312 rows, 100% coverage)
  ‚úÖ Cache hit for RXO (312 rows, 100% coverage)
  ‚úÖ Cache hit for RXRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for RXST (312 rows, 100% coverage)
  ‚úÖ Cache hit for RXT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RY (312 rows, 100% coverage)
  ‚úÖ Cache hit for RYAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for RYAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for RYI (312 rows, 100% coverage)
  ‚úÖ Cache hit for RYLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for RYM (312 rows, 100% coverage)
  ‚úÖ Cache hit for RYN (312 rows, 100% coverage)
  ‚úÖ Cache hit for RYTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for RZB (312 rows, 100% coverage)
  ‚úÖ Cache hit for RZG (312 rows, 100% coverage)
  ‚úÖ Cache hit for RZLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for RZLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for RZV (312 rows, 100% coverage)
  ‚úÖ Cache hit for S (312 rows, 100% coverage)
  ‚úÖ Cache hit for SA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SAA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SABR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SAFE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SAFT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SAH (312 rows, 100% coverage)
  ‚úÖ Cache hit for SAIA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SAIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SANA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SANM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SAP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SARK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SARO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SATS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SAVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBCF (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBET (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBFM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBH (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBLK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBSW (312 rows, 100% coverage)
  ‚úÖ Cache hit for SBUX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHF (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHH (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHW (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCHZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCNX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCVL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SCZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SDA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SDCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SDEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SDG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SDGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SDHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SDIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SDOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SDRL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SDVY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SDY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SECT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEDG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEER (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEF (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEIM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEIQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SELV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEMR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SENEA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEPN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SERV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SEZL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SF (312 rows, 100% coverage)
  ‚úÖ Cache hit for SFBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SFGV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SFIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SFL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SFM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SFNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SFST (312 rows, 100% coverage)
  ‚úÖ Cache hit for SFWL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SFY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SFYX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SGDJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SGDM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SGHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SGML (312 rows, 100% coverage)
  ‚úÖ Cache hit for SGMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SGOL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SGOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SGRY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SGU (312 rows, 100% coverage)
  ‚úÖ Cache hit for SH (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHAG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHAK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHOO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHOP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHW (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHYD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHYG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SHYL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIBN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SID (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIGA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SII (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SILA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SILC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SILJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIMS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SINT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SITC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SITE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SITM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIVR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIXA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIXG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIXH (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIXJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIXL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIXO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SIZE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SJB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SJM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SJNK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKIL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKLZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKWD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKYH (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKYT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKYW (312 rows, 100% coverage)
  ‚úÖ Cache hit for SKYY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLDP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLF (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLMBP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLNH (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLNO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLQD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLQT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLVM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLVO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLVP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLYG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SLYV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMCX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMDV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMH (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMLF (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMLR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMMU (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMMV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMPL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMTK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMWB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SMX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNAP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNCY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNDA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNDK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNDL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNDR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNFCA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNPE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNPS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNSR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SNY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOBO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOCL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOFI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOFR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOHU (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOJC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOJD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOJE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SON (312 rows, 100% coverage)
  ‚úÖ Cache hit for SONO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SONY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOXL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOXQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOXS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOXX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SOYB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPBO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPCE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPCX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPDN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPDV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPDW (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPEU (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPFF (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPFI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPGM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPGP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPH (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPHB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPHD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPHQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPIB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPIR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPMV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPOK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPPP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPRU (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPRY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPSK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPTE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPUC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPUU (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPVM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPVU (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPWH (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPWO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPXC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPXE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPXL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPXN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPXS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPXT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPXU (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPXV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPYC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPYD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPYG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPYI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPYM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPYT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPYV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SPYX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SQM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SQNS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SQQQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRAD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRCE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRET (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRHQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRRK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SRVR (312 rows, 100% coverage)
  ‚úÖ Cache hit for SSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SSD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SSNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SSO (312 rows, 100% coverage)
  ‚úÖ Cache hit for SSP (312 rows, 100% coverage)
  ‚úÖ Cache hit for SSPY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SSRM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SST (312 rows, 100% coverage)
  ‚úÖ Cache hit for SSTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SSTK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SSUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SSYS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ST (312 rows, 100% coverage)
  ‚úÖ Cache hit for STAA (312 rows, 100% coverage)
  ‚úÖ Cache hit for STAG (312 rows, 100% coverage)
  ‚úÖ Cache hit for STBA (312 rows, 100% coverage)
  ‚úÖ Cache hit for STC (312 rows, 100% coverage)
  ‚úÖ Cache hit for STE (312 rows, 100% coverage)
  ‚úÖ Cache hit for STEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for STEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for STGW (312 rows, 100% coverage)
  ‚úÖ Cache hit for STHO (312 rows, 100% coverage)
  ‚úÖ Cache hit for STIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for STKL (312 rows, 100% coverage)
  ‚úÖ Cache hit for STKS (312 rows, 100% coverage)
  ‚úÖ Cache hit for STLA (312 rows, 100% coverage)
  ‚úÖ Cache hit for STLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for STM (312 rows, 100% coverage)
  ‚úÖ Cache hit for STN (312 rows, 100% coverage)
  ‚úÖ Cache hit for STNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for STNE (312 rows, 100% coverage)
  ‚úÖ Cache hit for STNG (312 rows, 100% coverage)
  ‚úÖ Cache hit for STOK (312 rows, 100% coverage)
  ‚úÖ Cache hit for STOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for STPZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for STRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for STRK (312 rows, 100% coverage)
  ‚úÖ Cache hit for STRL (312 rows, 100% coverage)
  ‚úÖ Cache hit for STRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for STRZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for STT (312 rows, 100% coverage)
  ‚úÖ Cache hit for STUB (312 rows, 100% coverage)
  ‚úÖ Cache hit for STVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for STWD (312 rows, 100% coverage)
  ‚úÖ Cache hit for STX (312 rows, 100% coverage)
  ‚úÖ Cache hit for STXS (312 rows, 100% coverage)
  ‚úÖ Cache hit for STZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SU (312 rows, 100% coverage)
  ‚úÖ Cache hit for SUB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SUI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SUPN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SUPV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SURE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SUSA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SUSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SUSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SUSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SUZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for SVAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SVC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SVIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SVOL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SVRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SVRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SVV (312 rows, 100% coverage)
  ‚úÖ Cache hit for SVXY (312 rows, 100% coverage)
  ‚úÖ Cache hit for SW (312 rows, 100% coverage)
  ‚úÖ Cache hit for SWAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for SWBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SWIM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SWK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SWKS (312 rows, 100% coverage)
  ‚úÖ Cache hit for SWVL (312 rows, 100% coverage)
  ‚úÖ Cache hit for SWX (312 rows, 100% coverage)
  ‚úÖ Cache hit for SXC (312 rows, 100% coverage)
  ‚úÖ Cache hit for SXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for SXT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SYBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for SYF (312 rows, 100% coverage)
  ‚úÖ Cache hit for SYK (312 rows, 100% coverage)
  ‚úÖ Cache hit for SYLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for SYM (312 rows, 100% coverage)
  ‚úÖ Cache hit for SYNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for SYRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for SYSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for SYY (312 rows, 100% coverage)
  ‚úÖ Cache hit for T (312 rows, 100% coverage)
  ‚úÖ Cache hit for TAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TACK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TAGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TAIL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TAK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TALK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TALO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for TAP (312 rows, 100% coverage)
  ‚úÖ Cache hit for TARK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TARS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TASK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TATT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TAXF (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBB (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBBB (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBCH (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBF (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBIL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBLA (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBLL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBPH (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBUX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TBX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TCAF (312 rows, 100% coverage)
  ‚úÖ Cache hit for TCBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for TCBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TCBX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TCHP (312 rows, 100% coverage)
  ‚úÖ Cache hit for TCMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for TCOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for TCPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TCX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TD (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDG (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDOC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDTF (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDTT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDV (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDVG (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDW (312 rows, 100% coverage)
  ‚úÖ Cache hit for TDY (312 rows, 100% coverage)
  ‚úÖ Cache hit for TE (312 rows, 100% coverage)
  ‚úÖ Cache hit for TEAM (312 rows, 100% coverage)
  ‚úÖ Cache hit for TECB (312 rows, 100% coverage)
  ‚úÖ Cache hit for TECH (312 rows, 100% coverage)
  ‚úÖ Cache hit for TECK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TECL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TECS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TECX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TEF (312 rows, 100% coverage)
  ‚úÖ Cache hit for TEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for TEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for TENB (312 rows, 100% coverage)
  ‚úÖ Cache hit for TENX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TEO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TEQI (312 rows, 100% coverage)
  ‚úÖ Cache hit for TER (312 rows, 100% coverage)
  ‚úÖ Cache hit for TERN (312 rows, 100% coverage)
  ‚úÖ Cache hit for TESL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TETH (312 rows, 100% coverage)
  ‚úÖ Cache hit for TEVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for TEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TFI (312 rows, 100% coverage)
  ‚úÖ Cache hit for TFII (312 rows, 100% coverage)
  ‚úÖ Cache hit for TFIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for TFJL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TFLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TFPM (312 rows, 100% coverage)
  ‚úÖ Cache hit for TFSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TFX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TG (312 rows, 100% coverage)
  ‚úÖ Cache hit for TGLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TGNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for TGRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TGRW (312 rows, 100% coverage)
  ‚úÖ Cache hit for TGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TGT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TGTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TH (312 rows, 100% coverage)
  ‚úÖ Cache hit for THC (312 rows, 100% coverage)
  ‚úÖ Cache hit for THCH (312 rows, 100% coverage)
  ‚úÖ Cache hit for THD (312 rows, 100% coverage)
  ‚úÖ Cache hit for THFF (312 rows, 100% coverage)
  ‚úÖ Cache hit for THG (312 rows, 100% coverage)
  ‚úÖ Cache hit for THNQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for THO (312 rows, 100% coverage)
  ‚úÖ Cache hit for THR (312 rows, 100% coverage)
  ‚úÖ Cache hit for THRM (312 rows, 100% coverage)
  ‚úÖ Cache hit for THRY (312 rows, 100% coverage)
  ‚úÖ Cache hit for THS (312 rows, 100% coverage)
  ‚úÖ Cache hit for THY (312 rows, 100% coverage)
  ‚úÖ Cache hit for TIGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TIGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for TILE (312 rows, 100% coverage)
  ‚úÖ Cache hit for TILT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TIMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for TIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for TIPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TIPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TIPZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for TITN (312 rows, 100% coverage)
  ‚úÖ Cache hit for TJX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TKC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TKNO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TKO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TKR (312 rows, 100% coverage)
  ‚úÖ Cache hit for TLH (312 rows, 100% coverage)
  ‚úÖ Cache hit for TLK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for TLRY (312 rows, 100% coverage)
  ‚úÖ Cache hit for TLS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TLSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for TLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TLTD (312 rows, 100% coverage)
  ‚úÖ Cache hit for TLTE (312 rows, 100% coverage)
  ‚úÖ Cache hit for TLTW (312 rows, 100% coverage)
  ‚úÖ Cache hit for TLYS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TM (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMDX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TME (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMF (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMFM (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMHC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMP (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TMV (312 rows, 100% coverage)
  ‚úÖ Cache hit for TNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for TNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TNDM (312 rows, 100% coverage)
  ‚úÖ Cache hit for TNET (312 rows, 100% coverage)
  ‚úÖ Cache hit for TNGX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TNK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TNL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TNYA (312 rows, 100% coverage)
  ‚úÖ Cache hit for TOK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TOL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TOLZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for TONX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TORO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TOST (312 rows, 100% coverage)
  ‚úÖ Cache hit for TOTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TOTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for TOWN (312 rows, 100% coverage)
  ‚úÖ Cache hit for TOYO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TPB (312 rows, 100% coverage)
  ‚úÖ Cache hit for TPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TPG (312 rows, 100% coverage)
  ‚úÖ Cache hit for TPH (312 rows, 100% coverage)
  ‚úÖ Cache hit for TPHD (312 rows, 100% coverage)
  ‚úÖ Cache hit for TPIF (312 rows, 100% coverage)
  ‚úÖ Cache hit for TPL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TPLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for TPSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TPVG (312 rows, 100% coverage)
  ‚úÖ Cache hit for TPYP (312 rows, 100% coverage)
  ‚úÖ Cache hit for TQQQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for TR (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRAK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRDA (312 rows, 100% coverage)
  ‚úÖ Cache hit for TREE (312 rows, 100% coverage)
  ‚úÖ Cache hit for TREX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRGP (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRI (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRMK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRN (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRND (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRNO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRNR (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRNS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TROW (312 rows, 100% coverage)
  ‚úÖ Cache hit for TROX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRP (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRPA (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRST (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRU (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRUE (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRUP (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRV (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRVG (312 rows, 100% coverage)
  ‚úÖ Cache hit for TRVI (312 rows, 100% coverage)
  ‚úÖ Cache hit for TS (312 rows, 100% coverage)
  ‚úÖ Cache hit for TSAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TSCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TSE (312 rows, 100% coverage)
  ‚úÖ Cache hit for TSEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for TSLA (312 rows, 100% coverage)
  ‚úÖ Cache hit for TSLL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TSLX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for TSN (312 rows, 100% coverage)
  ‚úÖ Cache hit for TSPA (312 rows, 100% coverage)
  ‚úÖ Cache hit for TSSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for TT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TTAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for TTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TTD (312 rows, 100% coverage)
  ‚úÖ Cache hit for TTEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for TTEK (312 rows, 100% coverage)
  ‚úÖ Cache hit for TTGT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for TTMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for TTWO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TU (312 rows, 100% coverage)
  ‚úÖ Cache hit for TUA (312 rows, 100% coverage)
  ‚úÖ Cache hit for TUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for TUR (312 rows, 100% coverage)
  ‚úÖ Cache hit for TUYA (312 rows, 100% coverage)
  ‚úÖ Cache hit for TV (312 rows, 100% coverage)
  ‚úÖ Cache hit for TVTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TW (312 rows, 100% coverage)
  ‚úÖ Cache hit for TWFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for TWI (312 rows, 100% coverage)
  ‚úÖ Cache hit for TWLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TWO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TWST (312 rows, 100% coverage)
  ‚úÖ Cache hit for TX (312 rows, 100% coverage)
  ‚úÖ Cache hit for TXG (312 rows, 100% coverage)
  ‚úÖ Cache hit for TXMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for TXN (312 rows, 100% coverage)
  ‚úÖ Cache hit for TXNM (312 rows, 100% coverage)
  ‚úÖ Cache hit for TXO (312 rows, 100% coverage)
  ‚úÖ Cache hit for TXRH (312 rows, 100% coverage)
  ‚úÖ Cache hit for TXT (312 rows, 100% coverage)
  ‚úÖ Cache hit for TY (312 rows, 100% coverage)
  ‚úÖ Cache hit for TYD (312 rows, 100% coverage)
  ‚úÖ Cache hit for TYL (312 rows, 100% coverage)
  ‚úÖ Cache hit for TYRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for TZA (312 rows, 100% coverage)
  ‚úÖ Cache hit for U (312 rows, 100% coverage)
  ‚úÖ Cache hit for UA (312 rows, 100% coverage)
  ‚úÖ Cache hit for UAA (312 rows, 100% coverage)
  ‚úÖ Cache hit for UAE (312 rows, 100% coverage)
  ‚úÖ Cache hit for UAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for UAMY (312 rows, 100% coverage)
  ‚úÖ Cache hit for UAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for UAPR (312 rows, 100% coverage)
  ‚úÖ Cache hit for UAUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for UBER (312 rows, 100% coverage)
  ‚úÖ Cache hit for UBND (312 rows, 100% coverage)
  ‚úÖ Cache hit for UBOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for UBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for UBSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for UBT (312 rows, 100% coverage)
  ‚úÖ Cache hit for UCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for UCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for UCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for UCON (312 rows, 100% coverage)
  ‚úÖ Cache hit for UCRD (312 rows, 100% coverage)
  ‚úÖ Cache hit for UCTT (312 rows, 100% coverage)
  ‚úÖ Cache hit for UDMY (312 rows, 100% coverage)
  ‚úÖ Cache hit for UDN (312 rows, 100% coverage)
  ‚úÖ Cache hit for UDOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for UDR (312 rows, 100% coverage)
  ‚úÖ Cache hit for UE (312 rows, 100% coverage)
  ‚úÖ Cache hit for UEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for UEIC (312 rows, 100% coverage)
  ‚úÖ Cache hit for UEVM (312 rows, 100% coverage)
  ‚úÖ Cache hit for UFCS (312 rows, 100% coverage)
  ‚úÖ Cache hit for UFI (312 rows, 100% coverage)
  ‚úÖ Cache hit for UFO (312 rows, 100% coverage)
  ‚úÖ Cache hit for UFPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for UFPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for UGA (312 rows, 100% coverage)
  ‚úÖ Cache hit for UGE (312 rows, 100% coverage)
  ‚úÖ Cache hit for UGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for UGL (312 rows, 100% coverage)
  ‚úÖ Cache hit for UGP (312 rows, 100% coverage)
  ‚úÖ Cache hit for UGRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for UHAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for UHS (312 rows, 100% coverage)
  ‚úÖ Cache hit for UHT (312 rows, 100% coverage)
  ‚úÖ Cache hit for UI (312 rows, 100% coverage)
  ‚úÖ Cache hit for UIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for UITB (312 rows, 100% coverage)
  ‚úÖ Cache hit for UIVM (312 rows, 100% coverage)
  ‚úÖ Cache hit for UJAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for UJB (312 rows, 100% coverage)
  ‚úÖ Cache hit for UK (312 rows, 100% coverage)
  ‚úÖ Cache hit for UL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ULCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ULH (312 rows, 100% coverage)
  ‚úÖ Cache hit for ULS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ULST (312 rows, 100% coverage)
  ‚úÖ Cache hit for ULTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ULVM (312 rows, 100% coverage)
  ‚úÖ Cache hit for UMAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for UMBF (312 rows, 100% coverage)
  ‚úÖ Cache hit for UMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for UMDD (312 rows, 100% coverage)
  ‚úÖ Cache hit for UMH (312 rows, 100% coverage)
  ‚úÖ Cache hit for UMMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for UNB (312 rows, 100% coverage)
  ‚úÖ Cache hit for UNF (312 rows, 100% coverage)
  ‚úÖ Cache hit for UNFI (312 rows, 100% coverage)
  ‚úÖ Cache hit for UNG (312 rows, 100% coverage)
  ‚úÖ Cache hit for UNH (312 rows, 100% coverage)
  ‚úÖ Cache hit for UNIY (312 rows, 100% coverage)
  ‚úÖ Cache hit for UNL (312 rows, 100% coverage)
  ‚úÖ Cache hit for UNM (312 rows, 100% coverage)
  ‚úÖ Cache hit for UNP (312 rows, 100% coverage)
  ‚úÖ Cache hit for UNTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for UP (312 rows, 100% coverage)
  ‚úÖ Cache hit for UPB (312 rows, 100% coverage)
  ‚úÖ Cache hit for UPBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for UPGD (312 rows, 100% coverage)
  ‚úÖ Cache hit for UPLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for UPRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for UPS (312 rows, 100% coverage)
  ‚úÖ Cache hit for UPST (312 rows, 100% coverage)
  ‚úÖ Cache hit for UPV (312 rows, 100% coverage)
  ‚úÖ Cache hit for UPW (312 rows, 100% coverage)
  ‚úÖ Cache hit for UPWK (312 rows, 100% coverage)
  ‚úÖ Cache hit for UPXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for URA (312 rows, 100% coverage)
  ‚úÖ Cache hit for URBN (312 rows, 100% coverage)
  ‚úÖ Cache hit for URE (312 rows, 100% coverage)
  ‚úÖ Cache hit for URGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for URI (312 rows, 100% coverage)
  ‚úÖ Cache hit for URNJ (312 rows, 100% coverage)
  ‚úÖ Cache hit for URNM (312 rows, 100% coverage)
  ‚úÖ Cache hit for UROY (312 rows, 100% coverage)
  ‚úÖ Cache hit for URTH (312 rows, 100% coverage)
  ‚úÖ Cache hit for URTY (312 rows, 100% coverage)
  ‚úÖ Cache hit for USA (312 rows, 100% coverage)
  ‚úÖ Cache hit for USAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for USB (312 rows, 100% coverage)
  ‚úÖ Cache hit for USCB (312 rows, 100% coverage)
  ‚úÖ Cache hit for USCI (312 rows, 100% coverage)
  ‚úÖ Cache hit for USCL (312 rows, 100% coverage)
  ‚úÖ Cache hit for USD (312 rows, 100% coverage)
  ‚úÖ Cache hit for USDU (312 rows, 100% coverage)
  ‚úÖ Cache hit for USFD (312 rows, 100% coverage)
  ‚úÖ Cache hit for USFR (312 rows, 100% coverage)
  ‚úÖ Cache hit for USHY (312 rows, 100% coverage)
  ‚úÖ Cache hit for USIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for USL (312 rows, 100% coverage)
  ‚úÖ Cache hit for USLM (312 rows, 100% coverage)
  ‚úÖ Cache hit for USMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for USMF (312 rows, 100% coverage)
  ‚úÖ Cache hit for USMV (312 rows, 100% coverage)
  ‚úÖ Cache hit for USNA (312 rows, 100% coverage)
  ‚úÖ Cache hit for USO (312 rows, 100% coverage)
  ‚úÖ Cache hit for USOI (312 rows, 100% coverage)
  ‚úÖ Cache hit for USPH (312 rows, 100% coverage)
  ‚úÖ Cache hit for USPX (312 rows, 100% coverage)
  ‚úÖ Cache hit for USRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for USSE (312 rows, 100% coverage)
  ‚úÖ Cache hit for USSG (312 rows, 100% coverage)
  ‚úÖ Cache hit for UST (312 rows, 100% coverage)
  ‚úÖ Cache hit for USTB (312 rows, 100% coverage)
  ‚úÖ Cache hit for USVM (312 rows, 100% coverage)
  ‚úÖ Cache hit for USXF (312 rows, 100% coverage)
  ‚úÖ Cache hit for UTEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for UTHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for UTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for UTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for UTMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for UTSI (312 rows, 100% coverage)
  ‚úÖ Cache hit for UTWO (312 rows, 100% coverage)
  ‚úÖ Cache hit for UTZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for UUP (312 rows, 100% coverage)
  ‚úÖ Cache hit for UUUU (312 rows, 100% coverage)
  ‚úÖ Cache hit for UVE (312 rows, 100% coverage)
  ‚úÖ Cache hit for UVIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for UVSP (312 rows, 100% coverage)
  ‚úÖ Cache hit for UVV (312 rows, 100% coverage)
  ‚úÖ Cache hit for UVXY (312 rows, 100% coverage)
  ‚úÖ Cache hit for UWM (312 rows, 100% coverage)
  ‚úÖ Cache hit for UWMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for UXI (312 rows, 100% coverage)
  ‚úÖ Cache hit for UXIN (312 rows, 100% coverage)
  ‚úÖ Cache hit for UYM (312 rows, 100% coverage)
  ‚úÖ Cache hit for V (312 rows, 100% coverage)
  ‚úÖ Cache hit for VAC (312 rows, 100% coverage)
  ‚úÖ Cache hit for VACH (312 rows, 100% coverage)
  ‚úÖ Cache hit for VAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for VALE (312 rows, 100% coverage)
  ‚úÖ Cache hit for VALN (312 rows, 100% coverage)
  ‚úÖ Cache hit for VALQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for VAW (312 rows, 100% coverage)
  ‚úÖ Cache hit for VB (312 rows, 100% coverage)
  ‚úÖ Cache hit for VBK (312 rows, 100% coverage)
  ‚úÖ Cache hit for VBND (312 rows, 100% coverage)
  ‚úÖ Cache hit for VBNK (312 rows, 100% coverage)
  ‚úÖ Cache hit for VBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for VC (312 rows, 100% coverage)
  ‚úÖ Cache hit for VCEB (312 rows, 100% coverage)
  ‚úÖ Cache hit for VCEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for VCIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VCLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VCR (312 rows, 100% coverage)
  ‚úÖ Cache hit for VCSH (312 rows, 100% coverage)
  ‚úÖ Cache hit for VCTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for VCYT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for VDE (312 rows, 100% coverage)
  ‚úÖ Cache hit for VEA (312 rows, 100% coverage)
  ‚úÖ Cache hit for VECO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VEEV (312 rows, 100% coverage)
  ‚úÖ Cache hit for VEGA (312 rows, 100% coverage)
  ‚úÖ Cache hit for VEGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for VEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for VELO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VEON (312 rows, 100% coverage)
  ‚úÖ Cache hit for VERA (312 rows, 100% coverage)
  ‚úÖ Cache hit for VERI (312 rows, 100% coverage)
  ‚úÖ Cache hit for VERU (312 rows, 100% coverage)
  ‚úÖ Cache hit for VERX (312 rows, 100% coverage)
  ‚úÖ Cache hit for VET (312 rows, 100% coverage)
  ‚úÖ Cache hit for VEU (312 rows, 100% coverage)
  ‚úÖ Cache hit for VFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for VFH (312 rows, 100% coverage)
  ‚úÖ Cache hit for VFLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VFMF (312 rows, 100% coverage)
  ‚úÖ Cache hit for VFMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VFMV (312 rows, 100% coverage)
  ‚úÖ Cache hit for VFQY (312 rows, 100% coverage)
  ‚úÖ Cache hit for VFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VFVA (312 rows, 100% coverage)
  ‚úÖ Cache hit for VGIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VGK (312 rows, 100% coverage)
  ‚úÖ Cache hit for VGLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VGSH (312 rows, 100% coverage)
  ‚úÖ Cache hit for VGT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VHI (312 rows, 100% coverage)
  ‚úÖ Cache hit for VHT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIAV (312 rows, 100% coverage)
  ‚úÖ Cache hit for VICI (312 rows, 100% coverage)
  ‚úÖ Cache hit for VICR (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIDI (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIK (312 rows, 100% coverage)
  ‚úÖ Cache hit for VINP (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIOO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIPS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIR (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIST (312 rows, 100% coverage)
  ‚úÖ Cache hit for VITL (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIVS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIXM (312 rows, 100% coverage)
  ‚úÖ Cache hit for VIXY (312 rows, 100% coverage)
  ‚úÖ Cache hit for VKTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for VLGEA (312 rows, 100% coverage)
  ‚úÖ Cache hit for VLN (312 rows, 100% coverage)
  ‚úÖ Cache hit for VLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VLRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VLTO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VLU (312 rows, 100% coverage)
  ‚úÖ Cache hit for VLUE (312 rows, 100% coverage)
  ‚úÖ Cache hit for VLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for VMBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for VMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for VMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for VNDA (312 rows, 100% coverage)
  ‚úÖ Cache hit for VNET (312 rows, 100% coverage)
  ‚úÖ Cache hit for VNLA (312 rows, 100% coverage)
  ‚úÖ Cache hit for VNM (312 rows, 100% coverage)
  ‚úÖ Cache hit for VNO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VNOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for VNQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for VNQI (312 rows, 100% coverage)
  ‚úÖ Cache hit for VNT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VOD (312 rows, 100% coverage)
  ‚úÖ Cache hit for VOE (312 rows, 100% coverage)
  ‚úÖ Cache hit for VONE (312 rows, 100% coverage)
  ‚úÖ Cache hit for VONG (312 rows, 100% coverage)
  ‚úÖ Cache hit for VONV (312 rows, 100% coverage)
  ‚úÖ Cache hit for VOO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VOOG (312 rows, 100% coverage)
  ‚úÖ Cache hit for VOOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for VOT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VOTE (312 rows, 100% coverage)
  ‚úÖ Cache hit for VOX (312 rows, 100% coverage)
  ‚úÖ Cache hit for VOYA (312 rows, 100% coverage)
  ‚úÖ Cache hit for VPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for VPG (312 rows, 100% coverage)
  ‚úÖ Cache hit for VPL (312 rows, 100% coverage)
  ‚úÖ Cache hit for VPU (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRDN (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for VREX (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRIG (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRNS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRP (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRRM (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRSK (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRSN (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VRTX (312 rows, 100% coverage)
  ‚úÖ Cache hit for VS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VSAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VSCO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VSDA (312 rows, 100% coverage)
  ‚úÖ Cache hit for VSEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for VSGX (312 rows, 100% coverage)
  ‚úÖ Cache hit for VSH (312 rows, 100% coverage)
  ‚úÖ Cache hit for VSLU (312 rows, 100% coverage)
  ‚úÖ Cache hit for VSMV (312 rows, 100% coverage)
  ‚úÖ Cache hit for VSS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VST (312 rows, 100% coverage)
  ‚úÖ Cache hit for VSTA (312 rows, 100% coverage)
  ‚úÖ Cache hit for VSTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VT (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTEB (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTMX (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTOL (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTRS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTV (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTWG (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTWO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTWV (312 rows, 100% coverage)
  ‚úÖ Cache hit for VTYX (312 rows, 100% coverage)
  ‚úÖ Cache hit for VUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for VUSB (312 rows, 100% coverage)
  ‚úÖ Cache hit for VUSE (312 rows, 100% coverage)
  ‚úÖ Cache hit for VUZI (312 rows, 100% coverage)
  ‚úÖ Cache hit for VV (312 rows, 100% coverage)
  ‚úÖ Cache hit for VVOS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VVV (312 rows, 100% coverage)
  ‚úÖ Cache hit for VVX (312 rows, 100% coverage)
  ‚úÖ Cache hit for VWO (312 rows, 100% coverage)
  ‚úÖ Cache hit for VWOB (312 rows, 100% coverage)
  ‚úÖ Cache hit for VXF (312 rows, 100% coverage)
  ‚úÖ Cache hit for VXUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for VXX (312 rows, 100% coverage)
  ‚úÖ Cache hit for VYGR (312 rows, 100% coverage)
  ‚úÖ Cache hit for VYM (312 rows, 100% coverage)
  ‚úÖ Cache hit for VYMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for VYX (312 rows, 100% coverage)
  ‚úÖ Cache hit for VZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for W (312 rows, 100% coverage)
  ‚úÖ Cache hit for WAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for WABC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WAFD (312 rows, 100% coverage)
  ‚úÖ Cache hit for WAL (312 rows, 100% coverage)
  ‚úÖ Cache hit for WALD (312 rows, 100% coverage)
  ‚úÖ Cache hit for WANT (312 rows, 100% coverage)
  ‚úÖ Cache hit for WASH (312 rows, 100% coverage)
  ‚úÖ Cache hit for WAT (312 rows, 100% coverage)
  ‚úÖ Cache hit for WAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for WB (312 rows, 100% coverage)
  ‚úÖ Cache hit for WBD (312 rows, 100% coverage)
  ‚úÖ Cache hit for WBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for WBTN (312 rows, 100% coverage)
  ‚úÖ Cache hit for WBX (312 rows, 100% coverage)
  ‚úÖ Cache hit for WCBR (312 rows, 100% coverage)
  ‚úÖ Cache hit for WCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WCLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for WCN (312 rows, 100% coverage)
  ‚úÖ Cache hit for WD (312 rows, 100% coverage)
  ‚úÖ Cache hit for WDAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for WDC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WDFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WDIV (312 rows, 100% coverage)
  ‚úÖ Cache hit for WDS (312 rows, 100% coverage)
  ‚úÖ Cache hit for WDTE (312 rows, 100% coverage)
  ‚úÖ Cache hit for WEAV (312 rows, 100% coverage)
  ‚úÖ Cache hit for WEBL (312 rows, 100% coverage)
  ‚úÖ Cache hit for WEBS (312 rows, 100% coverage)
  ‚úÖ Cache hit for WEC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WELL (312 rows, 100% coverage)
  ‚úÖ Cache hit for WEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for WERN (312 rows, 100% coverage)
  ‚úÖ Cache hit for WES (312 rows, 100% coverage)
  ‚úÖ Cache hit for WEST (312 rows, 100% coverage)
  ‚úÖ Cache hit for WEX (312 rows, 100% coverage)
  ‚úÖ Cache hit for WF (312 rows, 100% coverage)
  ‚úÖ Cache hit for WFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WFG (312 rows, 100% coverage)
  ‚úÖ Cache hit for WFRD (312 rows, 100% coverage)
  ‚úÖ Cache hit for WGMI (312 rows, 100% coverage)
  ‚úÖ Cache hit for WGO (312 rows, 100% coverage)
  ‚úÖ Cache hit for WGS (312 rows, 100% coverage)
  ‚úÖ Cache hit for WH (312 rows, 100% coverage)
  ‚úÖ Cache hit for WHD (312 rows, 100% coverage)
  ‚úÖ Cache hit for WHLR (312 rows, 100% coverage)
  ‚úÖ Cache hit for WHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for WHWK (312 rows, 100% coverage)
  ‚úÖ Cache hit for WINA (312 rows, 100% coverage)
  ‚úÖ Cache hit for WING (312 rows, 100% coverage)
  ‚úÖ Cache hit for WINN (312 rows, 100% coverage)
  ‚úÖ Cache hit for WIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for WIT (312 rows, 100% coverage)
  ‚úÖ Cache hit for WIX (312 rows, 100% coverage)
  ‚úÖ Cache hit for WK (312 rows, 100% coverage)
  ‚úÖ Cache hit for WKC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WLDN (312 rows, 100% coverage)
  ‚úÖ Cache hit for WLDR (312 rows, 100% coverage)
  ‚úÖ Cache hit for WLFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WLK (312 rows, 100% coverage)
  ‚úÖ Cache hit for WLKP (312 rows, 100% coverage)
  ‚úÖ Cache hit for WLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for WM (312 rows, 100% coverage)
  ‚úÖ Cache hit for WMB (312 rows, 100% coverage)
  ‚úÖ Cache hit for WMG (312 rows, 100% coverage)
  ‚úÖ Cache hit for WMK (312 rows, 100% coverage)
  ‚úÖ Cache hit for WMS (312 rows, 100% coverage)
  ‚úÖ Cache hit for WMT (312 rows, 100% coverage)
  ‚úÖ Cache hit for WNC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WOLF (312 rows, 100% coverage)
  ‚úÖ Cache hit for WOOD (312 rows, 100% coverage)
  ‚úÖ Cache hit for WOOF (312 rows, 100% coverage)
  ‚úÖ Cache hit for WOR (312 rows, 100% coverage)
  ‚úÖ Cache hit for WOW (312 rows, 100% coverage)
  ‚úÖ Cache hit for WPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WPM (312 rows, 100% coverage)
  ‚úÖ Cache hit for WPP (312 rows, 100% coverage)
  ‚úÖ Cache hit for WRAP (312 rows, 100% coverage)
  ‚úÖ Cache hit for WRB (312 rows, 100% coverage)
  ‚úÖ Cache hit for WRBY (312 rows, 100% coverage)
  ‚úÖ Cache hit for WRD (312 rows, 100% coverage)
  ‚úÖ Cache hit for WRLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for WS (312 rows, 100% coverage)
  ‚úÖ Cache hit for WSBC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WSBF (312 rows, 100% coverage)
  ‚úÖ Cache hit for WSC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WSFS (312 rows, 100% coverage)
  ‚úÖ Cache hit for WSM (312 rows, 100% coverage)
  ‚úÖ Cache hit for WSO (312 rows, 100% coverage)
  ‚úÖ Cache hit for WSR (312 rows, 100% coverage)
  ‚úÖ Cache hit for WST (312 rows, 100% coverage)
  ‚úÖ Cache hit for WT (312 rows, 100% coverage)
  ‚úÖ Cache hit for WTBA (312 rows, 100% coverage)
  ‚úÖ Cache hit for WTFC (312 rows, 100% coverage)
  ‚úÖ Cache hit for WTI (312 rows, 100% coverage)
  ‚úÖ Cache hit for WTM (312 rows, 100% coverage)
  ‚úÖ Cache hit for WTMF (312 rows, 100% coverage)
  ‚úÖ Cache hit for WTPI (312 rows, 100% coverage)
  ‚úÖ Cache hit for WTRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for WTRG (312 rows, 100% coverage)
  ‚úÖ Cache hit for WTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for WTTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for WTV (312 rows, 100% coverage)
  ‚úÖ Cache hit for WTW (312 rows, 100% coverage)
  ‚úÖ Cache hit for WU (312 rows, 100% coverage)
  ‚úÖ Cache hit for WUGI (312 rows, 100% coverage)
  ‚úÖ Cache hit for WULF (312 rows, 100% coverage)
  ‚úÖ Cache hit for WVE (312 rows, 100% coverage)
  ‚úÖ Cache hit for WWD (312 rows, 100% coverage)
  ‚úÖ Cache hit for WWJD (312 rows, 100% coverage)
  ‚úÖ Cache hit for WWW (312 rows, 100% coverage)
  ‚úÖ Cache hit for WY (312 rows, 100% coverage)
  ‚úÖ Cache hit for WYNN (312 rows, 100% coverage)
  ‚úÖ Cache hit for XAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for XBI (312 rows, 100% coverage)
  ‚úÖ Cache hit for XBIL (312 rows, 100% coverage)
  ‚úÖ Cache hit for XCCC (312 rows, 100% coverage)
  ‚úÖ Cache hit for XCEM (312 rows, 100% coverage)
  ‚úÖ Cache hit for XDTE (312 rows, 100% coverage)
  ‚úÖ Cache hit for XEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for XEMD (312 rows, 100% coverage)
  ‚úÖ Cache hit for XENE (312 rows, 100% coverage)
  ‚úÖ Cache hit for XERS (312 rows, 100% coverage)
  ‚úÖ Cache hit for XES (312 rows, 100% coverage)
  ‚úÖ Cache hit for XFLT (312 rows, 100% coverage)
  ‚úÖ Cache hit for XHB (312 rows, 100% coverage)
  ‚úÖ Cache hit for XHE (312 rows, 100% coverage)
  ‚úÖ Cache hit for XHLF (312 rows, 100% coverage)
  ‚úÖ Cache hit for XHR (312 rows, 100% coverage)
  ‚úÖ Cache hit for XHS (312 rows, 100% coverage)
  ‚úÖ Cache hit for XIFR (312 rows, 100% coverage)
  ‚úÖ Cache hit for XITK (312 rows, 100% coverage)
  ‚úÖ Cache hit for XJH (312 rows, 100% coverage)
  ‚úÖ Cache hit for XJUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLB (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLC (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLE (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLF (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLG (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLI (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLK (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLP (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLRE (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLSR (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLU (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for XLY (312 rows, 100% coverage)
  ‚úÖ Cache hit for XMAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for XME (312 rows, 100% coverage)
  ‚úÖ Cache hit for XMHQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for XMLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for XMMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for XMPT (312 rows, 100% coverage)
  ‚úÖ Cache hit for XMTR (312 rows, 100% coverage)
  ‚úÖ Cache hit for XMVM (312 rows, 100% coverage)
  ‚úÖ Cache hit for XNCR (312 rows, 100% coverage)
  ‚úÖ Cache hit for XNTK (312 rows, 100% coverage)
  ‚úÖ Cache hit for XOM (312 rows, 100% coverage)
  ‚úÖ Cache hit for XOMA (312 rows, 100% coverage)
  ‚úÖ Cache hit for XOP (312 rows, 100% coverage)
  ‚úÖ Cache hit for XP (312 rows, 100% coverage)
  ‚úÖ Cache hit for XPEL (312 rows, 100% coverage)
  ‚úÖ Cache hit for XPER (312 rows, 100% coverage)
  ‚úÖ Cache hit for XPEV (312 rows, 100% coverage)
  ‚úÖ Cache hit for XPH (312 rows, 100% coverage)
  ‚úÖ Cache hit for XPO (312 rows, 100% coverage)
  ‚úÖ Cache hit for XPOF (312 rows, 100% coverage)
  ‚úÖ Cache hit for XPON (312 rows, 100% coverage)
  ‚úÖ Cache hit for XPP (312 rows, 100% coverage)
  ‚úÖ Cache hit for XPRO (312 rows, 100% coverage)
  ‚úÖ Cache hit for XRAY (312 rows, 100% coverage)
  ‚úÖ Cache hit for XRT (312 rows, 100% coverage)
  ‚úÖ Cache hit for XRX (312 rows, 100% coverage)
  ‚úÖ Cache hit for XSD (312 rows, 100% coverage)
  ‚úÖ Cache hit for XSHQ (312 rows, 100% coverage)
  ‚úÖ Cache hit for XSLV (312 rows, 100% coverage)
  ‚úÖ Cache hit for XSMO (312 rows, 100% coverage)
  ‚úÖ Cache hit for XSOE (312 rows, 100% coverage)
  ‚úÖ Cache hit for XSVM (312 rows, 100% coverage)
  ‚úÖ Cache hit for XSVN (312 rows, 100% coverage)
  ‚úÖ Cache hit for XSW (312 rows, 100% coverage)
  ‚úÖ Cache hit for XT (312 rows, 100% coverage)
  ‚úÖ Cache hit for XTEN (312 rows, 100% coverage)
  ‚úÖ Cache hit for XTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for XTN (312 rows, 100% coverage)
  ‚úÖ Cache hit for XTWO (312 rows, 100% coverage)
  ‚úÖ Cache hit for XVV (312 rows, 100% coverage)
  ‚úÖ Cache hit for XYF (312 rows, 100% coverage)
  ‚úÖ Cache hit for XYL (312 rows, 100% coverage)
  ‚úÖ Cache hit for XYLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for XYLG (312 rows, 100% coverage)
  ‚úÖ Cache hit for XYZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for YALA (312 rows, 100% coverage)
  ‚úÖ Cache hit for YANG (312 rows, 100% coverage)
  ‚úÖ Cache hit for YBTC (312 rows, 100% coverage)
  ‚úÖ Cache hit for YCL (312 rows, 100% coverage)
  ‚úÖ Cache hit for YCS (312 rows, 100% coverage)
  ‚úÖ Cache hit for YEAR (312 rows, 100% coverage)
  ‚úÖ Cache hit for YELP (312 rows, 100% coverage)
  ‚úÖ Cache hit for YETI (312 rows, 100% coverage)
  ‚úÖ Cache hit for YEXT (312 rows, 100% coverage)
  ‚úÖ Cache hit for YINN (312 rows, 100% coverage)
  ‚úÖ Cache hit for YJUN (312 rows, 100% coverage)
  ‚úÖ Cache hit for YLD (312 rows, 100% coverage)
  ‚úÖ Cache hit for YMAG (312 rows, 100% coverage)
  ‚úÖ Cache hit for YMAX (312 rows, 100% coverage)
  ‚úÖ Cache hit for YMM (312 rows, 100% coverage)
  ‚úÖ Cache hit for YOLO (312 rows, 100% coverage)
  ‚úÖ Cache hit for YORW (312 rows, 100% coverage)
  ‚úÖ Cache hit for YOU (312 rows, 100% coverage)
  ‚úÖ Cache hit for YPF (312 rows, 100% coverage)
  ‚úÖ Cache hit for YRD (312 rows, 100% coverage)
  ‚úÖ Cache hit for YSG (312 rows, 100% coverage)
  ‚úÖ Cache hit for YUM (312 rows, 100% coverage)
  ‚úÖ Cache hit for YUMC (312 rows, 100% coverage)
  ‚úÖ Cache hit for YYAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for YYY (312 rows, 100% coverage)
  ‚úÖ Cache hit for Z (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZALT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZAUG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZBAI (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZBH (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZBIO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZBRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZD (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZDEK (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZECP (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZETA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZEUS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZFEB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZG (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZGN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZH (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZIM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZION (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZIONP (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZIP (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZJAN (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZJK (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZJUL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZKH (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZLAB (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZM (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZNOV (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZNTL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZOCT (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZROZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZSEP (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZSL (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZSPC (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZTO (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZTS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZUMZ (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZVIA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZVRA (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZWS (312 rows, 100% coverage)
  ‚úÖ Cache hit for ZYME (312 rows, 100% coverage)
  üîÑ Downloading data for 2 tickers (2 full, 0 incremental)...
  üì• Downloading FULL range for 2 tickers...
  ‚úÖ Successfully downloaded full range for 2 tickers
      ‚ö†Ô∏è Cache append failed for QQQ, overwrote: Cannot compare tz-naive and tz-aware timestamps
      ‚ö†Ô∏è Cache append failed for SPY, overwrote: Cannot compare tz-naive and tz-aware timestamps

  üìä Data Summary for 5647 Tickers
  ===============================================================================================
  Ticker   Status          Rows     Start Date   End Date     Info                
  -----------------------------------------------------------------------------------------------
  A        Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AA       Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AAAU     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AAL      Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AAM      Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AAMI     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AAOI     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AAON     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AAP      Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AAPG     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AAPL     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AAT      Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AAXJ     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  AB       Cache Hit       312      2024-09-30   2025-12-26   From cache          
  ABBV     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  ABCB     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  ABCL     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  ABEO     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  ABEV     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  ABFL     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  ABG      Cache Hit       312      2024-09-30   2025-12-26   From cache          
  ABL      Cache Hit       312      2024-09-30   2025-12-26   From cache          
  ABM      Cache Hit       312      2024-09-30   2025-12-26   From cache          
  ABNB     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  ABOT     Cache Hit       312      2024-09-30   2025-12-26   From cache          
  ... and 5622 more tickers
  ===============================================================================================
  ‚úÖ All 5647 tickers loaded from cache (no downloads needed)

  üìä Combined data: 5647 cached + 1 fresh = 28245 total columns
üîÑ Converting data from wide format to long format...
   ‚úÖ Converted to long format: 1762488 rows, 5649 tickers
üîç Filtering out delisted stocks (no recent data)...
   ‚úÖ All 5649 tickers have recent data
‚úÖ Comprehensive data download complete.
‚ÑπÔ∏è Capping backtest end date from 2025-12-29 to last available data 2025-12-26
üìÖ Data available until: 2025-12-26
üìÖ Prediction horizon: 63 days
üìÖ Backtest will end: 2025-10-24 (ensuring 63 days of future data for validation)
üîç Fetching SPY data for Market Momentum feature...
  Updating SPY (+2 days)...
‚úÖ SPY Market Momentum data fetched and merged.
üîç Fetching intermarket data...
‚ö†Ô∏è Could not fetch intermarket data. Intermarket features will be 0.

üîç Validating data structure...
‚úÖ Data validation passed:
   - Shape: (1762488, 15)
   - Tickers: 5649
   - Date range: 2024-09-30 00:00:00+00:00 to 2025-12-26 00:00:00+00:00
   - Columns: ['date', 'ticker', 'Close', 'High', 'Low', 'Open', 'Volume', 'Market_Momentum_SPY', 'Intermarket_VIX_Index_Returns', 'Intermarket_DXY_Index_Returns', 'Intermarket_Gold_Futures_Returns', 'Intermarket_Oil_Futures_Returns', 'Intermarket_US10Y_Yield_Returns', 'Intermarket_Oil_Price_Returns', 'Intermarket_Gold_Price_Returns']

üîç Analyzing data quality for each ticker...
   üìä Fast validation for 5649 tickers...

   ‚úÖ Validation complete: 5649 OK, 0 insufficient, 0 empty
   üìä Overall data: 1762488 rows, 5649 tickers

üöÄ AI-Powered Momentum & Trend Strategy
==================================================

üîç Step 2: Identifying stocks outperforming market benchmarks...
  üìÖ Using performance data up to 2025-07-26 (purchase date) to avoid look-ahead bias
- Calculating 1-Year Performance Benchmarks...
  üîÑ Fetching data for QQQ using multi-provider fallback...
  ‚ÑπÔ∏è Alpaca (free tier) does not provide recent data for QQQ. Attempting fallback provider.
  ‚ÑπÔ∏è Alpaca fetch failed for QQQ. Trying TwelveData...
  ‚úÖ Successfully fetched data for QQQ from TwelveData.
  ‚úÖ QQQ 1-Year Performance: 22.33%
  üîÑ Fetching data for SPY using multi-provider fallback...
  ‚ÑπÔ∏è Alpaca (free tier) does not provide recent data for SPY. Attempting fallback provider.
  ‚ÑπÔ∏è Alpaca fetch failed for SPY. Trying TwelveData...
  ‚úÖ Successfully fetched data for SPY from TwelveData.
  ‚úÖ SPY 1-Year Performance: 17.02%
  üìà Using final 1-Year performance benchmark of 22.33%
üîç Calculating 1-Year performance from pre-fetched data...
...performance calculation complete.
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility

‚úÖ Selected top 5638 tickers based on 1-Year performance.
üîç Applying performance benchmarks for selected tickers in parallel...
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility

‚úÖ Found 1055 stocks that passed the performance benchmarks.
  üîç Screening 1055 strong performers for fundamental metrics in parallel...
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
  ‚úÖ Found 966 stocks passing the fundamental screens.

‚úÖ Identified 966 stocks for backtesting: OKLO, PRCH, LAES, RYM, AMPX, TMC, ARQQ, AEVA, QNTM, ABVX, KC, DAVE, SEZL, BMNR, IONQ, SRRK, HOOD, SMR, UAMY, PSIX, LEU, PLTR, OUST, BKSY, GRRR, TSSI, ASPI, RCAT, ACHR, NVTS, KOD, GRPN, CLS, CRDO, ROOT, BE, SLDP, SGHC, HIMS, ATAI, QURE, ZVIA, PGY, INOD, GRAL, CRNC, NNE, KOPN, CANG, APP, ONDS, SOFI, AKBA, MPU, RBRK, ALLT, ORLA, LX, SEI, ETON, KTOS, NAGE, QMCO, GEV, AMLX, SOUN, TTMI, SBET, AISP, OPFI, NET, LGCY, BITU, LMND, MSTR, NEXT, BITX, AS, CAR, SRAD, AGX, TPR, INVZ, CRCL, DPRO, EYE, ESLT, RDDT, OPRT, JFIN, CONL, HTZ, SBSW, GRNQ, PAYS, XYF, TRVG, AMBR, COIN, GOGO, SSRM, QSI, OSS, AAPG, GHRS, LUXE, EVEX, EOSE, MASS, AVXL, TESL, DOMO, DAO, FOA, ALNT, IREN, UPST, ASTS, AENT, TARK, IHS, APEI, NN, DOYU, APYX, LFMD, CTMX, GEO, DXPE, KEN, VNET, UI, TWLO, VVOS, ATOM, MGTX, RCL, EAT, WLDN, MESO, VS, DJTWW, DB, MIR, TSAT, TIGR, RBOT, METC, MSTY, ABCL, TBRG, LQDA, RIOT, MYRG, LIF, TLN, VUZI, UTI, AU, LINC, CVNA, AAOI, CCB, MGIC, HWM, CYD, IBKR, WGS, MNY, SPOT, CRK, JBL, BROS, CVAC, GHM, ARKW, STRL, BTCW, HODL, AXON, EZBC, BITB, BRRR, IBIT, FBTC, ARKB, BTCO, REAL, SAN, AMSC, SKE, DEFI, OM, UUUU, FRHC, TPB, GBTC, BBIO, ARKF, LASR, KEP, IRTC, HIMX, GDS, ETHZ, IESC, TME, PARR, APPS, VEON, XMTR, ATRO, FIX, LMB, CIB, TPC, ORGO, INDV, EXEL, PBI, ICCM, DASH, FUTU, TATT, CPS, TENX, BITO, NRG, CRS, ODC, PPTA, KGC, SNEX, CMPX, CTOS, DRS, NXT, TOST, REVG, HNRG, BLOK, MNMD, DNA, SLNO, YALA, JNUG, KD, NBP, MGNI, IVA, AVGO, CMP, AEHR, EVLV, HRTG, ODD, OMAB, UNFI, LLYVA, ZS, NIU, SE, VIK, CIFR, SHLD, CCJ, CRWD, SII, NFLX, HUT, LLYVK, API, VSEC, WEBL, DOUG, RYTM, LITE, CAKE, ARKX, LTM, AFRM, BCS, MPAA, SLI, CXW, ICL, LPLA, GDXU, GFI, WBD, CTRN, SENEA, CUK, MSB, VST, DLTR, TIGO, YBTC, APH, PCT, UFO, ZVRA, MRX, SMLR, ARKQ, ARKK, VRSN, WF, DAPP, PEGA, ORN, BITQ, CCL, NUGT, PRIM, IDCC, GTX, ITRN, APG, UAL, AEM, LUNR, HIPO, PRA, DAN, TGTX, AVPT, RDVT, VSTA, AAMI, ENVX, ASA, C, FNGO, FIVE, YPF, NWG, PW, UPXI, CD, ADTN, RL, SHOP, WPM, AAP, ZLAB, RRGB, GRND, BA, BBAR, BELFB, NGD, HTT, CAE, BTF, ATGE, GREK, LRN, AVAL, ESQ, OR, WFC, BBW, SCHW, MTZ, QTUM, ACAD, ROAD, HSBC, TGS, BTI, MFG, LFCR, WWD, DGP, CG, WOR, SGDM, BRNS, FHN, NFLY, URA, IDT, FINV, ECG, BWMN, PCRX, CTLP, IPI, FLEX, GS, WRBY, BB, UGI, CALM, OSIS, RMBS, CELH, UNTY, ESE, SYF, NTES, CHEF, CNM, SSP, CBRL, VIRT, KMDA, EME, CW, NTRS, CORT, TFPM, SUPV, DRD, ACMR, INBX, FSM, HUYA, OPLN, JOYY, MUFG, GILT, PFIX, MRP, AHR, SERV, SGDJ, IRS, UGL, TE, TTWO, SIL, FGM, NVDU, FDIG, SFM, NLR, JCI, EXK, BFC, NERD, ORCL, EPOL, SLM, LB, GE, OCS, TITN, MCK, CAH, GTES, LOMA, NVDL, KODK, PAYC, SANM, IZRL, EQT, CIEN, BK, OPY, ULS, IFS, COF, UEC, METCB, SXT, EIS, AG, ATLC, MRCY, FROG, LZ, PAY, TSM, NVDA, GOAU, LYG, GDXJ, ATRA, UAN, CRMD, NAMS, HGV, DEC, PLTM, PPLT, DLO, ATI, ESPO, VLN, AMPL, GILD, CTOR, TNL, PWR, EWO, PAAS, JBTM, SLVP, NPK, CENX, GRAB, MOS, CASY, XAR, NIC, QXO, STX, ETH, BKCH, OCUL, ETHW, ETHV, POET, EZET, RSI, FETH, PERI, TETH, ETHA, PTON, LAUR, WGMI, QETH, PLMR, BTSG, RING, LYV, HMY, FTI, USD, TEL, RJF, MAIN, DOCS, ATAT, BYRN, CX, UNM, EUFN, PLNT, CSV, TMV, MCB, UAE, PJT, HNST, MBI, EMR, ING, TMAT, VEEV, GTLS, VRT, TKO, PUK, SPNT, WT, DDS, IAI, PGNY, SGI, STN, ETHE, FAS, BAP, OLLI, NRGV, KLTR, MTW, DCO, TRMB, KT, FHI, GDX, BWXT, ETR, CGNT, SAH, FPX, TBPH, RBA, TCBX, CHAT, WWW, METV, BAM, PM, AVAV, OKTA, EFXT, FFIV, FAST, FBIO, GENI, LGND, IGIC, NGVC, HLF, MTA, GRMN, OSW, EMBJ, ROK, ISRA, FTNT, MEXX, FOX, TOYO, BBCP, CDE, WRLD, STRK, AX, IIIV, TR, BLX, CBNK, FOXA, LANV, BFH, BKNG, IAG, ELPC, LOUP, CFLT, FDD, GLXY, MEDP, ARLO, COCO, BYD, AEIS, AZZ, ECNS, USFD, OMF, MRUS, TXNM, XPP, EWP, WDC, PAC, T, ITA, QUAD, LENZ, PRLB, SHAK, FNGS, MTRX, MCRI, STVN, CNP, MIRM, CUBI, DXCM, RAMP, FWONK, CSCO, CTRI, RPRX, COLO, ULTA, FNV, GSAT, SKYW, TASK, DSP, STT, LIND, CME, AB, SEIC, WBS, PAHC, DAX, HERO, RTX, EWI, BMO, ECVT, EETH, EYPT, CMCM, NDAQ, OGIG, CEPU, PAR, LTL, THFF, SMMT, IMAX, SMCI, BGM, NG, FN, UFCS, NOTV, DG, SMFG, CCEP, MT, V, COMM, AGQ, GOLF, HCI, DTM, KBWB, APLD, NPKI, OSK, DDOG, VCTR, SFST, AGI, HAFC, FEP, WMB, ATEN, RZLT, AL, COR, ONC, NEU, YINN, RBC, PRDO, CSGS, EWS, FWONA, BKR, NMG, MKL, NTR, SONY, BETZ, DUOL, AWI, BEN, DAKT, DBD, NPO, VNM, NVDY, BMBL, NPCE, IVZ, SILJ, PPA, GL, XPO, DOCU, PBYI, WCC, EWG, FDN, DRTS, GLAD, FLUT, NTGR, AFK, WAY, DRI, ALV, SYBT, UBS, SHCO, FSCO, KMI, SPPP, OPPE, WELL, YMM, RDWR, BNT, EGAN, BN, SPMO, FMS, SKWD, BSVN, EWBC, PWRD, CIO, BBUC, FET, NGS, DIS, INTU, GVAL, PAX, ALTG, ITRI, ORLY, VALN, FFTY, R, EXPE, Z, EQH, TDY, OPEN, FDT, SAP, TEO, RELY, IAUM, GLDM, BAR, DK, BULZ, SGOL, EBAY, BSX, OUNZ, AAAU, KR, HACK, FINX, IAU, ASTE, CLSK, UROY, ARGT, GLD, CPER, CIBR, DCTH, BJ, FITE, ENVA, ZG, LNG, TARS, FER, KCE, SOCL, IGV, TBT, NTNX, IETC, ARTY, KALV, CTVA, SPWH, SIXG, OIS, ESAB, IYG, TS, PHYS, UPWK, VMI, YMAX, PRM, DE, GLTR, PBW, HLI, PIZ, FXI, MVBF, ETOR, NEM, CRBG, IDMO, GEOS, DBP, RIVN, SLVO, META, HWKN, GLW, ASLE, CLM, PODD, WUGI, RIGL, OZK, HEI-A, NTB, FSK, PSKY, NI, HDB, TG, TD, NBN, IDV, AMZY, NRIM, JTEK, AMZN, CFG, CRMT, DTST, NVMI, SNX, BRW, GNE, CHWY, WRB, IQM, HEI, TRMK, EVC, PAM, COWG, FDP, PSLV, MO, TQQQ, TRS, MTSI, WCBR, MAMA, FRSH, SOBO, GGAL, AXS, MASI, RSG, IRON, CPA, GEL, SIMO, GT, PEJ, FEDU, SPRY, CFR, CSGP, CPNG, UIVM, KEMQ, WTFC, FDTS, STEL, XITK, VSAT, EPR, SPOK, TRIP, IXG, PDLB, FTDR, QLD, HURN, CECO, WTS, ALG, CMPO, SMBK, AIT, FDNI, CDNS, BBSI, PCOR, FGD, UXI, FBNC, ONLN

üìÖ Backtest configured for 90 days (~3-Month)

üîç Step 3: Training AI models for 3-Month backtest...
    üìä OKLO 3- Training: Horizon=60d, Target=136.97% (B&H: 833.25%, Scale=0.164)
‚úÖ OKLO: Training data validated - 205 rows over 365 days
    üìä PRCH 3- Training: Horizon=60d, Target=127.28% (B&H: 774.27%, Scale=0.164)
‚úÖ PRCH: Training data validated - 205 rows over 365 days
    üìä LAES 3- Training: Horizon=60d, Target=107.60% (B&H: 654.55%, Scale=0.164)
‚úÖ LAES: Training data validated - 205 rows over 365 days
    üìä RYM 3- Training: Horizon=60d, Target=106.32% (B&H: 646.75%, Scale=0.164)
‚úÖ RYM: Training data validated - 205 rows over 365 days
    üìä AMPX 3- Training: Horizon=60d, Target=105.00% (B&H: 638.74%, Scale=0.164)
‚úÖ AMPX: Training data validated - 205 rows over 365 days
    üìä TMC 3- Training: Horizon=60d, Target=104.37% (B&H: 634.91%, Scale=0.164)
‚úÖ TMC: Training data validated - 205 rows over 365 days
    üìä ARQQ 3- Training: Horizon=60d, Target=94.10% (B&H: 572.46%, Scale=0.164)
‚úÖ ARQQ: Training data validated - 205 rows over 365 days
    üìä AEVA 3- Training: Horizon=60d, Target=90.94% (B&H: 553.19%, Scale=0.164)
‚úÖ AEVA: Training data validated - 205 rows over 365 days
    üìä QNTM 3- Training: Horizon=60d, Target=86.92% (B&H: 528.75%, Scale=0.164)
‚úÖ QNTM: Training data validated - 205 rows over 365 days
    üìä ABVX 3- Training: Horizon=60d, Target=78.44% (B&H: 477.17%, Scale=0.164)
‚úÖ ABVX: Training data validated - 205 rows over 365 days
    üìä KC 3- Training: Horizon=60d, Target=71.90% (B&H: 437.41%, Scale=0.164)
‚úÖ KC: Training data validated - 205 rows over 365 days
    üìä DAVE 3- Training: Horizon=60d, Target=70.20% (B&H: 427.05%, Scale=0.164)
‚úÖ DAVE: Training data validated - 205 rows over 365 days
    üìä SEZL 3- Training: Horizon=60d, Target=69.68% (B&H: 423.89%, Scale=0.164)
‚úÖ SEZL: Training data validated - 205 rows over 365 days
    üìä BMNR 3- Training: Horizon=60d, Target=67.98% (B&H: 413.55%, Scale=0.164)
  ‚ùå BMNR: Too many NaN values in Close price: 170 / 205 rows
   üí° Data quality issue - try different data source or date range
    üìä IONQ 3- Training: Horizon=60d, Target=64.76% (B&H: 393.94%, Scale=0.164)
‚úÖ IONQ: Training data validated - 205 rows over 365 days
    üìä SRRK 3- Training: Horizon=60d, Target=63.50% (B&H: 386.27%, Scale=0.164)
‚úÖ SRRK: Training data validated - 205 rows over 365 days
    üìä HOOD 3- Training: Horizon=60d, Target=57.16% (B&H: 347.69%, Scale=0.164)
‚úÖ HOOD: Training data validated - 205 rows over 365 days
    üìä SMR 3- Training: Horizon=60d, Target=56.91% (B&H: 346.20%, Scale=0.164)
‚úÖ SMR: Training data validated - 205 rows over 365 days
    üìä UAMY 3- Training: Horizon=60d, Target=56.02% (B&H: 340.79%, Scale=0.164)
‚úÖ UAMY: Training data validated - 205 rows over 365 days
    üìä PSIX 3- Training: Horizon=60d, Target=55.97% (B&H: 340.49%, Scale=0.164)
‚úÖ PSIX: Training data validated - 205 rows over 365 days
    üìä LEU 3- Training: Horizon=60d, Target=55.79% (B&H: 339.38%, Scale=0.164)
‚úÖ LEU: Training data validated - 205 rows over 365 days
    üìä PLTR 3- Training: Horizon=60d, Target=53.73% (B&H: 326.88%, Scale=0.164)
‚úÖ PLTR: Training data validated - 205 rows over 365 days
    üìä OUST 3- Training: Horizon=60d, Target=52.24% (B&H: 317.78%, Scale=0.164)
‚úÖ OUST: Training data validated - 205 rows over 365 days
    üìä BKSY 3- Training: Horizon=60d, Target=52.16% (B&H: 317.30%, Scale=0.164)
‚úÖ BKSY: Training data validated - 205 rows over 365 days
    üìä GRRR 3- Training: Horizon=60d, Target=51.64% (B&H: 314.14%, Scale=0.164)
‚úÖ GRRR: Training data validated - 205 rows over 365 days
    üìä TSSI 3- Training: Horizon=60d, Target=50.31% (B&H: 306.03%, Scale=0.164)
‚úÖ TSSI: Training data validated - 205 rows over 365 days
    üìä ASPI 3- Training: Horizon=60d, Target=45.47% (B&H: 276.62%, Scale=0.164)
‚úÖ ASPI: Training data validated - 205 rows over 365 days
    üìä RCAT 3- Training: Horizon=60d, Target=44.78% (B&H: 272.44%, Scale=0.164)
‚úÖ RCAT: Training data validated - 205 rows over 365 days
    üìä ACHR 3- Training: Horizon=60d, Target=44.38% (B&H: 269.97%, Scale=0.164)
‚úÖ ACHR: Training data validated - 205 rows over 365 days
    üìä NVTS 3- Training: Horizon=60d, Target=42.54% (B&H: 258.78%, Scale=0.164)
‚úÖ NVTS: Training data validated - 205 rows over 365 days
    üìä KOD 3- Training: Horizon=60d, Target=39.24% (B&H: 238.70%, Scale=0.164)
‚úÖ KOD: Training data validated - 205 rows over 365 days
    üìä GRPN 3- Training: Horizon=60d, Target=38.94% (B&H: 236.91%, Scale=0.164)
‚úÖ GRPN: Training data validated - 205 rows over 365 days
    üìä CLS 3- Training: Horizon=60d, Target=38.30% (B&H: 232.98%, Scale=0.164)
‚úÖ CLS: Training data validated - 205 rows over 365 days
    üìä CRDO 3- Training: Horizon=60d, Target=37.58% (B&H: 228.64%, Scale=0.164)
‚úÖ CRDO: Training data validated - 205 rows over 365 days
    üìä ROOT 3- Training: Horizon=60d, Target=37.34% (B&H: 227.16%, Scale=0.164)
‚úÖ ROOT: Training data validated - 205 rows over 365 days
    üìä BE 3- Training: Horizon=60d, Target=37.02% (B&H: 225.19%, Scale=0.164)
‚úÖ BE: Training data validated - 205 rows over 365 days
    üìä SLDP 3- Training: Horizon=60d, Target=36.04% (B&H: 219.26%, Scale=0.164)
‚úÖ SLDP: Training data validated - 205 rows over 365 days
    üìä SGHC 3- Training: Horizon=60d, Target=35.06% (B&H: 213.25%, Scale=0.164)
‚úÖ SGHC: Training data validated - 205 rows over 365 days
    üìä HIMS 3- Training: Horizon=60d, Target=35.01% (B&H: 212.98%, Scale=0.164)
‚úÖ HIMS: Training data validated - 205 rows over 365 days
    üìä ATAI 3- Training: Horizon=60d, Target=34.15% (B&H: 207.76%, Scale=0.164)
‚úÖ ATAI: Training data validated - 205 rows over 365 days
    üìä QURE 3- Training: Horizon=60d, Target=33.94% (B&H: 206.49%, Scale=0.164)
‚úÖ QURE: Training data validated - 205 rows over 365 days
    üìä ZVIA 3- Training: Horizon=60d, Target=33.64% (B&H: 204.63%, Scale=0.164)
‚úÖ ZVIA: Training data validated - 205 rows over 365 days
    üìä PGY 3- Training: Horizon=60d, Target=32.50% (B&H: 197.73%, Scale=0.164)
‚úÖ PGY: Training data validated - 205 rows over 365 days
    üìä INOD 3- Training: Horizon=60d, Target=31.79% (B&H: 193.38%, Scale=0.164)
‚úÖ INOD: Training data validated - 205 rows over 365 days
    üìä GRAL 3- Training: Horizon=60d, Target=31.69% (B&H: 192.81%, Scale=0.164)
‚úÖ GRAL: Training data validated - 205 rows over 365 days
    üìä CRNC 3- Training: Horizon=60d, Target=31.62% (B&H: 192.38%, Scale=0.164)
‚úÖ CRNC: Training data validated - 205 rows over 365 days
    üìä NNE 3- Training: Horizon=60d, Target=31.30% (B&H: 190.42%, Scale=0.164)
‚úÖ NNE: Training data validated - 205 rows over 365 days
    üìä KOPN 3- Training: Horizon=60d, Target=29.72% (B&H: 180.82%, Scale=0.164)
‚úÖ KOPN: Training data validated - 205 rows over 365 days
    üìä CANG 3- Training: Horizon=60d, Target=29.55% (B&H: 179.78%, Scale=0.164)
‚úÖ CANG: Training data validated - 205 rows over 365 days
    üìä APP 3- Training: Horizon=60d, Target=29.41% (B&H: 178.93%, Scale=0.164)
‚úÖ APP: Training data validated - 205 rows over 365 days
    üìä ONDS 3- Training: Horizon=60d, Target=28.98% (B&H: 176.26%, Scale=0.164)
‚úÖ ONDS: Training data validated - 205 rows over 365 days
    üìä SOFI 3- Training: Horizon=60d, Target=27.90% (B&H: 169.72%, Scale=0.164)
‚úÖ SOFI: Training data validated - 205 rows over 365 days
    üìä AKBA 3- Training: Horizon=60d, Target=27.90% (B&H: 169.70%, Scale=0.164)
‚úÖ AKBA: Training data validated - 205 rows over 365 days
    üìä MPU 3- Training: Horizon=60d, Target=27.18% (B&H: 165.35%, Scale=0.164)
‚úÖ MPU: Training data validated - 205 rows over 365 days
    üìä RBRK 3- Training: Horizon=60d, Target=27.02% (B&H: 164.39%, Scale=0.164)
‚úÖ RBRK: Training data validated - 205 rows over 365 days
    üìä ALLT 3- Training: Horizon=60d, Target=26.84% (B&H: 163.30%, Scale=0.164)
‚úÖ ALLT: Training data validated - 205 rows over 365 days
    üìä ORLA 3- Training: Horizon=60d, Target=26.47% (B&H: 161.00%, Scale=0.164)
‚úÖ ORLA: Training data validated - 205 rows over 365 days
    üìä LX 3- Training: Horizon=60d, Target=26.29% (B&H: 159.91%, Scale=0.164)
‚úÖ LX: Training data validated - 205 rows over 365 days
    üìä SEI 3- Training: Horizon=60d, Target=26.03% (B&H: 158.35%, Scale=0.164)
‚úÖ SEI: Training data validated - 205 rows over 365 days
    üìä ETON 3- Training: Horizon=60d, Target=25.75% (B&H: 156.67%, Scale=0.164)
‚úÖ ETON: Training data validated - 205 rows over 365 days
    üìä KTOS 3- Training: Horizon=60d, Target=25.73% (B&H: 156.52%, Scale=0.164)
‚úÖ KTOS: Training data validated - 205 rows over 365 days
    üìä NAGE 3- Training: Horizon=60d, Target=25.54% (B&H: 155.34%, Scale=0.164)
‚úÖ NAGE: Training data validated - 205 rows over 365 days
    üìä QMCO 3- Training: Horizon=60d, Target=25.27% (B&H: 153.71%, Scale=0.164)
‚úÖ QMCO: Training data validated - 205 rows over 365 days
    üìä GEV 3- Training: Horizon=60d, Target=25.20% (B&H: 153.29%, Scale=0.164)
‚úÖ GEV: Training data validated - 205 rows over 365 days
    üìä AMLX 3- Training: Horizon=60d, Target=24.91% (B&H: 151.54%, Scale=0.164)
‚úÖ AMLX: Training data validated - 205 rows over 365 days
    üìä SOUN 3- Training: Horizon=60d, Target=24.87% (B&H: 151.29%, Scale=0.164)
‚úÖ SOUN: Training data validated - 205 rows over 365 days
    üìä TTMI 3- Training: Horizon=60d, Target=24.36% (B&H: 148.16%, Scale=0.164)
‚úÖ TTMI: Training data validated - 205 rows over 365 days
    üìä SBET 3- Training: Horizon=60d, Target=24.27% (B&H: 147.64%, Scale=0.164)
‚úÖ SBET: Training data validated - 205 rows over 365 days
    üìä AISP 3- Training: Horizon=60d, Target=24.09% (B&H: 146.52%, Scale=0.164)
‚úÖ AISP: Training data validated - 205 rows over 365 days
    üìä OPFI 3- Training: Horizon=60d, Target=23.97% (B&H: 145.80%, Scale=0.164)
‚úÖ OPFI: Training data validated - 205 rows over 365 days
    üìä NET 3- Training: Horizon=60d, Target=23.88% (B&H: 145.30%, Scale=0.164)
‚úÖ NET: Training data validated - 205 rows over 365 days
    üìä LGCY 3- Training: Horizon=60d, Target=23.80% (B&H: 144.78%, Scale=0.164)
‚úÖ LGCY: Training data validated - 205 rows over 365 days
    üìä BITU 3- Training: Horizon=60d, Target=23.78% (B&H: 144.68%, Scale=0.164)
‚úÖ BITU: Training data validated - 205 rows over 365 days
    üìä LMND 3- Training: Horizon=60d, Target=23.42% (B&H: 142.45%, Scale=0.164)
‚úÖ LMND: Training data validated - 205 rows over 365 days
    üìä MSTR 3- Training: Horizon=60d, Target=23.14% (B&H: 140.74%, Scale=0.164)
‚úÖ MSTR: Training data validated - 205 rows over 365 days
    üìä NEXT 3- Training: Horizon=60d, Target=23.07% (B&H: 140.34%, Scale=0.164)
‚úÖ NEXT: Training data validated - 205 rows over 365 days
    üìä BITX 3- Training: Horizon=60d, Target=22.89% (B&H: 139.25%, Scale=0.164)
‚úÖ BITX: Training data validated - 205 rows over 365 days
    üìä AS 3- Training: Horizon=60d, Target=22.37% (B&H: 136.11%, Scale=0.164)
‚úÖ AS: Training data validated - 205 rows over 365 days
    üìä CAR 3- Training: Horizon=60d, Target=22.37% (B&H: 136.09%, Scale=0.164)
‚úÖ CAR: Training data validated - 205 rows over 365 days
    üìä SRAD 3- Training: Horizon=60d, Target=22.26% (B&H: 135.43%, Scale=0.164)
‚úÖ SRAD: Training data validated - 205 rows over 365 days
    üìä AGX 3- Training: Horizon=60d, Target=22.17% (B&H: 134.86%, Scale=0.164)
‚úÖ AGX: Training data validated - 205 rows over 365 days
    üìä TPR 3- Training: Horizon=60d, Target=22.01% (B&H: 133.92%, Scale=0.164)
‚úÖ TPR: Training data validated - 205 rows over 365 days
    üìä INVZ 3- Training: Horizon=60d, Target=21.68% (B&H: 131.88%, Scale=0.164)
‚úÖ INVZ: Training data validated - 205 rows over 365 days
    üìä CRCL 3- Training: Horizon=60d, Target=21.65% (B&H: 131.72%, Scale=0.164)
  ‚ùå CRCL: Too many NaN values in Close price: 170 / 205 rows
   üí° Data quality issue - try different data source or date range
    üìä DPRO 3- Training: Horizon=60d, Target=21.60% (B&H: 131.37%, Scale=0.164)
‚úÖ DPRO: Training data validated - 205 rows over 365 days
    üìä EYE 3- Training: Horizon=60d, Target=21.26% (B&H: 129.33%, Scale=0.164)
‚úÖ EYE: Training data validated - 205 rows over 365 days
    üìä ESLT 3- Training: Horizon=60d, Target=21.03% (B&H: 127.94%, Scale=0.164)
‚úÖ ESLT: Training data validated - 205 rows over 365 days
    üìä RDDT 3- Training: Horizon=60d, Target=20.88% (B&H: 127.03%, Scale=0.164)
‚úÖ RDDT: Training data validated - 205 rows over 365 days
    üìä OPRT 3- Training: Horizon=60d, Target=20.77% (B&H: 126.33%, Scale=0.164)
‚úÖ OPRT: Training data validated - 205 rows over 365 days
    üìä JFIN 3- Training: Horizon=60d, Target=20.71% (B&H: 125.98%, Scale=0.164)
‚úÖ JFIN: Training data validated - 205 rows over 365 days
    üìä CONL 3- Training: Horizon=60d, Target=20.70% (B&H: 125.93%, Scale=0.164)
‚úÖ CONL: Training data validated - 205 rows over 365 days
    üìä HTZ 3- Training: Horizon=60d, Target=20.62% (B&H: 125.45%, Scale=0.164)
‚úÖ HTZ: Training data validated - 205 rows over 365 days
    üìä SBSW 3- Training: Horizon=60d, Target=20.52% (B&H: 124.82%, Scale=0.164)
‚úÖ SBSW: Training data validated - 205 rows over 365 days
    üìä GRNQ 3- Training: Horizon=60d, Target=20.34% (B&H: 123.71%, Scale=0.164)
‚úÖ GRNQ: Training data validated - 205 rows over 365 days
    üìä PAYS 3- Training: Horizon=60d, Target=20.07% (B&H: 122.07%, Scale=0.164)
‚úÖ PAYS: Training data validated - 205 rows over 365 days
    üìä XYF 3- Training: Horizon=60d, Target=19.88% (B&H: 120.92%, Scale=0.164)
‚úÖ XYF: Training data validated - 205 rows over 365 days
    üìä TRVG 3- Training: Horizon=60d, Target=19.76% (B&H: 120.23%, Scale=0.164)
‚úÖ TRVG: Training data validated - 205 rows over 365 days
    üìä AMBR 3- Training: Horizon=60d, Target=19.73% (B&H: 120.00%, Scale=0.164)
‚úÖ AMBR: Training data validated - 205 rows over 365 days
    üìä COIN 3- Training: Horizon=60d, Target=19.70% (B&H: 119.82%, Scale=0.164)
‚úÖ COIN: Training data validated - 205 rows over 365 days
    üìä GOGO 3- Training: Horizon=60d, Target=19.69% (B&H: 119.78%, Scale=0.164)
‚úÖ GOGO: Training data validated - 205 rows over 365 days
    üìä SSRM 3- Training: Horizon=60d, Target=19.68% (B&H: 119.72%, Scale=0.164)
‚úÖ SSRM: Training data validated - 205 rows over 365 days
    üìä QSI 3- Training: Horizon=60d, Target=19.53% (B&H: 118.82%, Scale=0.164)
‚úÖ QSI: Training data validated - 205 rows over 365 days
    üìä OSS 3- Training: Horizon=60d, Target=19.46% (B&H: 118.41%, Scale=0.164)
‚úÖ OSS: Training data validated - 205 rows over 365 days
    üìä AAPG 3- Training: Horizon=60d, Target=19.31% (B&H: 117.49%, Scale=0.164)
  ‚ùå AAPG: Too many NaN values in Close price: 79 / 205 rows
   üí° Data quality issue - try different data source or date range
    üìä GHRS 3- Training: Horizon=60d, Target=19.19% (B&H: 116.74%, Scale=0.164)
‚úÖ GHRS: Training data validated - 205 rows over 365 days
    üìä LUXE 3- Training: Horizon=60d, Target=19.07% (B&H: 116.01%, Scale=0.164)
‚úÖ LUXE: Training data validated - 205 rows over 365 days
    üìä EVEX 3- Training: Horizon=60d, Target=18.87% (B&H: 114.81%, Scale=0.164)
‚úÖ EVEX: Training data validated - 205 rows over 365 days
    üìä EOSE 3- Training: Horizon=60d, Target=18.82% (B&H: 114.48%, Scale=0.164)
‚úÖ EOSE: Training data validated - 205 rows over 365 days
    üìä MASS 3- Training: Horizon=60d, Target=18.71% (B&H: 113.83%, Scale=0.164)
‚úÖ MASS: Training data validated - 205 rows over 365 days
    üìä AVXL 3- Training: Horizon=60d, Target=18.67% (B&H: 113.56%, Scale=0.164)
‚úÖ AVXL: Training data validated - 205 rows over 365 days
    üìä TESL 3- Training: Horizon=60d, Target=18.54% (B&H: 112.80%, Scale=0.164)
‚úÖ TESL: Training data validated - 205 rows over 365 days
    üìä DOMO 3- Training: Horizon=60d, Target=18.50% (B&H: 112.52%, Scale=0.164)
‚úÖ DOMO: Training data validated - 205 rows over 365 days
    üìä DAO 3- Training: Horizon=60d, Target=18.10% (B&H: 110.12%, Scale=0.164)
‚úÖ DAO: Training data validated - 205 rows over 365 days
    üìä FOA 3- Training: Horizon=60d, Target=18.09% (B&H: 110.03%, Scale=0.164)
‚úÖ FOA: Training data validated - 205 rows over 365 days
    üìä ALNT 3- Training: Horizon=60d, Target=18.08% (B&H: 109.98%, Scale=0.164)
‚úÖ ALNT: Training data validated - 205 rows over 365 days
    üìä IREN 3- Training: Horizon=60d, Target=18.07% (B&H: 109.95%, Scale=0.164)
‚úÖ IREN: Training data validated - 205 rows over 365 days
    üìä UPST 3- Training: Horizon=60d, Target=17.88% (B&H: 108.77%, Scale=0.164)
‚úÖ UPST: Training data validated - 205 rows over 365 days
    üìä ASTS 3- Training: Horizon=60d, Target=17.72% (B&H: 107.78%, Scale=0.164)
‚úÖ ASTS: Training data validated - 205 rows over 365 days
    üìä AENT 3- Training: Horizon=60d, Target=17.56% (B&H: 106.80%, Scale=0.164)
‚úÖ AENT: Training data validated - 205 rows over 365 days
    üìä TARK 3- Training: Horizon=60d, Target=17.44% (B&H: 106.09%, Scale=0.164)
‚úÖ TARK: Training data validated - 205 rows over 365 days
    üìä IHS 3- Training: Horizon=60d, Target=17.43% (B&H: 106.02%, Scale=0.164)
‚úÖ IHS: Training data validated - 205 rows over 365 days
    üìä APEI 3- Training: Horizon=60d, Target=17.36% (B&H: 105.63%, Scale=0.164)
‚úÖ APEI: Training data validated - 205 rows over 365 days
    üìä NN 3- Training: Horizon=60d, Target=17.36% (B&H: 105.61%, Scale=0.164)
‚úÖ NN: Training data validated - 205 rows over 365 days
    üìä DOYU 3- Training: Horizon=60d, Target=17.28% (B&H: 105.10%, Scale=0.164)
‚úÖ DOYU: Training data validated - 205 rows over 365 days
    üìä APYX 3- Training: Horizon=60d, Target=17.23% (B&H: 104.84%, Scale=0.164)
‚úÖ APYX: Training data validated - 205 rows over 365 days
    üìä LFMD 3- Training: Horizon=60d, Target=17.10% (B&H: 104.01%, Scale=0.164)
‚úÖ LFMD: Training data validated - 205 rows over 365 days
    üìä CTMX 3- Training: Horizon=60d, Target=17.00% (B&H: 103.39%, Scale=0.164)
‚úÖ CTMX: Training data validated - 205 rows over 365 days
    üìä GEO 3- Training: Horizon=60d, Target=16.95% (B&H: 103.11%, Scale=0.164)
‚úÖ GEO: Training data validated - 205 rows over 365 days
    üìä DXPE 3- Training: Horizon=60d, Target=16.89% (B&H: 102.72%, Scale=0.164)
‚úÖ DXPE: Training data validated - 205 rows over 365 days
    üìä KEN 3- Training: Horizon=60d, Target=16.84% (B&H: 102.45%, Scale=0.164)
‚úÖ KEN: Training data validated - 205 rows over 365 days
    üìä VNET 3- Training: Horizon=60d, Target=16.84% (B&H: 102.45%, Scale=0.164)
‚úÖ VNET: Training data validated - 205 rows over 365 days
    üìä UI 3- Training: Horizon=60d, Target=16.83% (B&H: 102.36%, Scale=0.164)
‚úÖ UI: Training data validated - 205 rows over 365 days
    üìä TWLO 3- Training: Horizon=60d, Target=16.59% (B&H: 100.95%, Scale=0.164)
‚úÖ TWLO: Training data validated - 205 rows over 365 days
    üìä VVOS 3- Training: Horizon=60d, Target=16.56% (B&H: 100.77%, Scale=0.164)
‚úÖ VVOS: Training data validated - 205 rows over 365 days
    üìä ATOM 3- Training: Horizon=60d, Target=16.56% (B&H: 100.76%, Scale=0.164)
‚úÖ ATOM: Training data validated - 205 rows over 365 days
    üìä MGTX 3- Training: Horizon=60d, Target=16.56% (B&H: 100.72%, Scale=0.164)
‚úÖ MGTX: Training data validated - 205 rows over 365 days
    üìä RCL 3- Training: Horizon=60d, Target=16.54% (B&H: 100.64%, Scale=0.164)
‚úÖ RCL: Training data validated - 205 rows over 365 days
    üìä EAT 3- Training: Horizon=60d, Target=16.53% (B&H: 100.57%, Scale=0.164)
‚úÖ EAT: Training data validated - 205 rows over 365 days
    üìä WLDN 3- Training: Horizon=60d, Target=16.49% (B&H: 100.34%, Scale=0.164)
‚úÖ WLDN: Training data validated - 205 rows over 365 days
    üìä MESO 3- Training: Horizon=60d, Target=16.48% (B&H: 100.24%, Scale=0.164)
‚úÖ MESO: Training data validated - 205 rows over 365 days
    üìä VS 3- Training: Horizon=60d, Target=16.30% (B&H: 99.16%, Scale=0.164)
‚úÖ VS: Training data validated - 205 rows over 365 days
    üìä DJTWW 3- Training: Horizon=60d, Target=16.30% (B&H: 99.13%, Scale=0.164)
‚úÖ DJTWW: Training data validated - 205 rows over 365 days
    üìä DB 3- Training: Horizon=60d, Target=16.24% (B&H: 98.77%, Scale=0.164)
‚úÖ DB: Training data validated - 205 rows over 365 days
    üìä MIR 3- Training: Horizon=60d, Target=16.14% (B&H: 98.19%, Scale=0.164)
‚úÖ MIR: Training data validated - 205 rows over 365 days
    üìä TSAT 3- Training: Horizon=60d, Target=16.14% (B&H: 98.18%, Scale=0.164)
‚úÖ TSAT: Training data validated - 205 rows over 365 days
    üìä TIGR 3- Training: Horizon=60d, Target=16.10% (B&H: 97.94%, Scale=0.164)
‚úÖ TIGR: Training data validated - 205 rows over 365 days
    üìä RBOT 3- Training: Horizon=60d, Target=16.03% (B&H: 97.54%, Scale=0.164)
‚úÖ RBOT: Training data validated - 205 rows over 365 days
    üìä METC 3- Training: Horizon=60d, Target=15.99% (B&H: 97.30%, Scale=0.164)
‚úÖ METC: Training data validated - 205 rows over 365 days
    üìä MSTY 3- Training: Horizon=60d, Target=15.95% (B&H: 97.00%, Scale=0.164)
‚úÖ MSTY: Training data validated - 205 rows over 365 days
    üìä ABCL 3- Training: Horizon=60d, Target=15.87% (B&H: 96.54%, Scale=0.164)
‚úÖ ABCL: Training data validated - 205 rows over 365 days
    üìä TBRG 3- Training: Horizon=60d, Target=15.86% (B&H: 96.49%, Scale=0.164)
‚úÖ TBRG: Training data validated - 205 rows over 365 days
    üìä LQDA 3- Training: Horizon=60d, Target=15.78% (B&H: 96.00%, Scale=0.164)
‚úÖ LQDA: Training data validated - 205 rows over 365 days
    üìä RIOT 3- Training: Horizon=60d, Target=15.77% (B&H: 95.96%, Scale=0.164)
‚úÖ RIOT: Training data validated - 205 rows over 365 days
    üìä MYRG 3- Training: Horizon=60d, Target=15.77% (B&H: 95.93%, Scale=0.164)
‚úÖ MYRG: Training data validated - 205 rows over 365 days
    üìä LIF 3- Training: Horizon=60d, Target=15.65% (B&H: 95.20%, Scale=0.164)
‚úÖ LIF: Training data validated - 205 rows over 365 days
    üìä TLN 3- Training: Horizon=60d, Target=15.53% (B&H: 94.47%, Scale=0.164)
‚úÖ TLN: Training data validated - 205 rows over 365 days
    üìä VUZI 3- Training: Horizon=60d, Target=15.45% (B&H: 94.02%, Scale=0.164)
‚úÖ VUZI: Training data validated - 205 rows over 365 days
    üìä UTI 3- Training: Horizon=60d, Target=15.45% (B&H: 93.97%, Scale=0.164)
‚úÖ UTI: Training data validated - 205 rows over 365 days
    üìä AU 3- Training: Horizon=60d, Target=15.29% (B&H: 93.00%, Scale=0.164)
‚úÖ AU: Training data validated - 205 rows over 365 days
    üìä LINC 3- Training: Horizon=60d, Target=15.03% (B&H: 91.46%, Scale=0.164)
‚úÖ LINC: Training data validated - 205 rows over 365 days
    üìä CVNA 3- Training: Horizon=60d, Target=14.92% (B&H: 90.75%, Scale=0.164)
‚úÖ CVNA: Training data validated - 205 rows over 365 days
    üìä AAOI 3- Training: Horizon=60d, Target=14.73% (B&H: 89.59%, Scale=0.164)
‚úÖ AAOI: Training data validated - 205 rows over 365 days
    üìä CCB 3- Training: Horizon=60d, Target=14.72% (B&H: 89.52%, Scale=0.164)
‚úÖ CCB: Training data validated - 205 rows over 365 days
    üìä MGIC 3- Training: Horizon=60d, Target=14.71% (B&H: 89.48%, Scale=0.164)
‚úÖ MGIC: Training data validated - 205 rows over 365 days
    üìä HWM 3- Training: Horizon=60d, Target=14.70% (B&H: 89.45%, Scale=0.164)
‚úÖ HWM: Training data validated - 205 rows over 365 days
    üìä CYD 3- Training: Horizon=60d, Target=14.64% (B&H: 89.08%, Scale=0.164)
‚úÖ CYD: Training data validated - 205 rows over 365 days
    üìä IBKR 3- Training: Horizon=60d, Target=14.59% (B&H: 88.77%, Scale=0.164)
‚úÖ IBKR: Training data validated - 205 rows over 365 days
    üìä WGS 3- Training: Horizon=60d, Target=14.48% (B&H: 88.10%, Scale=0.164)
‚úÖ WGS: Training data validated - 205 rows over 365 days
    üìä MNY 3- Training: Horizon=60d, Target=14.48% (B&H: 88.07%, Scale=0.164)
‚úÖ MNY: Training data validated - 205 rows over 365 days
    üìä SPOT 3- Training: Horizon=60d, Target=14.48% (B&H: 88.07%, Scale=0.164)
‚úÖ SPOT: Training data validated - 205 rows over 365 days
    üìä CRK 3- Training: Horizon=60d, Target=14.19% (B&H: 86.34%, Scale=0.164)
‚úÖ CRK: Training data validated - 205 rows over 365 days
    üìä JBL 3- Training: Horizon=60d, Target=14.14% (B&H: 86.01%, Scale=0.164)
‚úÖ JBL: Training data validated - 205 rows over 365 days
    üìä BROS 3- Training: Horizon=60d, Target=14.10% (B&H: 85.76%, Scale=0.164)
‚úÖ BROS: Training data validated - 205 rows over 365 days
    üìä CVAC 3- Training: Horizon=60d, Target=14.09% (B&H: 85.71%, Scale=0.164)
‚úÖ CVAC: Training data validated - 205 rows over 365 days
    üìä GHM 3- Training: Horizon=60d, Target=14.07% (B&H: 85.60%, Scale=0.164)
‚úÖ GHM: Training data validated - 205 rows over 365 days
    üìä ARKW 3- Training: Horizon=60d, Target=13.99% (B&H: 85.11%, Scale=0.164)
‚úÖ ARKW: Training data validated - 205 rows over 365 days
    üìä STRL 3- Training: Horizon=60d, Target=13.96% (B&H: 84.90%, Scale=0.164)
‚úÖ STRL: Training data validated - 205 rows over 365 days
    üìä BTCW 3- Training: Horizon=60d, Target=13.83% (B&H: 84.14%, Scale=0.164)
‚úÖ BTCW: Training data validated - 205 rows over 365 days
    üìä HODL 3- Training: Horizon=60d, Target=13.82% (B&H: 84.10%, Scale=0.164)
‚úÖ HODL: Training data validated - 205 rows over 365 days
    üìä AXON 3- Training: Horizon=60d, Target=13.80% (B&H: 83.94%, Scale=0.164)
‚úÖ AXON: Training data validated - 205 rows over 365 days
    üìä EZBC 3- Training: Horizon=60d, Target=13.80% (B&H: 83.92%, Scale=0.164)
‚úÖ EZBC: Training data validated - 205 rows over 365 days
    üìä BITB 3- Training: Horizon=60d, Target=13.77% (B&H: 83.78%, Scale=0.164)
‚úÖ BITB: Training data validated - 205 rows over 365 days
    üìä BRRR 3- Training: Horizon=60d, Target=13.76% (B&H: 83.70%, Scale=0.164)
‚úÖ BRRR: Training data validated - 205 rows over 365 days
    üìä IBIT 3- Training: Horizon=60d, Target=13.75% (B&H: 83.67%, Scale=0.164)
‚úÖ IBIT: Training data validated - 205 rows over 365 days
    üìä FBTC 3- Training: Horizon=60d, Target=13.75% (B&H: 83.63%, Scale=0.164)
‚úÖ FBTC: Training data validated - 205 rows over 365 days
    üìä ARKB 3- Training: Horizon=60d, Target=13.73% (B&H: 83.54%, Scale=0.164)
‚úÖ ARKB: Training data validated - 205 rows over 365 days
    üìä BTCO 3- Training: Horizon=60d, Target=13.73% (B&H: 83.52%, Scale=0.164)
‚úÖ BTCO: Training data validated - 205 rows over 365 days
    üìä REAL 3- Training: Horizon=60d, Target=13.72% (B&H: 83.44%, Scale=0.164)
‚úÖ REAL: Training data validated - 205 rows over 365 days
    üìä SAN 3- Training: Horizon=60d, Target=13.66% (B&H: 83.08%, Scale=0.164)
‚úÖ SAN: Training data validated - 205 rows over 365 days
    üìä AMSC 3- Training: Horizon=60d, Target=13.65% (B&H: 83.05%, Scale=0.164)
‚úÖ AMSC: Training data validated - 205 rows over 365 days
    üìä SKE 3- Training: Horizon=60d, Target=13.60% (B&H: 82.74%, Scale=0.164)
‚úÖ SKE: Training data validated - 205 rows over 365 days
    üìä DEFI 3- Training: Horizon=60d, Target=13.57% (B&H: 82.55%, Scale=0.164)
‚úÖ DEFI: Training data validated - 205 rows over 365 days
    üìä OM 3- Training: Horizon=60d, Target=13.56% (B&H: 82.47%, Scale=0.164)
‚úÖ OM: Training data validated - 205 rows over 365 days
    üìä UUUU 3- Training: Horizon=60d, Target=13.53% (B&H: 82.33%, Scale=0.164)
‚úÖ UUUU: Training data validated - 205 rows over 365 days
    üìä FRHC 3- Training: Horizon=60d, Target=13.53% (B&H: 82.28%, Scale=0.164)
‚úÖ FRHC: Training data validated - 205 rows over 365 days
    üìä TPB 3- Training: Horizon=60d, Target=13.49% (B&H: 82.07%, Scale=0.164)
‚úÖ TPB: Training data validated - 205 rows over 365 days
    üìä GBTC 3- Training: Horizon=60d, Target=13.47% (B&H: 81.92%, Scale=0.164)
‚úÖ GBTC: Training data validated - 205 rows over 365 days
    üìä BBIO 3- Training: Horizon=60d, Target=13.46% (B&H: 81.85%, Scale=0.164)
‚úÖ BBIO: Training data validated - 205 rows over 365 days
    üìä ARKF 3- Training: Horizon=60d, Target=13.38% (B&H: 81.39%, Scale=0.164)
‚úÖ ARKF: Training data validated - 205 rows over 365 days
    üìä LASR 3- Training: Horizon=60d, Target=13.38% (B&H: 81.38%, Scale=0.164)
‚úÖ LASR: Training data validated - 205 rows over 365 days
    üìä KEP 3- Training: Horizon=60d, Target=13.33% (B&H: 81.12%, Scale=0.164)
‚úÖ KEP: Training data validated - 205 rows over 365 days
    üìä IRTC 3- Training: Horizon=60d, Target=13.27% (B&H: 80.74%, Scale=0.164)
‚úÖ IRTC: Training data validated - 205 rows over 365 days
    üìä HIMX 3- Training: Horizon=60d, Target=13.24% (B&H: 80.53%, Scale=0.164)
‚úÖ HIMX: Training data validated - 205 rows over 365 days
    üìä GDS 3- Training: Horizon=60d, Target=13.20% (B&H: 80.29%, Scale=0.164)
‚úÖ GDS: Training data validated - 205 rows over 365 days
    üìä ETHZ 3- Training: Horizon=60d, Target=13.09% (B&H: 79.64%, Scale=0.164)
‚úÖ ETHZ: Training data validated - 205 rows over 365 days
    üìä IESC 3- Training: Horizon=60d, Target=13.01% (B&H: 79.17%, Scale=0.164)
‚úÖ IESC: Training data validated - 205 rows over 365 days
    üìä TME 3- Training: Horizon=60d, Target=12.98% (B&H: 78.99%, Scale=0.164)
‚úÖ TME: Training data validated - 205 rows over 365 days
    üìä PARR 3- Training: Horizon=60d, Target=12.92% (B&H: 78.58%, Scale=0.164)
‚úÖ PARR: Training data validated - 205 rows over 365 days
    üìä APPS 3- Training: Horizon=60d, Target=12.80% (B&H: 77.85%, Scale=0.164)
‚úÖ APPS: Training data validated - 205 rows over 365 days
    üìä VEON 3- Training: Horizon=60d, Target=12.79% (B&H: 77.78%, Scale=0.164)
‚úÖ VEON: Training data validated - 205 rows over 365 days
    üìä XMTR 3- Training: Horizon=60d, Target=12.75% (B&H: 77.57%, Scale=0.164)
‚úÖ XMTR: Training data validated - 205 rows over 365 days
    üìä ATRO 3- Training: Horizon=60d, Target=12.67% (B&H: 77.05%, Scale=0.164)
‚úÖ ATRO: Training data validated - 205 rows over 365 days
    üìä FIX 3- Training: Horizon=60d, Target=12.65% (B&H: 76.97%, Scale=0.164)
‚úÖ FIX: Training data validated - 205 rows over 365 days
    üìä LMB 3- Training: Horizon=60d, Target=12.60% (B&H: 76.66%, Scale=0.164)
‚úÖ LMB: Training data validated - 205 rows over 365 days
    üìä CIB 3- Training: Horizon=60d, Target=12.56% (B&H: 76.43%, Scale=0.164)
‚úÖ CIB: Training data validated - 205 rows over 365 days
    üìä TPC 3- Training: Horizon=60d, Target=12.56% (B&H: 76.40%, Scale=0.164)
‚úÖ TPC: Training data validated - 205 rows over 365 days
    üìä ORGO 3- Training: Horizon=60d, Target=12.47% (B&H: 75.87%, Scale=0.164)
‚úÖ ORGO: Training data validated - 205 rows over 365 days
    üìä INDV 3- Training: Horizon=60d, Target=12.46% (B&H: 75.79%, Scale=0.164)
‚úÖ INDV: Training data validated - 205 rows over 365 days
    üìä EXEL 3- Training: Horizon=60d, Target=12.45% (B&H: 75.72%, Scale=0.164)
‚úÖ EXEL: Training data validated - 205 rows over 365 days
    üìä PBI 3- Training: Horizon=60d, Target=12.45% (B&H: 75.71%, Scale=0.164)
‚úÖ PBI: Training data validated - 205 rows over 365 days
    üìä ICCM 3- Training: Horizon=60d, Target=12.40% (B&H: 75.41%, Scale=0.164)
‚úÖ ICCM: Training data validated - 205 rows over 365 days
    üìä DASH 3- Training: Horizon=60d, Target=12.35% (B&H: 75.10%, Scale=0.164)
‚úÖ DASH: Training data validated - 205 rows over 365 days
    üìä FUTU 3- Training: Horizon=60d, Target=12.34% (B&H: 75.08%, Scale=0.164)
‚úÖ FUTU: Training data validated - 205 rows over 365 days
    üìä TATT 3- Training: Horizon=60d, Target=12.33% (B&H: 75.03%, Scale=0.164)
‚úÖ TATT: Training data validated - 205 rows over 365 days
    üìä CPS 3- Training: Horizon=60d, Target=12.31% (B&H: 74.91%, Scale=0.164)
‚úÖ CPS: Training data validated - 205 rows over 365 days
    üìä TENX 3- Training: Horizon=60d, Target=12.31% (B&H: 74.86%, Scale=0.164)
‚úÖ TENX: Training data validated - 205 rows over 365 days
    üìä BITO 3- Training: Horizon=60d, Target=12.29% (B&H: 74.74%, Scale=0.164)
‚úÖ BITO: Training data validated - 205 rows over 365 days
    üìä NRG 3- Training: Horizon=60d, Target=12.18% (B&H: 74.11%, Scale=0.164)
‚úÖ NRG: Training data validated - 205 rows over 365 days
    üìä CRS 3- Training: Horizon=60d, Target=12.14% (B&H: 73.83%, Scale=0.164)
‚úÖ CRS: Training data validated - 205 rows over 365 days
    üìä ODC 3- Training: Horizon=60d, Target=12.10% (B&H: 73.62%, Scale=0.164)
‚úÖ ODC: Training data validated - 205 rows over 365 days
    üìä PPTA 3- Training: Horizon=60d, Target=12.06% (B&H: 73.37%, Scale=0.164)
‚úÖ PPTA: Training data validated - 205 rows over 365 days
    üìä KGC 3- Training: Horizon=60d, Target=12.04% (B&H: 73.24%, Scale=0.164)
‚úÖ KGC: Training data validated - 205 rows over 365 days
    üìä SNEX 3- Training: Horizon=60d, Target=12.03% (B&H: 73.16%, Scale=0.164)
‚úÖ SNEX: Training data validated - 205 rows over 365 days
    üìä CMPX 3- Training: Horizon=60d, Target=11.97% (B&H: 72.83%, Scale=0.164)
‚úÖ CMPX: Training data validated - 205 rows over 365 days
    üìä CTOS 3- Training: Horizon=60d, Target=11.96% (B&H: 72.75%, Scale=0.164)
‚úÖ CTOS: Training data validated - 205 rows over 365 days
    üìä DRS 3- Training: Horizon=60d, Target=11.92% (B&H: 72.53%, Scale=0.164)
‚úÖ DRS: Training data validated - 205 rows over 365 days
    üìä NXT 3- Training: Horizon=60d, Target=11.86% (B&H: 72.17%, Scale=0.164)
‚úÖ NXT: Training data validated - 205 rows over 365 days
    üìä TOST 3- Training: Horizon=60d, Target=11.84% (B&H: 72.02%, Scale=0.164)
‚úÖ TOST: Training data validated - 205 rows over 365 days
    üìä REVG 3- Training: Horizon=60d, Target=11.79% (B&H: 71.71%, Scale=0.164)
‚úÖ REVG: Training data validated - 205 rows over 365 days
    üìä HNRG 3- Training: Horizon=60d, Target=11.78% (B&H: 71.69%, Scale=0.164)
‚úÖ HNRG: Training data validated - 205 rows over 365 days
    üìä BLOK 3- Training: Horizon=60d, Target=11.77% (B&H: 71.62%, Scale=0.164)
‚úÖ BLOK: Training data validated - 205 rows over 365 days
    üìä MNMD 3- Training: Horizon=60d, Target=11.76% (B&H: 71.53%, Scale=0.164)
‚úÖ MNMD: Training data validated - 205 rows over 365 days
    üìä DNA 3- Training: Horizon=60d, Target=11.72% (B&H: 71.29%, Scale=0.164)
‚úÖ DNA: Training data validated - 205 rows over 365 days
    üìä SLNO 3- Training: Horizon=60d, Target=11.71% (B&H: 71.26%, Scale=0.164)
‚úÖ SLNO: Training data validated - 205 rows over 365 days
    üìä YALA 3- Training: Horizon=60d, Target=11.62% (B&H: 70.70%, Scale=0.164)
‚úÖ YALA: Training data validated - 205 rows over 365 days
    üìä JNUG 3- Training: Horizon=60d, Target=11.55% (B&H: 70.24%, Scale=0.164)
‚úÖ JNUG: Training data validated - 205 rows over 365 days
    üìä KD 3- Training: Horizon=60d, Target=11.55% (B&H: 70.23%, Scale=0.164)
‚úÖ KD: Training data validated - 205 rows over 365 days
    üìä NBP 3- Training: Horizon=60d, Target=11.53% (B&H: 70.16%, Scale=0.164)
‚úÖ NBP: Training data validated - 205 rows over 365 days
    üìä MGNI 3- Training: Horizon=60d, Target=11.48% (B&H: 69.82%, Scale=0.164)
‚úÖ MGNI: Training data validated - 205 rows over 365 days
    üìä IVA 3- Training: Horizon=60d, Target=11.48% (B&H: 69.81%, Scale=0.164)
‚úÖ IVA: Training data validated - 205 rows over 365 days
    üìä AVGO 3- Training: Horizon=60d, Target=11.44% (B&H: 69.58%, Scale=0.164)
‚úÖ AVGO: Training data validated - 205 rows over 365 days
    üìä CMP 3- Training: Horizon=60d, Target=11.42% (B&H: 69.47%, Scale=0.164)
‚úÖ CMP: Training data validated - 205 rows over 365 days
    üìä AEHR 3- Training: Horizon=60d, Target=11.37% (B&H: 69.18%, Scale=0.164)
‚úÖ AEHR: Training data validated - 205 rows over 365 days
    üìä EVLV 3- Training: Horizon=60d, Target=11.24% (B&H: 68.40%, Scale=0.164)
‚úÖ EVLV: Training data validated - 205 rows over 365 days
    üìä HRTG 3- Training: Horizon=60d, Target=11.20% (B&H: 68.14%, Scale=0.164)
‚úÖ HRTG: Training data validated - 205 rows over 365 days
    üìä ODD 3- Training: Horizon=60d, Target=11.20% (B&H: 68.13%, Scale=0.164)
‚úÖ ODD: Training data validated - 205 rows over 365 days
    üìä OMAB 3- Training: Horizon=60d, Target=11.17% (B&H: 67.98%, Scale=0.164)
‚úÖ OMAB: Training data validated - 205 rows over 365 days
    üìä UNFI 3- Training: Horizon=60d, Target=11.13% (B&H: 67.72%, Scale=0.164)
‚úÖ UNFI: Training data validated - 205 rows over 365 days
    üìä LLYVA 3- Training: Horizon=60d, Target=11.10% (B&H: 67.50%, Scale=0.164)
‚úÖ LLYVA: Training data validated - 205 rows over 365 days
    üìä ZS 3- Training: Horizon=60d, Target=11.08% (B&H: 67.42%, Scale=0.164)
‚úÖ ZS: Training data validated - 205 rows over 365 days
    üìä NIU 3- Training: Horizon=60d, Target=11.08% (B&H: 67.39%, Scale=0.164)
‚úÖ NIU: Training data validated - 205 rows over 365 days
    üìä SE 3- Training: Horizon=60d, Target=11.06% (B&H: 67.28%, Scale=0.164)
‚úÖ SE: Training data validated - 205 rows over 365 days
    üìä VIK 3- Training: Horizon=60d, Target=11.05% (B&H: 67.21%, Scale=0.164)
‚úÖ VIK: Training data validated - 205 rows over 365 days
    üìä CIFR 3- Training: Horizon=60d, Target=11.04% (B&H: 67.18%, Scale=0.164)
‚úÖ CIFR: Training data validated - 205 rows over 365 days
    üìä SHLD 3- Training: Horizon=60d, Target=11.02% (B&H: 67.07%, Scale=0.164)
‚úÖ SHLD: Training data validated - 205 rows over 365 days
    üìä CCJ 3- Training: Horizon=60d, Target=11.01% (B&H: 66.99%, Scale=0.164)
‚úÖ CCJ: Training data validated - 205 rows over 365 days
    üìä CRWD 3- Training: Horizon=60d, Target=10.99% (B&H: 66.83%, Scale=0.164)
‚úÖ CRWD: Training data validated - 205 rows over 365 days
    üìä SII 3- Training: Horizon=60d, Target=10.97% (B&H: 66.74%, Scale=0.164)
‚úÖ SII: Training data validated - 205 rows over 365 days
    üìä NFLX 3- Training: Horizon=60d, Target=10.92% (B&H: 66.44%, Scale=0.164)
‚úÖ NFLX: Training data validated - 205 rows over 365 days
    üìä HUT 3- Training: Horizon=60d, Target=10.89% (B&H: 66.23%, Scale=0.164)
‚úÖ HUT: Training data validated - 205 rows over 365 days
    üìä LLYVK 3- Training: Horizon=60d, Target=10.86% (B&H: 66.08%, Scale=0.164)
‚úÖ LLYVK: Training data validated - 205 rows over 365 days
    üìä API 3- Training: Horizon=60d, Target=10.85% (B&H: 65.98%, Scale=0.164)
‚úÖ API: Training data validated - 205 rows over 365 days
    üìä VSEC 3- Training: Horizon=60d, Target=10.81% (B&H: 65.79%, Scale=0.164)
‚úÖ VSEC: Training data validated - 205 rows over 365 days
    üìä WEBL 3- Training: Horizon=60d, Target=10.81% (B&H: 65.78%, Scale=0.164)
‚úÖ WEBL: Training data validated - 205 rows over 365 days
    üìä DOUG 3- Training: Horizon=60d, Target=10.78% (B&H: 65.57%, Scale=0.164)
‚úÖ DOUG: Training data validated - 205 rows over 365 days
    üìä RYTM 3- Training: Horizon=60d, Target=10.69% (B&H: 65.01%, Scale=0.164)
‚úÖ RYTM: Training data validated - 205 rows over 365 days
    üìä LITE 3- Training: Horizon=60d, Target=10.67% (B&H: 64.91%, Scale=0.164)
‚úÖ LITE: Training data validated - 205 rows over 365 days
    üìä CAKE 3- Training: Horizon=60d, Target=10.66% (B&H: 64.85%, Scale=0.164)
‚úÖ CAKE: Training data validated - 205 rows over 365 days
    üìä ARKX 3- Training: Horizon=60d, Target=10.62% (B&H: 64.59%, Scale=0.164)
‚úÖ ARKX: Training data validated - 205 rows over 365 days
    üìä LTM 3- Training: Horizon=60d, Target=10.61% (B&H: 64.53%, Scale=0.164)
‚úÖ LTM: Training data validated - 205 rows over 365 days
    üìä AFRM 3- Training: Horizon=60d, Target=10.58% (B&H: 64.36%, Scale=0.164)
‚úÖ AFRM: Training data validated - 205 rows over 365 days
    üìä BCS 3- Training: Horizon=60d, Target=10.58% (B&H: 64.35%, Scale=0.164)
‚úÖ BCS: Training data validated - 205 rows over 365 days
    üìä MPAA 3- Training: Horizon=60d, Target=10.57% (B&H: 64.28%, Scale=0.164)
‚úÖ MPAA: Training data validated - 205 rows over 365 days
    üìä SLI 3- Training: Horizon=60d, Target=10.52% (B&H: 63.98%, Scale=0.164)
‚úÖ SLI: Training data validated - 205 rows over 365 days
    üìä CXW 3- Training: Horizon=60d, Target=10.50% (B&H: 63.87%, Scale=0.164)
‚úÖ CXW: Training data validated - 205 rows over 365 days
    üìä ICL 3- Training: Horizon=60d, Target=10.50% (B&H: 63.87%, Scale=0.164)
‚úÖ ICL: Training data validated - 205 rows over 365 days
    üìä LPLA 3- Training: Horizon=60d, Target=10.49% (B&H: 63.81%, Scale=0.164)
‚úÖ LPLA: Training data validated - 205 rows over 365 days
    üìä GDXU 3- Training: Horizon=60d, Target=10.48% (B&H: 63.77%, Scale=0.164)
‚úÖ GDXU: Training data validated - 205 rows over 365 days
    üìä GFI 3- Training: Horizon=60d, Target=10.48% (B&H: 63.74%, Scale=0.164)
‚úÖ GFI: Training data validated - 205 rows over 365 days
    üìä WBD 3- Training: Horizon=60d, Target=10.44% (B&H: 63.52%, Scale=0.164)
‚úÖ WBD: Training data validated - 205 rows over 365 days
    üìä CTRN 3- Training: Horizon=60d, Target=10.40% (B&H: 63.26%, Scale=0.164)
‚úÖ CTRN: Training data validated - 205 rows over 365 days
    üìä SENEA 3- Training: Horizon=60d, Target=10.40% (B&H: 63.24%, Scale=0.164)
‚úÖ SENEA: Training data validated - 205 rows over 365 days
    üìä CUK 3- Training: Horizon=60d, Target=10.35% (B&H: 62.99%, Scale=0.164)
‚úÖ CUK: Training data validated - 205 rows over 365 days
    üìä MSB 3- Training: Horizon=60d, Target=10.34% (B&H: 62.91%, Scale=0.164)
‚úÖ MSB: Training data validated - 205 rows over 365 days
    üìä VST 3- Training: Horizon=60d, Target=10.34% (B&H: 62.89%, Scale=0.164)
‚úÖ VST: Training data validated - 205 rows over 365 days
    üìä DLTR 3- Training: Horizon=60d, Target=10.31% (B&H: 62.70%, Scale=0.164)
‚úÖ DLTR: Training data validated - 205 rows over 365 days
    üìä TIGO 3- Training: Horizon=60d, Target=10.29% (B&H: 62.60%, Scale=0.164)
‚úÖ TIGO: Training data validated - 205 rows over 365 days
    üìä YBTC 3- Training: Horizon=60d, Target=10.27% (B&H: 62.45%, Scale=0.164)
‚úÖ YBTC: Training data validated - 205 rows over 365 days
    üìä APH 3- Training: Horizon=60d, Target=10.23% (B&H: 62.23%, Scale=0.164)
‚úÖ APH: Training data validated - 205 rows over 365 days
    üìä PCT 3- Training: Horizon=60d, Target=10.21% (B&H: 62.11%, Scale=0.164)
‚úÖ PCT: Training data validated - 205 rows over 365 days
    üìä UFO 3- Training: Horizon=60d, Target=10.19% (B&H: 61.98%, Scale=0.164)
‚úÖ UFO: Training data validated - 205 rows over 365 days
    üìä ZVRA 3- Training: Horizon=60d, Target=10.16% (B&H: 61.82%, Scale=0.164)
‚úÖ ZVRA: Training data validated - 205 rows over 365 days
    üìä MRX 3- Training: Horizon=60d, Target=10.16% (B&H: 61.78%, Scale=0.164)
‚úÖ MRX: Training data validated - 205 rows over 365 days
    üìä SMLR 3- Training: Horizon=60d, Target=10.14% (B&H: 61.70%, Scale=0.164)
‚úÖ SMLR: Training data validated - 205 rows over 365 days
    üìä ARKQ 3- Training: Horizon=60d, Target=10.13% (B&H: 61.64%, Scale=0.164)
‚úÖ ARKQ: Training data validated - 205 rows over 365 days
    üìä ARKK 3- Training: Horizon=60d, Target=10.12% (B&H: 61.56%, Scale=0.164)
‚úÖ ARKK: Training data validated - 205 rows over 365 days
    üìä VRSN 3- Training: Horizon=60d, Target=10.10% (B&H: 61.41%, Scale=0.164)
‚úÖ VRSN: Training data validated - 205 rows over 365 days
    üìä WF 3- Training: Horizon=60d, Target=10.07% (B&H: 61.28%, Scale=0.164)
‚úÖ WF: Training data validated - 205 rows over 365 days
    üìä DAPP 3- Training: Horizon=60d, Target=10.07% (B&H: 61.27%, Scale=0.164)
‚úÖ DAPP: Training data validated - 205 rows over 365 days
    üìä PEGA 3- Training: Horizon=60d, Target=10.07% (B&H: 61.26%, Scale=0.164)
‚úÖ PEGA: Training data validated - 205 rows over 365 days
    üìä ORN 3- Training: Horizon=60d, Target=10.06% (B&H: 61.18%, Scale=0.164)
‚úÖ ORN: Training data validated - 205 rows over 365 days
    üìä BITQ 3- Training: Horizon=60d, Target=10.04% (B&H: 61.07%, Scale=0.164)
‚úÖ BITQ: Training data validated - 205 rows over 365 days
    üìä CCL 3- Training: Horizon=60d, Target=10.02% (B&H: 60.98%, Scale=0.164)
‚úÖ CCL: Training data validated - 205 rows over 365 days
    üìä NUGT 3- Training: Horizon=60d, Target=9.98% (B&H: 60.69%, Scale=0.164)
‚úÖ NUGT: Training data validated - 205 rows over 365 days
    üìä PRIM 3- Training: Horizon=60d, Target=9.93% (B&H: 60.38%, Scale=0.164)
‚úÖ PRIM: Training data validated - 205 rows over 365 days
    üìä IDCC 3- Training: Horizon=60d, Target=9.90% (B&H: 60.23%, Scale=0.164)
‚úÖ IDCC: Training data validated - 205 rows over 365 days
    üìä GTX 3- Training: Horizon=60d, Target=9.88% (B&H: 60.12%, Scale=0.164)
‚úÖ GTX: Training data validated - 205 rows over 365 days
    üìä ITRN 3- Training: Horizon=60d, Target=9.81% (B&H: 59.69%, Scale=0.164)
‚úÖ ITRN: Training data validated - 205 rows over 365 days
    üìä APG 3- Training: Horizon=60d, Target=9.81% (B&H: 59.68%, Scale=0.164)
‚úÖ APG: Training data validated - 205 rows over 365 days
    üìä UAL 3- Training: Horizon=60d, Target=9.81% (B&H: 59.67%, Scale=0.164)
‚úÖ UAL: Training data validated - 205 rows over 365 days
    üìä AEM 3- Training: Horizon=60d, Target=9.77% (B&H: 59.43%, Scale=0.164)
‚úÖ AEM: Training data validated - 205 rows over 365 days
    üìä LUNR 3- Training: Horizon=60d, Target=9.74% (B&H: 59.25%, Scale=0.164)
‚úÖ LUNR: Training data validated - 205 rows over 365 days
    üìä HIPO 3- Training: Horizon=60d, Target=9.70% (B&H: 59.00%, Scale=0.164)
‚úÖ HIPO: Training data validated - 205 rows over 365 days
    üìä PRA 3- Training: Horizon=60d, Target=9.57% (B&H: 58.24%, Scale=0.164)
‚úÖ PRA: Training data validated - 205 rows over 365 days
    üìä DAN 3- Training: Horizon=60d, Target=9.52% (B&H: 57.93%, Scale=0.164)
‚úÖ DAN: Training data validated - 205 rows over 365 days
    üìä TGTX 3- Training: Horizon=60d, Target=9.49% (B&H: 57.76%, Scale=0.164)
‚úÖ TGTX: Training data validated - 205 rows over 365 days
    üìä AVPT 3- Training: Horizon=60d, Target=9.48% (B&H: 57.69%, Scale=0.164)
‚úÖ AVPT: Training data validated - 205 rows over 365 days
    üìä RDVT 3- Training: Horizon=60d, Target=9.46% (B&H: 57.57%, Scale=0.164)
‚úÖ RDVT: Training data validated - 205 rows over 365 days
    üìä VSTA 3- Training: Horizon=60d, Target=9.45% (B&H: 57.49%, Scale=0.164)
‚úÖ VSTA: Training data validated - 205 rows over 365 days
    üìä AAMI 3- Training: Horizon=60d, Target=9.42% (B&H: 57.33%, Scale=0.164)
‚úÖ AAMI: Training data validated - 205 rows over 365 days
    üìä ENVX 3- Training: Horizon=60d, Target=9.42% (B&H: 57.28%, Scale=0.164)
‚úÖ ENVX: Training data validated - 205 rows over 365 days
    üìä ASA 3- Training: Horizon=60d, Target=9.41% (B&H: 57.25%, Scale=0.164)
‚úÖ ASA: Training data validated - 205 rows over 365 days
    üìä C 3- Training: Horizon=60d, Target=9.39% (B&H: 57.15%, Scale=0.164)
‚úÖ C: Training data validated - 205 rows over 365 days
    üìä FNGO 3- Training: Horizon=60d, Target=9.38% (B&H: 57.07%, Scale=0.164)
‚úÖ FNGO: Training data validated - 205 rows over 365 days
    üìä FIVE 3- Training: Horizon=60d, Target=9.36% (B&H: 56.96%, Scale=0.164)
‚úÖ FIVE: Training data validated - 205 rows over 365 days
    üìä YPF 3- Training: Horizon=60d, Target=9.26% (B&H: 56.34%, Scale=0.164)
‚úÖ YPF: Training data validated - 205 rows over 365 days
    üìä NWG 3- Training: Horizon=60d, Target=9.25% (B&H: 56.29%, Scale=0.164)
‚úÖ NWG: Training data validated - 205 rows over 365 days
    üìä PW 3- Training: Horizon=60d, Target=9.21% (B&H: 56.00%, Scale=0.164)
‚úÖ PW: Training data validated - 205 rows over 365 days
    üìä UPXI 3- Training: Horizon=60d, Target=9.18% (B&H: 55.87%, Scale=0.164)
‚úÖ UPXI: Training data validated - 205 rows over 365 days
    üìä CD 3- Training: Horizon=60d, Target=9.16% (B&H: 55.75%, Scale=0.164)
‚úÖ CD: Training data validated - 205 rows over 365 days
    üìä ADTN 3- Training: Horizon=60d, Target=9.15% (B&H: 55.65%, Scale=0.164)
‚úÖ ADTN: Training data validated - 205 rows over 365 days
    üìä RL 3- Training: Horizon=60d, Target=9.12% (B&H: 55.46%, Scale=0.164)
‚úÖ RL: Training data validated - 205 rows over 365 days
    üìä SHOP 3- Training: Horizon=60d, Target=9.08% (B&H: 55.27%, Scale=0.164)
‚úÖ SHOP: Training data validated - 205 rows over 365 days
    üìä WPM 3- Training: Horizon=60d, Target=9.02% (B&H: 54.87%, Scale=0.164)
‚úÖ WPM: Training data validated - 205 rows over 365 days
    üìä AAP 3- Training: Horizon=60d, Target=8.91% (B&H: 54.19%, Scale=0.164)
‚úÖ AAP: Training data validated - 205 rows over 365 days
    üìä ZLAB 3- Training: Horizon=60d, Target=8.87% (B&H: 53.98%, Scale=0.164)
‚úÖ ZLAB: Training data validated - 205 rows over 365 days
    üìä RRGB 3- Training: Horizon=60d, Target=8.87% (B&H: 53.97%, Scale=0.164)
‚úÖ RRGB: Training data validated - 205 rows over 365 days
    üìä GRND 3- Training: Horizon=60d, Target=8.76% (B&H: 53.31%, Scale=0.164)
‚úÖ GRND: Training data validated - 205 rows over 365 days
    üìä BA 3- Training: Horizon=60d, Target=8.76% (B&H: 53.29%, Scale=0.164)
‚úÖ BA: Training data validated - 205 rows over 365 days
    üìä BBAR 3- Training: Horizon=60d, Target=8.75% (B&H: 53.23%, Scale=0.164)
‚úÖ BBAR: Training data validated - 205 rows over 365 days
    üìä BELFB 3- Training: Horizon=60d, Target=8.74% (B&H: 53.16%, Scale=0.164)
‚úÖ BELFB: Training data validated - 205 rows over 365 days
    üìä NGD 3- Training: Horizon=60d, Target=8.73% (B&H: 53.12%, Scale=0.164)
‚úÖ NGD: Training data validated - 205 rows over 365 days
    üìä HTT 3- Training: Horizon=60d, Target=8.72% (B&H: 53.05%, Scale=0.164)
‚úÖ HTT: Training data validated - 205 rows over 365 days
    üìä CAE 3- Training: Horizon=60d, Target=8.71% (B&H: 52.96%, Scale=0.164)
‚úÖ CAE: Training data validated - 205 rows over 365 days
    üìä BTF 3- Training: Horizon=60d, Target=8.66% (B&H: 52.68%, Scale=0.164)
‚úÖ BTF: Training data validated - 205 rows over 365 days
    üìä ATGE 3- Training: Horizon=60d, Target=8.63% (B&H: 52.52%, Scale=0.164)
‚úÖ ATGE: Training data validated - 205 rows over 365 days
    üìä GREK 3- Training: Horizon=60d, Target=8.61% (B&H: 52.35%, Scale=0.164)
‚úÖ GREK: Training data validated - 205 rows over 365 days
    üìä LRN 3- Training: Horizon=60d, Target=8.60% (B&H: 52.32%, Scale=0.164)
‚úÖ LRN: Training data validated - 205 rows over 365 days
    üìä AVAL 3- Training: Horizon=60d, Target=8.60% (B&H: 52.32%, Scale=0.164)
‚úÖ AVAL: Training data validated - 205 rows over 365 days
    üìä ESQ 3- Training: Horizon=60d, Target=8.58% (B&H: 52.20%, Scale=0.164)
‚úÖ ESQ: Training data validated - 205 rows over 365 days
    üìä OR 3- Training: Horizon=60d, Target=8.53% (B&H: 51.87%, Scale=0.164)
‚úÖ OR: Training data validated - 205 rows over 365 days
    üìä WFC 3- Training: Horizon=60d, Target=8.50% (B&H: 51.69%, Scale=0.164)
‚úÖ WFC: Training data validated - 205 rows over 365 days
    üìä BBW 3- Training: Horizon=60d, Target=8.49% (B&H: 51.66%, Scale=0.164)
‚úÖ BBW: Training data validated - 205 rows over 365 days
    üìä SCHW 3- Training: Horizon=60d, Target=8.43% (B&H: 51.26%, Scale=0.164)
‚úÖ SCHW: Training data validated - 205 rows over 365 days
    üìä MTZ 3- Training: Horizon=60d, Target=8.42% (B&H: 51.25%, Scale=0.164)
‚úÖ MTZ: Training data validated - 205 rows over 365 days
    üìä QTUM 3- Training: Horizon=60d, Target=8.42% (B&H: 51.20%, Scale=0.164)
‚úÖ QTUM: Training data validated - 205 rows over 365 days
    üìä ACAD 3- Training: Horizon=60d, Target=8.41% (B&H: 51.17%, Scale=0.164)
‚úÖ ACAD: Training data validated - 205 rows over 365 days
    üìä ROAD 3- Training: Horizon=60d, Target=8.39% (B&H: 51.06%, Scale=0.164)
‚úÖ ROAD: Training data validated - 205 rows over 365 days
    üìä HSBC 3- Training: Horizon=60d, Target=8.39% (B&H: 51.05%, Scale=0.164)
‚úÖ HSBC: Training data validated - 205 rows over 365 days
    üìä TGS 3- Training: Horizon=60d, Target=8.37% (B&H: 50.93%, Scale=0.164)
‚úÖ TGS: Training data validated - 205 rows over 365 days
    üìä BTI 3- Training: Horizon=60d, Target=8.35% (B&H: 50.82%, Scale=0.164)
‚úÖ BTI: Training data validated - 205 rows over 365 days
    üìä MFG 3- Training: Horizon=60d, Target=8.35% (B&H: 50.82%, Scale=0.164)
‚úÖ MFG: Training data validated - 205 rows over 365 days
    üìä LFCR 3- Training: Horizon=60d, Target=8.34% (B&H: 50.71%, Scale=0.164)
‚úÖ LFCR: Training data validated - 205 rows over 365 days
    üìä WWD 3- Training: Horizon=60d, Target=8.32% (B&H: 50.64%, Scale=0.164)
‚úÖ WWD: Training data validated - 205 rows over 365 days
    üìä DGP 3- Training: Horizon=60d, Target=8.32% (B&H: 50.60%, Scale=0.164)
‚úÖ DGP: Training data validated - 205 rows over 365 days
    üìä CG 3- Training: Horizon=60d, Target=8.30% (B&H: 50.50%, Scale=0.164)
‚úÖ CG: Training data validated - 205 rows over 365 days
    üìä WOR 3- Training: Horizon=60d, Target=8.30% (B&H: 50.46%, Scale=0.164)
‚úÖ WOR: Training data validated - 205 rows over 365 days
    üìä SGDM 3- Training: Horizon=60d, Target=8.29% (B&H: 50.46%, Scale=0.164)
‚úÖ SGDM: Training data validated - 205 rows over 365 days
    üìä BRNS 3- Training: Horizon=60d, Target=8.29% (B&H: 50.42%, Scale=0.164)
‚úÖ BRNS: Training data validated - 205 rows over 365 days
    üìä FHN 3- Training: Horizon=60d, Target=8.27% (B&H: 50.31%, Scale=0.164)
‚úÖ FHN: Training data validated - 205 rows over 365 days
    üìä NFLY 3- Training: Horizon=60d, Target=8.26% (B&H: 50.26%, Scale=0.164)
‚úÖ NFLY: Training data validated - 205 rows over 365 days
    üìä URA 3- Training: Horizon=60d, Target=8.25% (B&H: 50.17%, Scale=0.164)
‚úÖ URA: Training data validated - 205 rows over 365 days
    üìä IDT 3- Training: Horizon=60d, Target=8.24% (B&H: 50.15%, Scale=0.164)
‚úÖ IDT: Training data validated - 205 rows over 365 days
    üìä FINV 3- Training: Horizon=60d, Target=8.24% (B&H: 50.12%, Scale=0.164)
‚úÖ FINV: Training data validated - 205 rows over 365 days
    üìä ECG 3- Training: Horizon=60d, Target=8.23% (B&H: 50.06%, Scale=0.164)
‚úÖ ECG: Training data validated - 205 rows over 365 days
    üìä BWMN 3- Training: Horizon=60d, Target=8.23% (B&H: 50.04%, Scale=0.164)
‚úÖ BWMN: Training data validated - 205 rows over 365 days
    üìä PCRX 3- Training: Horizon=60d, Target=8.19% (B&H: 49.83%, Scale=0.164)
‚úÖ PCRX: Training data validated - 205 rows over 365 days
    üìä CTLP 3- Training: Horizon=60d, Target=8.17% (B&H: 49.73%, Scale=0.164)
‚úÖ CTLP: Training data validated - 205 rows over 365 days
    üìä IPI 3- Training: Horizon=60d, Target=8.14% (B&H: 49.54%, Scale=0.164)
‚úÖ IPI: Training data validated - 205 rows over 365 days
    üìä FLEX 3- Training: Horizon=60d, Target=8.14% (B&H: 49.54%, Scale=0.164)
‚úÖ FLEX: Training data validated - 205 rows over 365 days
    üìä GS 3- Training: Horizon=60d, Target=8.13% (B&H: 49.44%, Scale=0.164)
‚úÖ GS: Training data validated - 205 rows over 365 days
    üìä WRBY 3- Training: Horizon=60d, Target=8.11% (B&H: 49.36%, Scale=0.164)
‚úÖ WRBY: Training data validated - 205 rows over 365 days
    üìä BB 3- Training: Horizon=60d, Target=8.09% (B&H: 49.24%, Scale=0.164)
‚úÖ BB: Training data validated - 205 rows over 365 days
    üìä UGI 3- Training: Horizon=60d, Target=8.08% (B&H: 49.14%, Scale=0.164)
‚úÖ UGI: Training data validated - 205 rows over 365 days
    üìä CALM 3- Training: Horizon=60d, Target=8.06% (B&H: 49.04%, Scale=0.164)
‚úÖ CALM: Training data validated - 205 rows over 365 days
    üìä OSIS 3- Training: Horizon=60d, Target=8.04% (B&H: 48.90%, Scale=0.164)
‚úÖ OSIS: Training data validated - 205 rows over 365 days
    üìä RMBS 3- Training: Horizon=60d, Target=8.03% (B&H: 48.86%, Scale=0.164)
‚úÖ RMBS: Training data validated - 205 rows over 365 days
    üìä CELH 3- Training: Horizon=60d, Target=8.01% (B&H: 48.72%, Scale=0.164)
‚úÖ CELH: Training data validated - 205 rows over 365 days
    üìä UNTY 3- Training: Horizon=60d, Target=7.99% (B&H: 48.64%, Scale=0.164)
‚úÖ UNTY: Training data validated - 205 rows over 365 days
    üìä ESE 3- Training: Horizon=60d, Target=7.99% (B&H: 48.63%, Scale=0.164)
‚úÖ ESE: Training data validated - 205 rows over 365 days
    üìä SYF 3- Training: Horizon=60d, Target=7.92% (B&H: 48.17%, Scale=0.164)
‚úÖ SYF: Training data validated - 205 rows over 365 days
    üìä NTES 3- Training: Horizon=60d, Target=7.92% (B&H: 48.16%, Scale=0.164)
‚úÖ NTES: Training data validated - 205 rows over 365 days
    üìä CHEF 3- Training: Horizon=60d, Target=7.91% (B&H: 48.13%, Scale=0.164)
‚úÖ CHEF: Training data validated - 205 rows over 365 days
    üìä CNM 3- Training: Horizon=60d, Target=7.91% (B&H: 48.13%, Scale=0.164)
‚úÖ CNM: Training data validated - 205 rows over 365 days
    üìä SSP 3- Training: Horizon=60d, Target=7.89% (B&H: 48.00%, Scale=0.164)
‚úÖ SSP: Training data validated - 205 rows over 365 days
    üìä CBRL 3- Training: Horizon=60d, Target=7.88% (B&H: 47.93%, Scale=0.164)
‚úÖ CBRL: Training data validated - 205 rows over 365 days
    üìä VIRT 3- Training: Horizon=60d, Target=7.88% (B&H: 47.92%, Scale=0.164)
‚úÖ VIRT: Training data validated - 205 rows over 365 days
    üìä KMDA 3- Training: Horizon=60d, Target=7.87% (B&H: 47.88%, Scale=0.164)
‚úÖ KMDA: Training data validated - 205 rows over 365 days
    üìä EME 3- Training: Horizon=60d, Target=7.86% (B&H: 47.82%, Scale=0.164)
‚úÖ EME: Training data validated - 205 rows over 365 days
    üìä CW 3- Training: Horizon=60d, Target=7.85% (B&H: 47.78%, Scale=0.164)
‚úÖ CW: Training data validated - 205 rows over 365 days
    üìä NTRS 3- Training: Horizon=60d, Target=7.83% (B&H: 47.61%, Scale=0.164)
‚úÖ NTRS: Training data validated - 205 rows over 365 days
    üìä CORT 3- Training: Horizon=60d, Target=7.82% (B&H: 47.56%, Scale=0.164)
‚úÖ CORT: Training data validated - 205 rows over 365 days
    üìä TFPM 3- Training: Horizon=60d, Target=7.81% (B&H: 47.52%, Scale=0.164)
‚úÖ TFPM: Training data validated - 205 rows over 365 days
    üìä SUPV 3- Training: Horizon=60d, Target=7.80% (B&H: 47.48%, Scale=0.164)
‚úÖ SUPV: Training data validated - 205 rows over 365 days
    üìä DRD 3- Training: Horizon=60d, Target=7.80% (B&H: 47.45%, Scale=0.164)
‚úÖ DRD: Training data validated - 205 rows over 365 days
    üìä ACMR 3- Training: Horizon=60d, Target=7.80% (B&H: 47.44%, Scale=0.164)
‚úÖ ACMR: Training data validated - 205 rows over 365 days
    üìä INBX 3- Training: Horizon=60d, Target=7.79% (B&H: 47.38%, Scale=0.164)
‚úÖ INBX: Training data validated - 205 rows over 365 days
    üìä FSM 3- Training: Horizon=60d, Target=7.78% (B&H: 47.30%, Scale=0.164)
‚úÖ FSM: Training data validated - 205 rows over 365 days
    üìä HUYA 3- Training: Horizon=60d, Target=7.77% (B&H: 47.29%, Scale=0.164)
‚úÖ HUYA: Training data validated - 205 rows over 365 days
    üìä OPLN 3- Training: Horizon=60d, Target=7.75% (B&H: 47.16%, Scale=0.164)
‚úÖ OPLN: Training data validated - 205 rows over 365 days
    üìä JOYY 3- Training: Horizon=60d, Target=7.73% (B&H: 47.03%, Scale=0.164)
‚úÖ JOYY: Training data validated - 205 rows over 365 days
    üìä MUFG 3- Training: Horizon=60d, Target=7.72% (B&H: 46.93%, Scale=0.164)
‚úÖ MUFG: Training data validated - 205 rows over 365 days
    üìä GILT 3- Training: Horizon=60d, Target=7.70% (B&H: 46.87%, Scale=0.164)
‚úÖ GILT: Training data validated - 205 rows over 365 days
    üìä PFIX 3- Training: Horizon=60d, Target=7.69% (B&H: 46.80%, Scale=0.164)
‚úÖ PFIX: Training data validated - 205 rows over 365 days
    üìä MRP 3- Training: Horizon=60d, Target=7.67% (B&H: 46.64%, Scale=0.164)
  ‚ùå MRP: Too many NaN values in Close price: 87 / 205 rows
   üí° Data quality issue - try different data source or date range
    üìä AHR 3- Training: Horizon=60d, Target=7.66% (B&H: 46.59%, Scale=0.164)
‚úÖ AHR: Training data validated - 205 rows over 365 days
    üìä SERV 3- Training: Horizon=60d, Target=7.65% (B&H: 46.54%, Scale=0.164)
‚úÖ SERV: Training data validated - 205 rows over 365 days
    üìä SGDJ 3- Training: Horizon=60d, Target=7.65% (B&H: 46.54%, Scale=0.164)
‚úÖ SGDJ: Training data validated - 205 rows over 365 days
    üìä IRS 3- Training: Horizon=60d, Target=7.65% (B&H: 46.53%, Scale=0.164)
‚úÖ IRS: Training data validated - 205 rows over 365 days
    üìä UGL 3- Training: Horizon=60d, Target=7.63% (B&H: 46.42%, Scale=0.164)
‚úÖ UGL: Training data validated - 205 rows over 365 days
    üìä TE 3- Training: Horizon=60d, Target=7.63% (B&H: 46.39%, Scale=0.164)
‚úÖ TE: Training data validated - 205 rows over 365 days
    üìä TTWO 3- Training: Horizon=60d, Target=7.60% (B&H: 46.22%, Scale=0.164)
‚úÖ TTWO: Training data validated - 205 rows over 365 days
    üìä SIL 3- Training: Horizon=60d, Target=7.60% (B&H: 46.21%, Scale=0.164)
‚úÖ SIL: Training data validated - 205 rows over 365 days
    üìä FGM 3- Training: Horizon=60d, Target=7.58% (B&H: 46.12%, Scale=0.164)
‚úÖ FGM: Training data validated - 205 rows over 365 days
    üìä NVDU 3- Training: Horizon=60d, Target=7.57% (B&H: 46.04%, Scale=0.164)
‚úÖ NVDU: Training data validated - 205 rows over 365 days
    üìä FDIG 3- Training: Horizon=60d, Target=7.55% (B&H: 45.90%, Scale=0.164)
‚úÖ FDIG: Training data validated - 205 rows over 365 days
    üìä SFM 3- Training: Horizon=60d, Target=7.54% (B&H: 45.88%, Scale=0.164)
‚úÖ SFM: Training data validated - 205 rows over 365 days
    üìä NLR 3- Training: Horizon=60d, Target=7.54% (B&H: 45.85%, Scale=0.164)
‚úÖ NLR: Training data validated - 205 rows over 365 days
    üìä JCI 3- Training: Horizon=60d, Target=7.53% (B&H: 45.80%, Scale=0.164)
‚úÖ JCI: Training data validated - 205 rows over 365 days
    üìä EXK 3- Training: Horizon=60d, Target=7.47% (B&H: 45.43%, Scale=0.164)
‚úÖ EXK: Training data validated - 205 rows over 365 days
    üìä BFC 3- Training: Horizon=60d, Target=7.46% (B&H: 45.41%, Scale=0.164)
‚úÖ BFC: Training data validated - 205 rows over 365 days
    üìä NERD 3- Training: Horizon=60d, Target=7.46% (B&H: 45.38%, Scale=0.164)
‚úÖ NERD: Training data validated - 205 rows over 365 days
    üìä ORCL 3- Training: Horizon=60d, Target=7.46% (B&H: 45.35%, Scale=0.164)
‚úÖ ORCL: Training data validated - 205 rows over 365 days
    üìä EPOL 3- Training: Horizon=60d, Target=7.44% (B&H: 45.27%, Scale=0.164)
‚úÖ EPOL: Training data validated - 205 rows over 365 days
    üìä SLM 3- Training: Horizon=60d, Target=7.41% (B&H: 45.08%, Scale=0.164)
‚úÖ SLM: Training data validated - 205 rows over 365 days
    üìä LB 3- Training: Horizon=60d, Target=7.37% (B&H: 44.85%, Scale=0.164)
‚úÖ LB: Training data validated - 205 rows over 365 days
    üìä GE 3- Training: Horizon=60d, Target=7.35% (B&H: 44.73%, Scale=0.164)
‚úÖ GE: Training data validated - 205 rows over 365 days
    üìä OCS 3- Training: Horizon=60d, Target=7.31% (B&H: 44.45%, Scale=0.164)
‚úÖ OCS: Training data validated - 205 rows over 365 days
    üìä TITN 3- Training: Horizon=60d, Target=7.30% (B&H: 44.44%, Scale=0.164)
‚úÖ TITN: Training data validated - 205 rows over 365 days
    üìä MCK 3- Training: Horizon=60d, Target=7.30% (B&H: 44.44%, Scale=0.164)
‚úÖ MCK: Training data validated - 205 rows over 365 days
    üìä CAH 3- Training: Horizon=60d, Target=7.30% (B&H: 44.42%, Scale=0.164)
‚úÖ CAH: Training data validated - 205 rows over 365 days
    üìä GTES 3- Training: Horizon=60d, Target=7.27% (B&H: 44.22%, Scale=0.164)
‚úÖ GTES: Training data validated - 205 rows over 365 days
    üìä LOMA 3- Training: Horizon=60d, Target=7.26% (B&H: 44.17%, Scale=0.164)
‚úÖ LOMA: Training data validated - 205 rows over 365 days
    üìä NVDL 3- Training: Horizon=60d, Target=7.25% (B&H: 44.10%, Scale=0.164)
‚úÖ NVDL: Training data validated - 205 rows over 365 days
    üìä KODK 3- Training: Horizon=60d, Target=7.24% (B&H: 44.07%, Scale=0.164)
‚úÖ KODK: Training data validated - 205 rows over 365 days
    üìä PAYC 3- Training: Horizon=60d, Target=7.24% (B&H: 44.06%, Scale=0.164)
‚úÖ PAYC: Training data validated - 205 rows over 365 days
    üìä SANM 3- Training: Horizon=60d, Target=7.24% (B&H: 44.02%, Scale=0.164)
‚úÖ SANM: Training data validated - 205 rows over 365 days
    üìä IZRL 3- Training: Horizon=60d, Target=7.23% (B&H: 44.01%, Scale=0.164)
‚úÖ IZRL: Training data validated - 205 rows over 365 days
    üìä EQT 3- Training: Horizon=60d, Target=7.22% (B&H: 43.89%, Scale=0.164)
‚úÖ EQT: Training data validated - 205 rows over 365 days
    üìä CIEN 3- Training: Horizon=60d, Target=7.21% (B&H: 43.85%, Scale=0.164)
‚úÖ CIEN: Training data validated - 205 rows over 365 days
    üìä BK 3- Training: Horizon=60d, Target=7.19% (B&H: 43.73%, Scale=0.164)
‚úÖ BK: Training data validated - 205 rows over 365 days
    üìä OPY 3- Training: Horizon=60d, Target=7.17% (B&H: 43.62%, Scale=0.164)
‚úÖ OPY: Training data validated - 205 rows over 365 days
    üìä ULS 3- Training: Horizon=60d, Target=7.17% (B&H: 43.60%, Scale=0.164)
‚úÖ ULS: Training data validated - 205 rows over 365 days
    üìä IFS 3- Training: Horizon=60d, Target=7.16% (B&H: 43.57%, Scale=0.164)
‚úÖ IFS: Training data validated - 205 rows over 365 days
    üìä COF 3- Training: Horizon=60d, Target=7.15% (B&H: 43.50%, Scale=0.164)
‚úÖ COF: Training data validated - 205 rows over 365 days
    üìä UEC 3- Training: Horizon=60d, Target=7.15% (B&H: 43.48%, Scale=0.164)
‚úÖ UEC: Training data validated - 205 rows over 365 days
    üìä METCB 3- Training: Horizon=60d, Target=7.13% (B&H: 43.40%, Scale=0.164)
‚úÖ METCB: Training data validated - 205 rows over 365 days
    üìä SXT 3- Training: Horizon=60d, Target=7.13% (B&H: 43.39%, Scale=0.164)
‚úÖ SXT: Training data validated - 205 rows over 365 days
    üìä EIS 3- Training: Horizon=60d, Target=7.11% (B&H: 43.27%, Scale=0.164)
‚úÖ EIS: Training data validated - 205 rows over 365 days
    üìä AG 3- Training: Horizon=60d, Target=7.11% (B&H: 43.23%, Scale=0.164)
‚úÖ AG: Training data validated - 205 rows over 365 days
    üìä ATLC 3- Training: Horizon=60d, Target=7.10% (B&H: 43.22%, Scale=0.164)
‚úÖ ATLC: Training data validated - 205 rows over 365 days
    üìä MRCY 3- Training: Horizon=60d, Target=7.10% (B&H: 43.19%, Scale=0.164)
‚úÖ MRCY: Training data validated - 205 rows over 365 days
    üìä FROG 3- Training: Horizon=60d, Target=7.08% (B&H: 43.04%, Scale=0.164)
‚úÖ FROG: Training data validated - 205 rows over 365 days
    üìä LZ 3- Training: Horizon=60d, Target=7.07% (B&H: 42.99%, Scale=0.164)
‚úÖ LZ: Training data validated - 205 rows over 365 days
    üìä PAY 3- Training: Horizon=60d, Target=7.06% (B&H: 42.96%, Scale=0.164)
‚úÖ PAY: Training data validated - 205 rows over 365 days
    üìä TSM 3- Training: Horizon=60d, Target=7.06% (B&H: 42.94%, Scale=0.164)
‚úÖ TSM: Training data validated - 205 rows over 365 days
    üìä NVDA 3- Training: Horizon=60d, Target=7.05% (B&H: 42.90%, Scale=0.164)
‚úÖ NVDA: Training data validated - 205 rows over 365 days
    üìä GOAU 3- Training: Horizon=60d, Target=7.05% (B&H: 42.87%, Scale=0.164)
‚úÖ GOAU: Training data validated - 205 rows over 365 days
    üìä LYG 3- Training: Horizon=60d, Target=7.00% (B&H: 42.60%, Scale=0.164)
‚úÖ LYG: Training data validated - 205 rows over 365 days
    üìä GDXJ 3- Training: Horizon=60d, Target=6.99% (B&H: 42.53%, Scale=0.164)
‚úÖ GDXJ: Training data validated - 205 rows over 365 days
    üìä ATRA 3- Training: Horizon=60d, Target=6.98% (B&H: 42.44%, Scale=0.164)
‚úÖ ATRA: Training data validated - 205 rows over 365 days
    üìä UAN 3- Training: Horizon=60d, Target=6.97% (B&H: 42.43%, Scale=0.164)
‚úÖ UAN: Training data validated - 205 rows over 365 days
    üìä CRMD 3- Training: Horizon=60d, Target=6.94% (B&H: 42.20%, Scale=0.164)
‚úÖ CRMD: Training data validated - 205 rows over 365 days
    üìä NAMS 3- Training: Horizon=60d, Target=6.93% (B&H: 42.17%, Scale=0.164)
‚úÖ NAMS: Training data validated - 205 rows over 365 days
    üìä HGV 3- Training: Horizon=60d, Target=6.93% (B&H: 42.15%, Scale=0.164)
‚úÖ HGV: Training data validated - 205 rows over 365 days
    üìä DEC 3- Training: Horizon=60d, Target=6.93% (B&H: 42.15%, Scale=0.164)
‚úÖ DEC: Training data validated - 205 rows over 365 days
    üìä PLTM 3- Training: Horizon=60d, Target=6.92% (B&H: 42.12%, Scale=0.164)
‚úÖ PLTM: Training data validated - 205 rows over 365 days
    üìä PPLT 3- Training: Horizon=60d, Target=6.92% (B&H: 42.12%, Scale=0.164)
‚úÖ PPLT: Training data validated - 205 rows over 365 days
    üìä DLO 3- Training: Horizon=60d, Target=6.90% (B&H: 42.00%, Scale=0.164)
‚úÖ DLO: Training data validated - 205 rows over 365 days
    üìä ATI 3- Training: Horizon=60d, Target=6.90% (B&H: 41.97%, Scale=0.164)
‚úÖ ATI: Training data validated - 205 rows over 365 days
    üìä ESPO 3- Training: Horizon=60d, Target=6.89% (B&H: 41.91%, Scale=0.164)
‚úÖ ESPO: Training data validated - 205 rows over 365 days
    üìä VLN 3- Training: Horizon=60d, Target=6.87% (B&H: 41.82%, Scale=0.164)
‚úÖ VLN: Training data validated - 205 rows over 365 days
    üìä AMPL 3- Training: Horizon=60d, Target=6.87% (B&H: 41.81%, Scale=0.164)
‚úÖ AMPL: Training data validated - 205 rows over 365 days
    üìä GILD 3- Training: Horizon=60d, Target=6.86% (B&H: 41.74%, Scale=0.164)
‚úÖ GILD: Training data validated - 205 rows over 365 days
    üìä CTOR 3- Training: Horizon=60d, Target=6.86% (B&H: 41.73%, Scale=0.164)
‚úÖ CTOR: Training data validated - 205 rows over 365 days
    üìä TNL 3- Training: Horizon=60d, Target=6.84% (B&H: 41.61%, Scale=0.164)
‚úÖ TNL: Training data validated - 205 rows over 365 days
    üìä PWR 3- Training: Horizon=60d, Target=6.84% (B&H: 41.61%, Scale=0.164)
‚úÖ PWR: Training data validated - 205 rows over 365 days
    üìä EWO 3- Training: Horizon=60d, Target=6.84% (B&H: 41.58%, Scale=0.164)
‚úÖ EWO: Training data validated - 205 rows over 365 days
    üìä PAAS 3- Training: Horizon=60d, Target=6.82% (B&H: 41.48%, Scale=0.164)
‚úÖ PAAS: Training data validated - 205 rows over 365 days
    üìä JBTM 3- Training: Horizon=60d, Target=6.82% (B&H: 41.46%, Scale=0.164)
‚úÖ JBTM: Training data validated - 205 rows over 365 days
    üìä SLVP 3- Training: Horizon=60d, Target=6.78% (B&H: 41.22%, Scale=0.164)
‚úÖ SLVP: Training data validated - 205 rows over 365 days
    üìä NPK 3- Training: Horizon=60d, Target=6.77% (B&H: 41.19%, Scale=0.164)
‚úÖ NPK: Training data validated - 205 rows over 365 days
    üìä CENX 3- Training: Horizon=60d, Target=6.76% (B&H: 41.10%, Scale=0.164)
‚úÖ CENX: Training data validated - 205 rows over 365 days
    üìä GRAB 3- Training: Horizon=60d, Target=6.75% (B&H: 41.05%, Scale=0.164)
‚úÖ GRAB: Training data validated - 205 rows over 365 days
    üìä MOS 3- Training: Horizon=60d, Target=6.74% (B&H: 41.00%, Scale=0.164)
‚úÖ MOS: Training data validated - 205 rows over 365 days
    üìä CASY 3- Training: Horizon=60d, Target=6.72% (B&H: 40.90%, Scale=0.164)
‚úÖ CASY: Training data validated - 205 rows over 365 days
    üìä XAR 3- Training: Horizon=60d, Target=6.72% (B&H: 40.87%, Scale=0.164)
‚úÖ XAR: Training data validated - 205 rows over 365 days
    üìä NIC 3- Training: Horizon=60d, Target=6.70% (B&H: 40.73%, Scale=0.164)
‚úÖ NIC: Training data validated - 205 rows over 365 days
    üìä QXO 3- Training: Horizon=60d, Target=6.69% (B&H: 40.71%, Scale=0.164)
‚úÖ QXO: Training data validated - 205 rows over 365 days
    üìä STX 3- Training: Horizon=60d, Target=6.68% (B&H: 40.66%, Scale=0.164)
‚úÖ STX: Training data validated - 205 rows over 365 days
    üìä ETH 3- Training: Horizon=60d, Target=6.68% (B&H: 40.66%, Scale=0.164)
‚úÖ ETH: Training data validated - 205 rows over 365 days
    üìä BKCH 3- Training: Horizon=60d, Target=6.64% (B&H: 40.39%, Scale=0.164)
‚úÖ BKCH: Training data validated - 205 rows over 365 days
    üìä OCUL 3- Training: Horizon=60d, Target=6.63% (B&H: 40.34%, Scale=0.164)
‚úÖ OCUL: Training data validated - 205 rows over 365 days
    üìä ETHW 3- Training: Horizon=60d, Target=6.63% (B&H: 40.33%, Scale=0.164)
‚úÖ ETHW: Training data validated - 205 rows over 365 days
    üìä ETHV 3- Training: Horizon=60d, Target=6.63% (B&H: 40.32%, Scale=0.164)
‚úÖ ETHV: Training data validated - 205 rows over 365 days
    üìä POET 3- Training: Horizon=60d, Target=6.63% (B&H: 40.32%, Scale=0.164)
‚úÖ POET: Training data validated - 205 rows over 365 days
    üìä EZET 3- Training: Horizon=60d, Target=6.62% (B&H: 40.29%, Scale=0.164)
‚úÖ EZET: Training data validated - 205 rows over 365 days
    üìä RSI 3- Training: Horizon=60d, Target=6.62% (B&H: 40.28%, Scale=0.164)
‚úÖ RSI: Training data validated - 205 rows over 365 days
    üìä FETH 3- Training: Horizon=60d, Target=6.61% (B&H: 40.24%, Scale=0.164)
‚úÖ FETH: Training data validated - 205 rows over 365 days
    üìä PERI 3- Training: Horizon=60d, Target=6.61% (B&H: 40.23%, Scale=0.164)
‚úÖ PERI: Training data validated - 205 rows over 365 days
    üìä TETH 3- Training: Horizon=60d, Target=6.61% (B&H: 40.22%, Scale=0.164)
‚úÖ TETH: Training data validated - 205 rows over 365 days
    üìä ETHA 3- Training: Horizon=60d, Target=6.61% (B&H: 40.21%, Scale=0.164)
‚úÖ ETHA: Training data validated - 205 rows over 365 days
    üìä PTON 3- Training: Horizon=60d, Target=6.60% (B&H: 40.17%, Scale=0.164)
‚úÖ PTON: Training data validated - 205 rows over 365 days
    üìä LAUR 3- Training: Horizon=60d, Target=6.59% (B&H: 40.10%, Scale=0.164)
‚úÖ LAUR: Training data validated - 205 rows over 365 days
    üìä WGMI 3- Training: Horizon=60d, Target=6.58% (B&H: 40.01%, Scale=0.164)
‚úÖ WGMI: Training data validated - 205 rows over 365 days
    üìä QETH 3- Training: Horizon=60d, Target=6.57% (B&H: 39.98%, Scale=0.164)
‚úÖ QETH: Training data validated - 205 rows over 365 days
    üìä PLMR 3- Training: Horizon=60d, Target=6.57% (B&H: 39.98%, Scale=0.164)
‚úÖ PLMR: Training data validated - 205 rows over 365 days
    üìä BTSG 3- Training: Horizon=60d, Target=6.55% (B&H: 39.85%, Scale=0.164)
‚úÖ BTSG: Training data validated - 205 rows over 365 days
    üìä RING 3- Training: Horizon=60d, Target=6.55% (B&H: 39.84%, Scale=0.164)
‚úÖ RING: Training data validated - 205 rows over 365 days
    üìä LYV 3- Training: Horizon=60d, Target=6.54% (B&H: 39.79%, Scale=0.164)
‚úÖ LYV: Training data validated - 205 rows over 365 days
    üìä HMY 3- Training: Horizon=60d, Target=6.53% (B&H: 39.71%, Scale=0.164)
‚úÖ HMY: Training data validated - 205 rows over 365 days
    üìä FTI 3- Training: Horizon=60d, Target=6.52% (B&H: 39.68%, Scale=0.164)
‚úÖ FTI: Training data validated - 205 rows over 365 days
    üìä USD 3- Training: Horizon=60d, Target=6.51% (B&H: 39.60%, Scale=0.164)
‚úÖ USD: Training data validated - 205 rows over 365 days
    üìä TEL 3- Training: Horizon=60d, Target=6.51% (B&H: 39.58%, Scale=0.164)
‚úÖ TEL: Training data validated - 205 rows over 365 days
    üìä RJF 3- Training: Horizon=60d, Target=6.50% (B&H: 39.53%, Scale=0.164)
‚úÖ RJF: Training data validated - 205 rows over 365 days
    üìä MAIN 3- Training: Horizon=60d, Target=6.50% (B&H: 39.52%, Scale=0.164)
‚úÖ MAIN: Training data validated - 205 rows over 365 days
    üìä DOCS 3- Training: Horizon=60d, Target=6.49% (B&H: 39.48%, Scale=0.164)
‚úÖ DOCS: Training data validated - 205 rows over 365 days
    üìä ATAT 3- Training: Horizon=60d, Target=6.49% (B&H: 39.46%, Scale=0.164)
‚úÖ ATAT: Training data validated - 205 rows over 365 days
    üìä BYRN 3- Training: Horizon=60d, Target=6.47% (B&H: 39.36%, Scale=0.164)
‚úÖ BYRN: Training data validated - 205 rows over 365 days
    üìä CX 3- Training: Horizon=60d, Target=6.46% (B&H: 39.29%, Scale=0.164)
‚úÖ CX: Training data validated - 205 rows over 365 days
    üìä UNM 3- Training: Horizon=60d, Target=6.42% (B&H: 39.07%, Scale=0.164)
‚úÖ UNM: Training data validated - 205 rows over 365 days
    üìä EUFN 3- Training: Horizon=60d, Target=6.39% (B&H: 38.84%, Scale=0.164)
‚úÖ EUFN: Training data validated - 205 rows over 365 days
    üìä PLNT 3- Training: Horizon=60d, Target=6.38% (B&H: 38.82%, Scale=0.164)
‚úÖ PLNT: Training data validated - 205 rows over 365 days
    üìä CSV 3- Training: Horizon=60d, Target=6.38% (B&H: 38.81%, Scale=0.164)
‚úÖ CSV: Training data validated - 205 rows over 365 days
    üìä TMV 3- Training: Horizon=60d, Target=6.38% (B&H: 38.78%, Scale=0.164)
‚úÖ TMV: Training data validated - 205 rows over 365 days
    üìä MCB 3- Training: Horizon=60d, Target=6.37% (B&H: 38.78%, Scale=0.164)
‚úÖ MCB: Training data validated - 205 rows over 365 days
    üìä UAE 3- Training: Horizon=60d, Target=6.37% (B&H: 38.75%, Scale=0.164)
‚úÖ UAE: Training data validated - 205 rows over 365 days
    üìä PJT 3- Training: Horizon=60d, Target=6.37% (B&H: 38.74%, Scale=0.164)
‚úÖ PJT: Training data validated - 205 rows over 365 days
    üìä HNST 3- Training: Horizon=60d, Target=6.35% (B&H: 38.66%, Scale=0.164)
‚úÖ HNST: Training data validated - 205 rows over 365 days
    üìä MBI 3- Training: Horizon=60d, Target=6.35% (B&H: 38.66%, Scale=0.164)
‚úÖ MBI: Training data validated - 205 rows over 365 days
    üìä EMR 3- Training: Horizon=60d, Target=6.34% (B&H: 38.56%, Scale=0.164)
‚úÖ EMR: Training data validated - 205 rows over 365 days
    üìä ING 3- Training: Horizon=60d, Target=6.34% (B&H: 38.55%, Scale=0.164)
‚úÖ ING: Training data validated - 205 rows over 365 days
    üìä TMAT 3- Training: Horizon=60d, Target=6.31% (B&H: 38.39%, Scale=0.164)
‚úÖ TMAT: Training data validated - 205 rows over 365 days
    üìä VEEV 3- Training: Horizon=60d, Target=6.31% (B&H: 38.38%, Scale=0.164)
‚úÖ VEEV: Training data validated - 205 rows over 365 days
    üìä GTLS 3- Training: Horizon=60d, Target=6.31% (B&H: 38.38%, Scale=0.164)
‚úÖ GTLS: Training data validated - 205 rows over 365 days
    üìä VRT 3- Training: Horizon=60d, Target=6.30% (B&H: 38.32%, Scale=0.164)
‚úÖ VRT: Training data validated - 205 rows over 365 days
    üìä TKO 3- Training: Horizon=60d, Target=6.27% (B&H: 38.15%, Scale=0.164)
‚úÖ TKO: Training data validated - 205 rows over 365 days
    üìä PUK 3- Training: Horizon=60d, Target=6.27% (B&H: 38.14%, Scale=0.164)
‚úÖ PUK: Training data validated - 205 rows over 365 days
    üìä SPNT 3- Training: Horizon=60d, Target=6.25% (B&H: 38.01%, Scale=0.164)
‚úÖ SPNT: Training data validated - 205 rows over 365 days
    üìä WT 3- Training: Horizon=60d, Target=6.25% (B&H: 38.00%, Scale=0.164)
‚úÖ WT: Training data validated - 205 rows over 365 days
    üìä DDS 3- Training: Horizon=60d, Target=6.24% (B&H: 37.93%, Scale=0.164)
‚úÖ DDS: Training data validated - 205 rows over 365 days
    üìä IAI 3- Training: Horizon=60d, Target=6.24% (B&H: 37.93%, Scale=0.164)
‚úÖ IAI: Training data validated - 205 rows over 365 days
    üìä PGNY 3- Training: Horizon=60d, Target=6.23% (B&H: 37.89%, Scale=0.164)
‚úÖ PGNY: Training data validated - 205 rows over 365 days
    üìä SGI 3- Training: Horizon=60d, Target=6.22% (B&H: 37.83%, Scale=0.164)
‚úÖ SGI: Training data validated - 205 rows over 365 days
    üìä STN 3- Training: Horizon=60d, Target=6.21% (B&H: 37.77%, Scale=0.164)
‚úÖ STN: Training data validated - 205 rows over 365 days
    üìä ETHE 3- Training: Horizon=60d, Target=6.20% (B&H: 37.73%, Scale=0.164)
‚úÖ ETHE: Training data validated - 205 rows over 365 days
    üìä FAS 3- Training: Horizon=60d, Target=6.20% (B&H: 37.69%, Scale=0.164)
‚úÖ FAS: Training data validated - 205 rows over 365 days
    üìä BAP 3- Training: Horizon=60d, Target=6.19% (B&H: 37.66%, Scale=0.164)
‚úÖ BAP: Training data validated - 205 rows over 365 days
    üìä OLLI 3- Training: Horizon=60d, Target=6.18% (B&H: 37.58%, Scale=0.164)
‚úÖ OLLI: Training data validated - 205 rows over 365 days
    üìä NRGV 3- Training: Horizon=60d, Target=6.16% (B&H: 37.50%, Scale=0.164)
‚úÖ NRGV: Training data validated - 205 rows over 365 days
    üìä KLTR 3- Training: Horizon=60d, Target=6.16% (B&H: 37.50%, Scale=0.164)
‚úÖ KLTR: Training data validated - 205 rows over 365 days
    üìä MTW 3- Training: Horizon=60d, Target=6.15% (B&H: 37.42%, Scale=0.164)
‚úÖ MTW: Training data validated - 205 rows over 365 days
    üìä DCO 3- Training: Horizon=60d, Target=6.15% (B&H: 37.40%, Scale=0.164)
‚úÖ DCO: Training data validated - 205 rows over 365 days
    üìä TRMB 3- Training: Horizon=60d, Target=6.13% (B&H: 37.28%, Scale=0.164)
‚úÖ TRMB: Training data validated - 205 rows over 365 days
    üìä KT 3- Training: Horizon=60d, Target=6.13% (B&H: 37.28%, Scale=0.164)
‚úÖ KT: Training data validated - 205 rows over 365 days
    üìä FHI 3- Training: Horizon=60d, Target=6.11% (B&H: 37.18%, Scale=0.164)
‚úÖ FHI: Training data validated - 205 rows over 365 days
    üìä GDX 3- Training: Horizon=60d, Target=6.10% (B&H: 37.10%, Scale=0.164)
‚úÖ GDX: Training data validated - 205 rows over 365 days
    üìä BWXT 3- Training: Horizon=60d, Target=6.09% (B&H: 37.04%, Scale=0.164)
‚úÖ BWXT: Training data validated - 205 rows over 365 days
    üìä ETR 3- Training: Horizon=60d, Target=6.09% (B&H: 37.03%, Scale=0.164)
‚úÖ ETR: Training data validated - 205 rows over 365 days
    üìä CGNT 3- Training: Horizon=60d, Target=6.08% (B&H: 36.97%, Scale=0.164)
‚úÖ CGNT: Training data validated - 205 rows over 365 days
    üìä SAH 3- Training: Horizon=60d, Target=6.06% (B&H: 36.89%, Scale=0.164)
‚úÖ SAH: Training data validated - 205 rows over 365 days
    üìä FPX 3- Training: Horizon=60d, Target=6.06% (B&H: 36.86%, Scale=0.164)
‚úÖ FPX: Training data validated - 205 rows over 365 days
    üìä TBPH 3- Training: Horizon=60d, Target=6.06% (B&H: 36.85%, Scale=0.164)
‚úÖ TBPH: Training data validated - 205 rows over 365 days
    üìä RBA 3- Training: Horizon=60d, Target=6.04% (B&H: 36.73%, Scale=0.164)
‚úÖ RBA: Training data validated - 205 rows over 365 days
    üìä TCBX 3- Training: Horizon=60d, Target=6.04% (B&H: 36.72%, Scale=0.164)
‚úÖ TCBX: Training data validated - 205 rows over 365 days
    üìä CHAT 3- Training: Horizon=60d, Target=6.03% (B&H: 36.69%, Scale=0.164)
‚úÖ CHAT: Training data validated - 205 rows over 365 days
    üìä WWW 3- Training: Horizon=60d, Target=6.00% (B&H: 36.52%, Scale=0.164)
‚úÖ WWW: Training data validated - 205 rows over 365 days
    üìä METV 3- Training: Horizon=60d, Target=5.98% (B&H: 36.40%, Scale=0.164)
‚úÖ METV: Training data validated - 205 rows over 365 days
    üìä BAM 3- Training: Horizon=60d, Target=5.96% (B&H: 36.28%, Scale=0.164)
‚úÖ BAM: Training data validated - 205 rows over 365 days
    üìä PM 3- Training: Horizon=60d, Target=5.96% (B&H: 36.23%, Scale=0.164)
‚úÖ PM: Training data validated - 205 rows over 365 days
    üìä AVAV 3- Training: Horizon=60d, Target=5.93% (B&H: 36.10%, Scale=0.164)
‚úÖ AVAV: Training data validated - 205 rows over 365 days
    üìä OKTA 3- Training: Horizon=60d, Target=5.92% (B&H: 36.00%, Scale=0.164)
‚úÖ OKTA: Training data validated - 205 rows over 365 days
    üìä EFXT 3- Training: Horizon=60d, Target=5.91% (B&H: 35.96%, Scale=0.164)
‚úÖ EFXT: Training data validated - 205 rows over 365 days
    üìä FFIV 3- Training: Horizon=60d, Target=5.91% (B&H: 35.95%, Scale=0.164)
‚úÖ FFIV: Training data validated - 205 rows over 365 days
    üìä FAST 3- Training: Horizon=60d, Target=5.90% (B&H: 35.91%, Scale=0.164)
‚úÖ FAST: Training data validated - 205 rows over 365 days
    üìä FBIO 3- Training: Horizon=60d, Target=5.90% (B&H: 35.86%, Scale=0.164)
‚úÖ FBIO: Training data validated - 205 rows over 365 days
    üìä GENI 3- Training: Horizon=60d, Target=5.87% (B&H: 35.71%, Scale=0.164)
‚úÖ GENI: Training data validated - 205 rows over 365 days
    üìä LGND 3- Training: Horizon=60d, Target=5.87% (B&H: 35.71%, Scale=0.164)
‚úÖ LGND: Training data validated - 205 rows over 365 days
    üìä IGIC 3- Training: Horizon=60d, Target=5.87% (B&H: 35.71%, Scale=0.164)
‚úÖ IGIC: Training data validated - 205 rows over 365 days
    üìä NGVC 3- Training: Horizon=60d, Target=5.87% (B&H: 35.69%, Scale=0.164)
‚úÖ NGVC: Training data validated - 205 rows over 365 days
    üìä HLF 3- Training: Horizon=60d, Target=5.85% (B&H: 35.61%, Scale=0.164)
‚úÖ HLF: Training data validated - 205 rows over 365 days
    üìä MTA 3- Training: Horizon=60d, Target=5.85% (B&H: 35.60%, Scale=0.164)
‚úÖ MTA: Training data validated - 205 rows over 365 days
    üìä GRMN 3- Training: Horizon=60d, Target=5.82% (B&H: 35.41%, Scale=0.164)
‚úÖ GRMN: Training data validated - 205 rows over 365 days
    üìä OSW 3- Training: Horizon=60d, Target=5.82% (B&H: 35.41%, Scale=0.164)
‚úÖ OSW: Training data validated - 205 rows over 365 days
    üìä EMBJ 3- Training: Horizon=60d, Target=5.82% (B&H: 35.39%, Scale=0.164)
‚úÖ EMBJ: Training data validated - 205 rows over 365 days
    üìä ROK 3- Training: Horizon=60d, Target=5.81% (B&H: 35.33%, Scale=0.164)
‚úÖ ROK: Training data validated - 205 rows over 365 days
    üìä ISRA 3- Training: Horizon=60d, Target=5.79% (B&H: 35.24%, Scale=0.164)
‚úÖ ISRA: Training data validated - 205 rows over 365 days
    üìä FTNT 3- Training: Horizon=60d, Target=5.78% (B&H: 35.16%, Scale=0.164)
‚úÖ FTNT: Training data validated - 205 rows over 365 days
    üìä MEXX 3- Training: Horizon=60d, Target=5.77% (B&H: 35.09%, Scale=0.164)
‚úÖ MEXX: Training data validated - 205 rows over 365 days
    üìä FOX 3- Training: Horizon=60d, Target=5.76% (B&H: 35.02%, Scale=0.164)
‚úÖ FOX: Training data validated - 205 rows over 365 days
    üìä TOYO 3- Training: Horizon=60d, Target=5.76% (B&H: 35.02%, Scale=0.164)
‚úÖ TOYO: Training data validated - 205 rows over 365 days
    üìä BBCP 3- Training: Horizon=60d, Target=5.74% (B&H: 34.90%, Scale=0.164)
‚úÖ BBCP: Training data validated - 205 rows over 365 days
    üìä CDE 3- Training: Horizon=60d, Target=5.73% (B&H: 34.88%, Scale=0.164)
‚úÖ CDE: Training data validated - 205 rows over 365 days
    üìä WRLD 3- Training: Horizon=60d, Target=5.73% (B&H: 34.84%, Scale=0.164)
‚úÖ WRLD: Training data validated - 205 rows over 365 days
    üìä STRK 3- Training: Horizon=60d, Target=5.73% (B&H: 34.83%, Scale=0.164)
  ‚ùå STRK: Too many NaN values in Close price: 85 / 205 rows
   üí° Data quality issue - try different data source or date range
    üìä AX 3- Training: Horizon=60d, Target=5.71% (B&H: 34.73%, Scale=0.164)
‚úÖ AX: Training data validated - 205 rows over 365 days
    üìä IIIV 3- Training: Horizon=60d, Target=5.69% (B&H: 34.63%, Scale=0.164)
‚úÖ IIIV: Training data validated - 205 rows over 365 days
    üìä TR 3- Training: Horizon=60d, Target=5.68% (B&H: 34.55%, Scale=0.164)
‚úÖ TR: Training data validated - 205 rows over 365 days
    üìä BLX 3- Training: Horizon=60d, Target=5.68% (B&H: 34.55%, Scale=0.164)
‚úÖ BLX: Training data validated - 205 rows over 365 days
    üìä CBNK 3- Training: Horizon=60d, Target=5.68% (B&H: 34.53%, Scale=0.164)
‚úÖ CBNK: Training data validated - 205 rows over 365 days
    üìä FOXA 3- Training: Horizon=60d, Target=5.67% (B&H: 34.52%, Scale=0.164)
‚úÖ FOXA: Training data validated - 205 rows over 365 days
    üìä LANV 3- Training: Horizon=60d, Target=5.67% (B&H: 34.50%, Scale=0.164)
‚úÖ LANV: Training data validated - 205 rows over 365 days
    üìä BFH 3- Training: Horizon=60d, Target=5.66% (B&H: 34.46%, Scale=0.164)
‚úÖ BFH: Training data validated - 205 rows over 365 days
    üìä BKNG 3- Training: Horizon=60d, Target=5.66% (B&H: 34.44%, Scale=0.164)
‚úÖ BKNG: Training data validated - 205 rows over 365 days
    üìä IAG 3- Training: Horizon=60d, Target=5.66% (B&H: 34.42%, Scale=0.164)
‚úÖ IAG: Training data validated - 205 rows over 365 days
    üìä ELPC 3- Training: Horizon=60d, Target=5.65% (B&H: 34.36%, Scale=0.164)
‚úÖ ELPC: Training data validated - 205 rows over 365 days
    üìä LOUP 3- Training: Horizon=60d, Target=5.64% (B&H: 34.32%, Scale=0.164)
‚úÖ LOUP: Training data validated - 205 rows over 365 days
    üìä CFLT 3- Training: Horizon=60d, Target=5.62% (B&H: 34.20%, Scale=0.164)
‚úÖ CFLT: Training data validated - 205 rows over 365 days
    üìä FDD 3- Training: Horizon=60d, Target=5.62% (B&H: 34.18%, Scale=0.164)
‚úÖ FDD: Training data validated - 205 rows over 365 days
    üìä GLXY 3- Training: Horizon=60d, Target=5.62% (B&H: 34.17%, Scale=0.164)
  ‚ùå GLXY: Too many NaN values in Close price: 157 / 205 rows
   üí° Data quality issue - try different data source or date range
    üìä MEDP 3- Training: Horizon=60d, Target=5.60% (B&H: 34.06%, Scale=0.164)
‚úÖ MEDP: Training data validated - 205 rows over 365 days
    üìä ARLO 3- Training: Horizon=60d, Target=5.59% (B&H: 34.02%, Scale=0.164)
‚úÖ ARLO: Training data validated - 205 rows over 365 days
    üìä COCO 3- Training: Horizon=60d, Target=5.58% (B&H: 33.95%, Scale=0.164)
‚úÖ COCO: Training data validated - 205 rows over 365 days
    üìä BYD 3- Training: Horizon=60d, Target=5.57% (B&H: 33.91%, Scale=0.164)
‚úÖ BYD: Training data validated - 205 rows over 365 days
    üìä AEIS 3- Training: Horizon=60d, Target=5.57% (B&H: 33.88%, Scale=0.164)
‚úÖ AEIS: Training data validated - 205 rows over 365 days
    üìä AZZ 3- Training: Horizon=60d, Target=5.57% (B&H: 33.87%, Scale=0.164)
‚úÖ AZZ: Training data validated - 205 rows over 365 days
    üìä ECNS 3- Training: Horizon=60d, Target=5.55% (B&H: 33.78%, Scale=0.164)
‚úÖ ECNS: Training data validated - 205 rows over 365 days
    üìä USFD 3- Training: Horizon=60d, Target=5.55% (B&H: 33.76%, Scale=0.164)
‚úÖ USFD: Training data validated - 205 rows over 365 days
    üìä OMF 3- Training: Horizon=60d, Target=5.55% (B&H: 33.75%, Scale=0.164)
‚úÖ OMF: Training data validated - 205 rows over 365 days
    üìä MRUS 3- Training: Horizon=60d, Target=5.55% (B&H: 33.75%, Scale=0.164)
‚úÖ MRUS: Training data validated - 205 rows over 365 days
    üìä TXNM 3- Training: Horizon=60d, Target=5.55% (B&H: 33.74%, Scale=0.164)
‚úÖ TXNM: Training data validated - 205 rows over 365 days
    üìä XPP 3- Training: Horizon=60d, Target=5.54% (B&H: 33.69%, Scale=0.164)
‚úÖ XPP: Training data validated - 205 rows over 365 days
    üìä EWP 3- Training: Horizon=60d, Target=5.53% (B&H: 33.64%, Scale=0.164)
‚úÖ EWP: Training data validated - 205 rows over 365 days
    üìä WDC 3- Training: Horizon=60d, Target=5.52% (B&H: 33.58%, Scale=0.164)
‚úÖ WDC: Training data validated - 205 rows over 365 days
    üìä PAC 3- Training: Horizon=60d, Target=5.51% (B&H: 33.55%, Scale=0.164)
‚úÖ PAC: Training data validated - 205 rows over 365 days
    üìä T 3- Training: Horizon=60d, Target=5.47% (B&H: 33.25%, Scale=0.164)
‚úÖ T: Training data validated - 205 rows over 365 days
    üìä ITA 3- Training: Horizon=60d, Target=5.46% (B&H: 33.23%, Scale=0.164)
‚úÖ ITA: Training data validated - 205 rows over 365 days
    üìä QUAD 3- Training: Horizon=60d, Target=5.46% (B&H: 33.20%, Scale=0.164)
‚úÖ QUAD: Training data validated - 205 rows over 365 days
    üìä LENZ 3- Training: Horizon=60d, Target=5.46% (B&H: 33.19%, Scale=0.164)
‚úÖ LENZ: Training data validated - 205 rows over 365 days
    üìä PRLB 3- Training: Horizon=60d, Target=5.45% (B&H: 33.16%, Scale=0.164)
‚úÖ PRLB: Training data validated - 205 rows over 365 days
    üìä SHAK 3- Training: Horizon=60d, Target=5.44% (B&H: 33.12%, Scale=0.164)
‚úÖ SHAK: Training data validated - 205 rows over 365 days
    üìä FNGS 3- Training: Horizon=60d, Target=5.43% (B&H: 33.05%, Scale=0.164)
‚úÖ FNGS: Training data validated - 205 rows over 365 days
    üìä MTRX 3- Training: Horizon=60d, Target=5.43% (B&H: 33.04%, Scale=0.164)
‚úÖ MTRX: Training data validated - 205 rows over 365 days
    üìä MCRI 3- Training: Horizon=60d, Target=5.43% (B&H: 33.01%, Scale=0.164)
‚úÖ MCRI: Training data validated - 205 rows over 365 days
    üìä STVN 3- Training: Horizon=60d, Target=5.41% (B&H: 32.92%, Scale=0.164)
‚úÖ STVN: Training data validated - 205 rows over 365 days
    üìä CNP 3- Training: Horizon=60d, Target=5.41% (B&H: 32.91%, Scale=0.164)
‚úÖ CNP: Training data validated - 205 rows over 365 days
    üìä MIRM 3- Training: Horizon=60d, Target=5.41% (B&H: 32.90%, Scale=0.164)
‚úÖ MIRM: Training data validated - 205 rows over 365 days
    üìä CUBI 3- Training: Horizon=60d, Target=5.39% (B&H: 32.81%, Scale=0.164)
‚úÖ CUBI: Training data validated - 205 rows over 365 days
    üìä DXCM 3- Training: Horizon=60d, Target=5.38% (B&H: 32.74%, Scale=0.164)
‚úÖ DXCM: Training data validated - 205 rows over 365 days
    üìä RAMP 3- Training: Horizon=60d, Target=5.37% (B&H: 32.65%, Scale=0.164)
‚úÖ RAMP: Training data validated - 205 rows over 365 days
    üìä FWONK 3- Training: Horizon=60d, Target=5.36% (B&H: 32.62%, Scale=0.164)
‚úÖ FWONK: Training data validated - 205 rows over 365 days
    üìä CSCO 3- Training: Horizon=60d, Target=5.36% (B&H: 32.61%, Scale=0.164)
‚úÖ CSCO: Training data validated - 205 rows over 365 days
    üìä CTRI 3- Training: Horizon=60d, Target=5.35% (B&H: 32.57%, Scale=0.164)
‚úÖ CTRI: Training data validated - 205 rows over 365 days
    üìä RPRX 3- Training: Horizon=60d, Target=5.33% (B&H: 32.44%, Scale=0.164)
‚úÖ RPRX: Training data validated - 205 rows over 365 days
    üìä COLO 3- Training: Horizon=60d, Target=5.33% (B&H: 32.42%, Scale=0.164)
‚úÖ COLO: Training data validated - 205 rows over 365 days
    üìä ULTA 3- Training: Horizon=60d, Target=5.32% (B&H: 32.34%, Scale=0.164)
‚úÖ ULTA: Training data validated - 205 rows over 365 days
    üìä FNV 3- Training: Horizon=60d, Target=5.28% (B&H: 32.10%, Scale=0.164)
‚úÖ FNV: Training data validated - 205 rows over 365 days
    üìä GSAT 3- Training: Horizon=60d, Target=5.28% (B&H: 32.10%, Scale=0.164)
‚úÖ GSAT: Training data validated - 205 rows over 365 days
    üìä SKYW 3- Training: Horizon=60d, Target=5.27% (B&H: 32.09%, Scale=0.164)
‚úÖ SKYW: Training data validated - 205 rows over 365 days
    üìä TASK 3- Training: Horizon=60d, Target=5.27% (B&H: 32.04%, Scale=0.164)
‚úÖ TASK: Training data validated - 205 rows over 365 days
    üìä DSP 3- Training: Horizon=60d, Target=5.24% (B&H: 31.89%, Scale=0.164)
‚úÖ DSP: Training data validated - 205 rows over 365 days
    üìä STT 3- Training: Horizon=60d, Target=5.23% (B&H: 31.81%, Scale=0.164)
‚úÖ STT: Training data validated - 205 rows over 365 days
    üìä LIND 3- Training: Horizon=60d, Target=5.22% (B&H: 31.78%, Scale=0.164)
‚úÖ LIND: Training data validated - 205 rows over 365 days
    üìä CME 3- Training: Horizon=60d, Target=5.21% (B&H: 31.71%, Scale=0.164)
‚úÖ CME: Training data validated - 205 rows over 365 days
    üìä AB 3- Training: Horizon=60d, Target=5.20% (B&H: 31.66%, Scale=0.164)
‚úÖ AB: Training data validated - 205 rows over 365 days
    üìä SEIC 3- Training: Horizon=60d, Target=5.19% (B&H: 31.57%, Scale=0.164)
‚úÖ SEIC: Training data validated - 205 rows over 365 days
    üìä WBS 3- Training: Horizon=60d, Target=5.19% (B&H: 31.56%, Scale=0.164)
‚úÖ WBS: Training data validated - 205 rows over 365 days
    üìä PAHC 3- Training: Horizon=60d, Target=5.18% (B&H: 31.53%, Scale=0.164)
‚úÖ PAHC: Training data validated - 205 rows over 365 days
    üìä DAX 3- Training: Horizon=60d, Target=5.18% (B&H: 31.52%, Scale=0.164)
‚úÖ DAX: Training data validated - 205 rows over 365 days
    üìä HERO 3- Training: Horizon=60d, Target=5.18% (B&H: 31.51%, Scale=0.164)
‚úÖ HERO: Training data validated - 205 rows over 365 days
    üìä RTX 3- Training: Horizon=60d, Target=5.18% (B&H: 31.50%, Scale=0.164)
‚úÖ RTX: Training data validated - 205 rows over 365 days
    üìä EWI 3- Training: Horizon=60d, Target=5.16% (B&H: 31.41%, Scale=0.164)
‚úÖ EWI: Training data validated - 205 rows over 365 days
    üìä BMO 3- Training: Horizon=60d, Target=5.16% (B&H: 31.41%, Scale=0.164)
‚úÖ BMO: Training data validated - 205 rows over 365 days
    üìä ECVT 3- Training: Horizon=60d, Target=5.14% (B&H: 31.24%, Scale=0.164)
‚úÖ ECVT: Training data validated - 205 rows over 365 days
    üìä EETH 3- Training: Horizon=60d, Target=5.13% (B&H: 31.18%, Scale=0.164)
‚úÖ EETH: Training data validated - 205 rows over 365 days
    üìä EYPT 3- Training: Horizon=60d, Target=5.12% (B&H: 31.16%, Scale=0.164)
‚úÖ EYPT: Training data validated - 205 rows over 365 days
    üìä CMCM 3- Training: Horizon=60d, Target=5.12% (B&H: 31.15%, Scale=0.164)
‚úÖ CMCM: Training data validated - 205 rows over 365 days
    üìä NDAQ 3- Training: Horizon=60d, Target=5.12% (B&H: 31.13%, Scale=0.164)
‚úÖ NDAQ: Training data validated - 205 rows over 365 days
    üìä OGIG 3- Training: Horizon=60d, Target=5.11% (B&H: 31.11%, Scale=0.164)
‚úÖ OGIG: Training data validated - 205 rows over 365 days
    üìä CEPU 3- Training: Horizon=60d, Target=5.11% (B&H: 31.10%, Scale=0.164)
‚úÖ CEPU: Training data validated - 205 rows over 365 days
    üìä PAR 3- Training: Horizon=60d, Target=5.11% (B&H: 31.07%, Scale=0.164)
‚úÖ PAR: Training data validated - 205 rows over 365 days
    üìä LTL 3- Training: Horizon=60d, Target=5.10% (B&H: 31.05%, Scale=0.164)
‚úÖ LTL: Training data validated - 205 rows over 365 days
    üìä THFF 3- Training: Horizon=60d, Target=5.08% (B&H: 30.92%, Scale=0.164)
‚úÖ THFF: Training data validated - 205 rows over 365 days
    üìä SMMT 3- Training: Horizon=60d, Target=5.08% (B&H: 30.91%, Scale=0.164)
‚úÖ SMMT: Training data validated - 205 rows over 365 days
    üìä IMAX 3- Training: Horizon=60d, Target=5.08% (B&H: 30.91%, Scale=0.164)
‚úÖ IMAX: Training data validated - 205 rows over 365 days
    üìä SMCI 3- Training: Horizon=60d, Target=5.06% (B&H: 30.81%, Scale=0.164)
‚úÖ SMCI: Training data validated - 205 rows over 365 days
    üìä BGM 3- Training: Horizon=60d, Target=5.06% (B&H: 30.79%, Scale=0.164)
‚úÖ BGM: Training data validated - 205 rows over 365 days
    üìä NG 3- Training: Horizon=60d, Target=5.05% (B&H: 30.73%, Scale=0.164)
‚úÖ NG: Training data validated - 205 rows over 365 days
    üìä FN 3- Training: Horizon=60d, Target=5.04% (B&H: 30.64%, Scale=0.164)
‚úÖ FN: Training data validated - 205 rows over 365 days
    üìä UFCS 3- Training: Horizon=60d, Target=5.04% (B&H: 30.63%, Scale=0.164)
‚úÖ UFCS: Training data validated - 205 rows over 365 days
    üìä NOTV 3- Training: Horizon=60d, Target=5.03% (B&H: 30.59%, Scale=0.164)
‚úÖ NOTV: Training data validated - 205 rows over 365 days
    üìä DG 3- Training: Horizon=60d, Target=5.03% (B&H: 30.58%, Scale=0.164)
‚úÖ DG: Training data validated - 205 rows over 365 days
    üìä SMFG 3- Training: Horizon=60d, Target=5.03% (B&H: 30.58%, Scale=0.164)
‚úÖ SMFG: Training data validated - 205 rows over 365 days
    üìä CCEP 3- Training: Horizon=60d, Target=5.03% (B&H: 30.57%, Scale=0.164)
‚úÖ CCEP: Training data validated - 205 rows over 365 days
    üìä MT 3- Training: Horizon=60d, Target=5.02% (B&H: 30.56%, Scale=0.164)
‚úÖ MT: Training data validated - 205 rows over 365 days
    üìä V 3- Training: Horizon=60d, Target=5.02% (B&H: 30.54%, Scale=0.164)
‚úÖ V: Training data validated - 205 rows over 365 days
    üìä COMM 3- Training: Horizon=60d, Target=5.00% (B&H: 30.44%, Scale=0.164)
‚úÖ COMM: Training data validated - 205 rows over 365 days
    üìä AGQ 3- Training: Horizon=60d, Target=5.00% (B&H: 30.42%, Scale=0.164)
‚úÖ AGQ: Training data validated - 205 rows over 365 days
    üìä GOLF 3- Training: Horizon=60d, Target=5.00% (B&H: 30.41%, Scale=0.164)
‚úÖ GOLF: Training data validated - 205 rows over 365 days
    üìä HCI 3- Training: Horizon=60d, Target=5.00% (B&H: 30.39%, Scale=0.164)
‚úÖ HCI: Training data validated - 205 rows over 365 days
    üìä DTM 3- Training: Horizon=60d, Target=4.99% (B&H: 30.38%, Scale=0.164)
‚úÖ DTM: Training data validated - 205 rows over 365 days
    üìä KBWB 3- Training: Horizon=60d, Target=4.99% (B&H: 30.33%, Scale=0.164)
‚úÖ KBWB: Training data validated - 205 rows over 365 days
    üìä APLD 3- Training: Horizon=60d, Target=4.98% (B&H: 30.30%, Scale=0.164)
‚úÖ APLD: Training data validated - 205 rows over 365 days
    üìä NPKI 3- Training: Horizon=60d, Target=4.98% (B&H: 30.30%, Scale=0.164)
‚úÖ NPKI: Training data validated - 205 rows over 365 days
    üìä OSK 3- Training: Horizon=60d, Target=4.97% (B&H: 30.24%, Scale=0.164)
‚úÖ OSK: Training data validated - 205 rows over 365 days
    üìä DDOG 3- Training: Horizon=60d, Target=4.97% (B&H: 30.23%, Scale=0.164)
‚úÖ DDOG: Training data validated - 205 rows over 365 days
    üìä VCTR 3- Training: Horizon=60d, Target=4.97% (B&H: 30.22%, Scale=0.164)
‚úÖ VCTR: Training data validated - 205 rows over 365 days
    üìä SFST 3- Training: Horizon=60d, Target=4.96% (B&H: 30.19%, Scale=0.164)
‚úÖ SFST: Training data validated - 205 rows over 365 days
    üìä AGI 3- Training: Horizon=60d, Target=4.96% (B&H: 30.16%, Scale=0.164)
‚úÖ AGI: Training data validated - 205 rows over 365 days
    üìä HAFC 3- Training: Horizon=60d, Target=4.95% (B&H: 30.10%, Scale=0.164)
‚úÖ HAFC: Training data validated - 205 rows over 365 days
    üìä FEP 3- Training: Horizon=60d, Target=4.94% (B&H: 30.05%, Scale=0.164)
‚úÖ FEP: Training data validated - 205 rows over 365 days
    üìä WMB 3- Training: Horizon=60d, Target=4.93% (B&H: 29.99%, Scale=0.164)
‚úÖ WMB: Training data validated - 205 rows over 365 days
    üìä ATEN 3- Training: Horizon=60d, Target=4.92% (B&H: 29.94%, Scale=0.164)
‚úÖ ATEN: Training data validated - 205 rows over 365 days
    üìä RZLT 3- Training: Horizon=60d, Target=4.91% (B&H: 29.90%, Scale=0.164)
‚úÖ RZLT: Training data validated - 205 rows over 365 days
    üìä AL 3- Training: Horizon=60d, Target=4.91% (B&H: 29.87%, Scale=0.164)
‚úÖ AL: Training data validated - 205 rows over 365 days
    üìä COR 3- Training: Horizon=60d, Target=4.90% (B&H: 29.84%, Scale=0.164)
‚úÖ COR: Training data validated - 205 rows over 365 days
    üìä ONC 3- Training: Horizon=60d, Target=4.90% (B&H: 29.82%, Scale=0.164)
‚úÖ ONC: Training data validated - 205 rows over 365 days
    üìä NEU 3- Training: Horizon=60d, Target=4.89% (B&H: 29.76%, Scale=0.164)
‚úÖ NEU: Training data validated - 205 rows over 365 days
    üìä YINN 3- Training: Horizon=60d, Target=4.89% (B&H: 29.73%, Scale=0.164)
‚úÖ YINN: Training data validated - 205 rows over 365 days
    üìä RBC 3- Training: Horizon=60d, Target=4.89% (B&H: 29.72%, Scale=0.164)
‚úÖ RBC: Training data validated - 205 rows over 365 days
    üìä PRDO 3- Training: Horizon=60d, Target=4.88% (B&H: 29.71%, Scale=0.164)
‚úÖ PRDO: Training data validated - 205 rows over 365 days
    üìä CSGS 3- Training: Horizon=60d, Target=4.88% (B&H: 29.69%, Scale=0.164)
‚úÖ CSGS: Training data validated - 205 rows over 365 days
    üìä EWS 3- Training: Horizon=60d, Target=4.87% (B&H: 29.62%, Scale=0.164)
‚úÖ EWS: Training data validated - 205 rows over 365 days
    üìä FWONA 3- Training: Horizon=60d, Target=4.87% (B&H: 29.60%, Scale=0.164)
‚úÖ FWONA: Training data validated - 205 rows over 365 days
    üìä BKR 3- Training: Horizon=60d, Target=4.85% (B&H: 29.53%, Scale=0.164)
‚úÖ BKR: Training data validated - 205 rows over 365 days
    üìä NMG 3- Training: Horizon=60d, Target=4.82% (B&H: 29.30%, Scale=0.164)
‚úÖ NMG: Training data validated - 205 rows over 365 days
    üìä MKL 3- Training: Horizon=60d, Target=4.80% (B&H: 29.21%, Scale=0.164)
‚úÖ MKL: Training data validated - 205 rows over 365 days
    üìä NTR 3- Training: Horizon=60d, Target=4.80% (B&H: 29.18%, Scale=0.164)
‚úÖ NTR: Training data validated - 205 rows over 365 days
    üìä SONY 3- Training: Horizon=60d, Target=4.80% (B&H: 29.18%, Scale=0.164)
‚úÖ SONY: Training data validated - 205 rows over 365 days
    üìä BETZ 3- Training: Horizon=60d, Target=4.79% (B&H: 29.11%, Scale=0.164)
‚úÖ BETZ: Training data validated - 205 rows over 365 days
    üìä DUOL 3- Training: Horizon=60d, Target=4.78% (B&H: 29.10%, Scale=0.164)
‚úÖ DUOL: Training data validated - 205 rows over 365 days
    üìä AWI 3- Training: Horizon=60d, Target=4.77% (B&H: 29.02%, Scale=0.164)
‚úÖ AWI: Training data validated - 205 rows over 365 days
    üìä BEN 3- Training: Horizon=60d, Target=4.76% (B&H: 28.98%, Scale=0.164)
‚úÖ BEN: Training data validated - 205 rows over 365 days
    üìä DAKT 3- Training: Horizon=60d, Target=4.76% (B&H: 28.97%, Scale=0.164)
‚úÖ DAKT: Training data validated - 205 rows over 365 days
    üìä DBD 3- Training: Horizon=60d, Target=4.76% (B&H: 28.95%, Scale=0.164)
‚úÖ DBD: Training data validated - 205 rows over 365 days
    üìä NPO 3- Training: Horizon=60d, Target=4.75% (B&H: 28.88%, Scale=0.164)
‚úÖ NPO: Training data validated - 205 rows over 365 days
    üìä VNM 3- Training: Horizon=60d, Target=4.75% (B&H: 28.87%, Scale=0.164)
‚úÖ VNM: Training data validated - 205 rows over 365 days
    üìä NVDY 3- Training: Horizon=60d, Target=4.75% (B&H: 28.87%, Scale=0.164)
‚úÖ NVDY: Training data validated - 205 rows over 365 days
    üìä BMBL 3- Training: Horizon=60d, Target=4.74% (B&H: 28.84%, Scale=0.164)
‚úÖ BMBL: Training data validated - 205 rows over 365 days
    üìä NPCE 3- Training: Horizon=60d, Target=4.74% (B&H: 28.84%, Scale=0.164)
‚úÖ NPCE: Training data validated - 205 rows over 365 days
    üìä IVZ 3- Training: Horizon=60d, Target=4.74% (B&H: 28.80%, Scale=0.164)
‚úÖ IVZ: Training data validated - 205 rows over 365 days
    üìä SILJ 3- Training: Horizon=60d, Target=4.73% (B&H: 28.76%, Scale=0.164)
‚úÖ SILJ: Training data validated - 205 rows over 365 days
    üìä PPA 3- Training: Horizon=60d, Target=4.72% (B&H: 28.73%, Scale=0.164)
‚úÖ PPA: Training data validated - 205 rows over 365 days
    üìä GL 3- Training: Horizon=60d, Target=4.72% (B&H: 28.71%, Scale=0.164)
‚úÖ GL: Training data validated - 205 rows over 365 days
    üìä XPO 3- Training: Horizon=60d, Target=4.71% (B&H: 28.65%, Scale=0.164)
‚úÖ XPO: Training data validated - 205 rows over 365 days
    üìä DOCU 3- Training: Horizon=60d, Target=4.71% (B&H: 28.64%, Scale=0.164)
‚úÖ DOCU: Training data validated - 205 rows over 365 days
    üìä PBYI 3- Training: Horizon=60d, Target=4.71% (B&H: 28.63%, Scale=0.164)
‚úÖ PBYI: Training data validated - 205 rows over 365 days
    üìä WCC 3- Training: Horizon=60d, Target=4.71% (B&H: 28.62%, Scale=0.164)
‚úÖ WCC: Training data validated - 205 rows over 365 days
    üìä EWG 3- Training: Horizon=60d, Target=4.70% (B&H: 28.61%, Scale=0.164)
‚úÖ EWG: Training data validated - 205 rows over 365 days
    üìä FDN 3- Training: Horizon=60d, Target=4.70% (B&H: 28.60%, Scale=0.164)
‚úÖ FDN: Training data validated - 205 rows over 365 days
    üìä DRTS 3- Training: Horizon=60d, Target=4.70% (B&H: 28.57%, Scale=0.164)
‚úÖ DRTS: Training data validated - 205 rows over 365 days
    üìä GLAD 3- Training: Horizon=60d, Target=4.70% (B&H: 28.57%, Scale=0.164)
‚úÖ GLAD: Training data validated - 205 rows over 365 days
    üìä FLUT 3- Training: Horizon=60d, Target=4.69% (B&H: 28.53%, Scale=0.164)
‚úÖ FLUT: Training data validated - 205 rows over 365 days
    üìä NTGR 3- Training: Horizon=60d, Target=4.69% (B&H: 28.51%, Scale=0.164)
‚úÖ NTGR: Training data validated - 205 rows over 365 days
    üìä AFK 3- Training: Horizon=60d, Target=4.68% (B&H: 28.47%, Scale=0.164)
‚úÖ AFK: Training data validated - 205 rows over 365 days
    üìä WAY 3- Training: Horizon=60d, Target=4.68% (B&H: 28.47%, Scale=0.164)
‚úÖ WAY: Training data validated - 205 rows over 365 days
    üìä DRI 3- Training: Horizon=60d, Target=4.68% (B&H: 28.46%, Scale=0.164)
‚úÖ DRI: Training data validated - 205 rows over 365 days
    üìä ALV 3- Training: Horizon=60d, Target=4.66% (B&H: 28.37%, Scale=0.164)
‚úÖ ALV: Training data validated - 205 rows over 365 days
    üìä SYBT 3- Training: Horizon=60d, Target=4.66% (B&H: 28.35%, Scale=0.164)
‚úÖ SYBT: Training data validated - 205 rows over 365 days
    üìä UBS 3- Training: Horizon=60d, Target=4.65% (B&H: 28.31%, Scale=0.164)
‚úÖ UBS: Training data validated - 205 rows over 365 days
    üìä SHCO 3- Training: Horizon=60d, Target=4.64% (B&H: 28.24%, Scale=0.164)
‚úÖ SHCO: Training data validated - 205 rows over 365 days
    üìä FSCO 3- Training: Horizon=60d, Target=4.63% (B&H: 28.18%, Scale=0.164)
‚úÖ FSCO: Training data validated - 205 rows over 365 days
    üìä KMI 3- Training: Horizon=60d, Target=4.63% (B&H: 28.16%, Scale=0.164)
‚úÖ KMI: Training data validated - 205 rows over 365 days
    üìä SPPP 3- Training: Horizon=60d, Target=4.62% (B&H: 28.11%, Scale=0.164)
‚úÖ SPPP: Training data validated - 205 rows over 365 days
    üìä OPPE 3- Training: Horizon=60d, Target=4.61% (B&H: 28.03%, Scale=0.164)
‚úÖ OPPE: Training data validated - 205 rows over 365 days
    üìä WELL 3- Training: Horizon=60d, Target=4.60% (B&H: 27.97%, Scale=0.164)
‚úÖ WELL: Training data validated - 205 rows over 365 days
    üìä YMM 3- Training: Horizon=60d, Target=4.60% (B&H: 27.96%, Scale=0.164)
‚úÖ YMM: Training data validated - 205 rows over 365 days
    üìä RDWR 3- Training: Horizon=60d, Target=4.60% (B&H: 27.96%, Scale=0.164)
‚úÖ RDWR: Training data validated - 205 rows over 365 days
    üìä BNT 3- Training: Horizon=60d, Target=4.59% (B&H: 27.92%, Scale=0.164)
‚úÖ BNT: Training data validated - 205 rows over 365 days
    üìä EGAN 3- Training: Horizon=60d, Target=4.58% (B&H: 27.84%, Scale=0.164)
‚úÖ EGAN: Training data validated - 205 rows over 365 days
    üìä BN 3- Training: Horizon=60d, Target=4.57% (B&H: 27.79%, Scale=0.164)
‚úÖ BN: Training data validated - 205 rows over 365 days
    üìä SPMO 3- Training: Horizon=60d, Target=4.55% (B&H: 27.66%, Scale=0.164)
‚úÖ SPMO: Training data validated - 205 rows over 365 days
    üìä FMS 3- Training: Horizon=60d, Target=4.54% (B&H: 27.63%, Scale=0.164)
‚úÖ FMS: Training data validated - 205 rows over 365 days
    üìä SKWD 3- Training: Horizon=60d, Target=4.54% (B&H: 27.62%, Scale=0.164)
‚úÖ SKWD: Training data validated - 205 rows over 365 days
    üìä BSVN 3- Training: Horizon=60d, Target=4.54% (B&H: 27.60%, Scale=0.164)
‚úÖ BSVN: Training data validated - 205 rows over 365 days
    üìä EWBC 3- Training: Horizon=60d, Target=4.53% (B&H: 27.55%, Scale=0.164)
‚úÖ EWBC: Training data validated - 205 rows over 365 days
    üìä PWRD 3- Training: Horizon=60d, Target=4.53% (B&H: 27.54%, Scale=0.164)
‚úÖ PWRD: Training data validated - 205 rows over 365 days
    üìä CIO 3- Training: Horizon=60d, Target=4.53% (B&H: 27.53%, Scale=0.164)
‚úÖ CIO: Training data validated - 205 rows over 365 days
    üìä BBUC 3- Training: Horizon=60d, Target=4.52% (B&H: 27.51%, Scale=0.164)
‚úÖ BBUC: Training data validated - 205 rows over 365 days
    üìä FET 3- Training: Horizon=60d, Target=4.52% (B&H: 27.49%, Scale=0.164)
‚úÖ FET: Training data validated - 205 rows over 365 days
    üìä NGS 3- Training: Horizon=60d, Target=4.51% (B&H: 27.42%, Scale=0.164)
‚úÖ NGS: Training data validated - 205 rows over 365 days
    üìä DIS 3- Training: Horizon=60d, Target=4.50% (B&H: 27.38%, Scale=0.164)
‚úÖ DIS: Training data validated - 205 rows over 365 days
    üìä INTU 3- Training: Horizon=60d, Target=4.50% (B&H: 27.38%, Scale=0.164)
‚úÖ INTU: Training data validated - 205 rows over 365 days
    üìä GVAL 3- Training: Horizon=60d, Target=4.50% (B&H: 27.35%, Scale=0.164)
‚úÖ GVAL: Training data validated - 205 rows over 365 days
    üìä PAX 3- Training: Horizon=60d, Target=4.49% (B&H: 27.34%, Scale=0.164)
‚úÖ PAX: Training data validated - 205 rows over 365 days
    üìä ALTG 3- Training: Horizon=60d, Target=4.49% (B&H: 27.32%, Scale=0.164)
‚úÖ ALTG: Training data validated - 205 rows over 365 days
    üìä ITRI 3- Training: Horizon=60d, Target=4.49% (B&H: 27.30%, Scale=0.164)
‚úÖ ITRI: Training data validated - 205 rows over 365 days
    üìä ORLY 3- Training: Horizon=60d, Target=4.47% (B&H: 27.21%, Scale=0.164)
‚úÖ ORLY: Training data validated - 205 rows over 365 days
    üìä VALN 3- Training: Horizon=60d, Target=4.46% (B&H: 27.15%, Scale=0.164)
‚úÖ VALN: Training data validated - 205 rows over 365 days
    üìä FFTY 3- Training: Horizon=60d, Target=4.46% (B&H: 27.14%, Scale=0.164)
‚úÖ FFTY: Training data validated - 205 rows over 365 days
    üìä R 3- Training: Horizon=60d, Target=4.46% (B&H: 27.13%, Scale=0.164)
‚úÖ R: Training data validated - 205 rows over 365 days
    üìä EXPE 3- Training: Horizon=60d, Target=4.46% (B&H: 27.13%, Scale=0.164)
‚úÖ EXPE: Training data validated - 205 rows over 365 days
    üìä Z 3- Training: Horizon=60d, Target=4.46% (B&H: 27.11%, Scale=0.164)
‚úÖ Z: Training data validated - 205 rows over 365 days
    üìä EQH 3- Training: Horizon=60d, Target=4.45% (B&H: 27.08%, Scale=0.164)
‚úÖ EQH: Training data validated - 205 rows over 365 days
    üìä TDY 3- Training: Horizon=60d, Target=4.44% (B&H: 27.01%, Scale=0.164)
‚úÖ TDY: Training data validated - 205 rows over 365 days
    üìä OPEN 3- Training: Horizon=60d, Target=4.44% (B&H: 27.00%, Scale=0.164)
‚úÖ OPEN: Training data validated - 205 rows over 365 days
    üìä FDT 3- Training: Horizon=60d, Target=4.43% (B&H: 26.92%, Scale=0.164)
‚úÖ FDT: Training data validated - 205 rows over 365 days
    üìä SAP 3- Training: Horizon=60d, Target=4.42% (B&H: 26.86%, Scale=0.164)
‚úÖ SAP: Training data validated - 205 rows over 365 days
    üìä TEO 3- Training: Horizon=60d, Target=4.41% (B&H: 26.83%, Scale=0.164)
‚úÖ TEO: Training data validated - 205 rows over 365 days
    üìä RELY 3- Training: Horizon=60d, Target=4.41% (B&H: 26.81%, Scale=0.164)
‚úÖ RELY: Training data validated - 205 rows over 365 days
    üìä IAUM 3- Training: Horizon=60d, Target=4.40% (B&H: 26.78%, Scale=0.164)
‚úÖ IAUM: Training data validated - 205 rows over 365 days
    üìä GLDM 3- Training: Horizon=60d, Target=4.40% (B&H: 26.78%, Scale=0.164)
‚úÖ GLDM: Training data validated - 205 rows over 365 days
    üìä BAR 3- Training: Horizon=60d, Target=4.40% (B&H: 26.76%, Scale=0.164)
‚úÖ BAR: Training data validated - 205 rows over 365 days
    üìä DK 3- Training: Horizon=60d, Target=4.40% (B&H: 26.75%, Scale=0.164)
‚úÖ DK: Training data validated - 205 rows over 365 days
    üìä BULZ 3- Training: Horizon=60d, Target=4.39% (B&H: 26.72%, Scale=0.164)
‚úÖ BULZ: Training data validated - 205 rows over 365 days
    üìä SGOL 3- Training: Horizon=60d, Target=4.39% (B&H: 26.70%, Scale=0.164)
‚úÖ SGOL: Training data validated - 205 rows over 365 days
    üìä EBAY 3- Training: Horizon=60d, Target=4.38% (B&H: 26.67%, Scale=0.164)
‚úÖ EBAY: Training data validated - 205 rows over 365 days
    üìä BSX 3- Training: Horizon=60d, Target=4.38% (B&H: 26.66%, Scale=0.164)
‚úÖ BSX: Training data validated - 205 rows over 365 days
    üìä OUNZ 3- Training: Horizon=60d, Target=4.38% (B&H: 26.62%, Scale=0.164)
‚úÖ OUNZ: Training data validated - 205 rows over 365 days
    üìä AAAU 3- Training: Horizon=60d, Target=4.38% (B&H: 26.62%, Scale=0.164)
‚úÖ AAAU: Training data validated - 205 rows over 365 days
    üìä KR 3- Training: Horizon=60d, Target=4.38% (B&H: 26.62%, Scale=0.164)
‚úÖ KR: Training data validated - 205 rows over 365 days
    üìä HACK 3- Training: Horizon=60d, Target=4.37% (B&H: 26.61%, Scale=0.164)
‚úÖ HACK: Training data validated - 205 rows over 365 days
    üìä FINX 3- Training: Horizon=60d, Target=4.37% (B&H: 26.59%, Scale=0.164)
‚úÖ FINX: Training data validated - 205 rows over 365 days
    üìä IAU 3- Training: Horizon=60d, Target=4.37% (B&H: 26.58%, Scale=0.164)
‚úÖ IAU: Training data validated - 205 rows over 365 days
    üìä ASTE 3- Training: Horizon=60d, Target=4.37% (B&H: 26.58%, Scale=0.164)
‚úÖ ASTE: Training data validated - 205 rows over 365 days
    üìä CLSK 3- Training: Horizon=60d, Target=4.36% (B&H: 26.55%, Scale=0.164)
‚úÖ CLSK: Training data validated - 205 rows over 365 days
    üìä UROY 3- Training: Horizon=60d, Target=4.36% (B&H: 26.53%, Scale=0.164)
‚úÖ UROY: Training data validated - 205 rows over 365 days
    üìä ARGT 3- Training: Horizon=60d, Target=4.35% (B&H: 26.48%, Scale=0.164)
‚úÖ ARGT: Training data validated - 205 rows over 365 days
    üìä GLD 3- Training: Horizon=60d, Target=4.35% (B&H: 26.47%, Scale=0.164)
‚úÖ GLD: Training data validated - 205 rows over 365 days
    üìä CPER 3- Training: Horizon=60d, Target=4.34% (B&H: 26.42%, Scale=0.164)
‚úÖ CPER: Training data validated - 205 rows over 365 days
    üìä CIBR 3- Training: Horizon=60d, Target=4.33% (B&H: 26.37%, Scale=0.164)
‚úÖ CIBR: Training data validated - 205 rows over 365 days
    üìä DCTH 3- Training: Horizon=60d, Target=4.33% (B&H: 26.36%, Scale=0.164)
‚úÖ DCTH: Training data validated - 205 rows over 365 days
    üìä BJ 3- Training: Horizon=60d, Target=4.33% (B&H: 26.33%, Scale=0.164)
‚úÖ BJ: Training data validated - 205 rows over 365 days
    üìä FITE 3- Training: Horizon=60d, Target=4.32% (B&H: 26.30%, Scale=0.164)
‚úÖ FITE: Training data validated - 205 rows over 365 days
    üìä ENVA 3- Training: Horizon=60d, Target=4.32% (B&H: 26.29%, Scale=0.164)
‚úÖ ENVA: Training data validated - 205 rows over 365 days
    üìä ZG 3- Training: Horizon=60d, Target=4.31% (B&H: 26.21%, Scale=0.164)
‚úÖ ZG: Training data validated - 205 rows over 365 days
    üìä LNG 3- Training: Horizon=60d, Target=4.30% (B&H: 26.18%, Scale=0.164)
‚úÖ LNG: Training data validated - 205 rows over 365 days
    üìä TARS 3- Training: Horizon=60d, Target=4.30% (B&H: 26.18%, Scale=0.164)
‚úÖ TARS: Training data validated - 205 rows over 365 days
    üìä FER 3- Training: Horizon=60d, Target=4.30% (B&H: 26.18%, Scale=0.164)
‚úÖ FER: Training data validated - 205 rows over 365 days
    üìä KCE 3- Training: Horizon=60d, Target=4.30% (B&H: 26.14%, Scale=0.164)
‚úÖ KCE: Training data validated - 205 rows over 365 days
    üìä SOCL 3- Training: Horizon=60d, Target=4.29% (B&H: 26.11%, Scale=0.164)
‚úÖ SOCL: Training data validated - 205 rows over 365 days
    üìä IGV 3- Training: Horizon=60d, Target=4.29% (B&H: 26.09%, Scale=0.164)
‚úÖ IGV: Training data validated - 205 rows over 365 days
    üìä TBT 3- Training: Horizon=60d, Target=4.29% (B&H: 26.09%, Scale=0.164)
‚úÖ TBT: Training data validated - 205 rows over 365 days
    üìä NTNX 3- Training: Horizon=60d, Target=4.28% (B&H: 26.06%, Scale=0.164)
‚úÖ NTNX: Training data validated - 205 rows over 365 days
    üìä IETC 3- Training: Horizon=60d, Target=4.27% (B&H: 25.97%, Scale=0.164)
‚úÖ IETC: Training data validated - 205 rows over 365 days
    üìä ARTY 3- Training: Horizon=60d, Target=4.26% (B&H: 25.93%, Scale=0.164)
‚úÖ ARTY: Training data validated - 205 rows over 365 days
    üìä KALV 3- Training: Horizon=60d, Target=4.26% (B&H: 25.91%, Scale=0.164)
‚úÖ KALV: Training data validated - 205 rows over 365 days
    üìä CTVA 3- Training: Horizon=60d, Target=4.26% (B&H: 25.89%, Scale=0.164)
‚úÖ CTVA: Training data validated - 205 rows over 365 days
    üìä SPWH 3- Training: Horizon=60d, Target=4.25% (B&H: 25.83%, Scale=0.164)
‚úÖ SPWH: Training data validated - 205 rows over 365 days
    üìä SIXG 3- Training: Horizon=60d, Target=4.22% (B&H: 25.67%, Scale=0.164)
‚úÖ SIXG: Training data validated - 205 rows over 365 days
    üìä OIS 3- Training: Horizon=60d, Target=4.22% (B&H: 25.65%, Scale=0.164)
‚úÖ OIS: Training data validated - 205 rows over 365 days
    üìä ESAB 3- Training: Horizon=60d, Target=4.22% (B&H: 25.64%, Scale=0.164)
‚úÖ ESAB: Training data validated - 205 rows over 365 days
    üìä IYG 3- Training: Horizon=60d, Target=4.21% (B&H: 25.64%, Scale=0.164)
‚úÖ IYG: Training data validated - 205 rows over 365 days
    üìä TS 3- Training: Horizon=60d, Target=4.21% (B&H: 25.63%, Scale=0.164)
‚úÖ TS: Training data validated - 205 rows over 365 days
    üìä PHYS 3- Training: Horizon=60d, Target=4.21% (B&H: 25.61%, Scale=0.164)
‚úÖ PHYS: Training data validated - 205 rows over 365 days
    üìä UPWK 3- Training: Horizon=60d, Target=4.18% (B&H: 25.45%, Scale=0.164)
‚úÖ UPWK: Training data validated - 205 rows over 365 days
    üìä VMI 3- Training: Horizon=60d, Target=4.18% (B&H: 25.43%, Scale=0.164)
‚úÖ VMI: Training data validated - 205 rows over 365 days
    üìä YMAX 3- Training: Horizon=60d, Target=4.17% (B&H: 25.39%, Scale=0.164)
‚úÖ YMAX: Training data validated - 205 rows over 365 days
    üìä PRM 3- Training: Horizon=60d, Target=4.17% (B&H: 25.35%, Scale=0.164)
‚úÖ PRM: Training data validated - 205 rows over 365 days
    üìä DE 3- Training: Horizon=60d, Target=4.16% (B&H: 25.28%, Scale=0.164)
‚úÖ DE: Training data validated - 205 rows over 365 days
    üìä GLTR 3- Training: Horizon=60d, Target=4.15% (B&H: 25.26%, Scale=0.164)
‚úÖ GLTR: Training data validated - 205 rows over 365 days
    üìä PBW 3- Training: Horizon=60d, Target=4.15% (B&H: 25.22%, Scale=0.164)
‚úÖ PBW: Training data validated - 205 rows over 365 days
    üìä HLI 3- Training: Horizon=60d, Target=4.14% (B&H: 25.21%, Scale=0.164)
‚úÖ HLI: Training data validated - 205 rows over 365 days
    üìä PIZ 3- Training: Horizon=60d, Target=4.14% (B&H: 25.19%, Scale=0.164)
‚úÖ PIZ: Training data validated - 205 rows over 365 days
    üìä FXI 3- Training: Horizon=60d, Target=4.14% (B&H: 25.18%, Scale=0.164)
‚úÖ FXI: Training data validated - 205 rows over 365 days
    üìä MVBF 3- Training: Horizon=60d, Target=4.14% (B&H: 25.18%, Scale=0.164)
‚úÖ MVBF: Training data validated - 205 rows over 365 days
    üìä ETOR 3- Training: Horizon=60d, Target=4.13% (B&H: 25.15%, Scale=0.164)
  ‚ùå ETOR: Too many NaN values in Close price: 154 / 205 rows
   üí° Data quality issue - try different data source or date range
    üìä NEM 3- Training: Horizon=60d, Target=4.12% (B&H: 25.06%, Scale=0.164)
‚úÖ NEM: Training data validated - 205 rows over 365 days
    üìä CRBG 3- Training: Horizon=60d, Target=4.11% (B&H: 24.98%, Scale=0.164)
‚úÖ CRBG: Training data validated - 205 rows over 365 days
    üìä IDMO 3- Training: Horizon=60d, Target=4.10% (B&H: 24.97%, Scale=0.164)
‚úÖ IDMO: Training data validated - 205 rows over 365 days
    üìä GEOS 3- Training: Horizon=60d, Target=4.10% (B&H: 24.95%, Scale=0.164)
‚úÖ GEOS: Training data validated - 205 rows over 365 days
    üìä DBP 3- Training: Horizon=60d, Target=4.10% (B&H: 24.94%, Scale=0.164)
‚úÖ DBP: Training data validated - 205 rows over 365 days
    üìä RIVN 3- Training: Horizon=60d, Target=4.09% (B&H: 24.87%, Scale=0.164)
‚úÖ RIVN: Training data validated - 205 rows over 365 days
    üìä SLVO 3- Training: Horizon=60d, Target=4.08% (B&H: 24.82%, Scale=0.164)
‚úÖ SLVO: Training data validated - 205 rows over 365 days
    üìä META 3- Training: Horizon=60d, Target=4.08% (B&H: 24.81%, Scale=0.164)
‚úÖ META: Training data validated - 205 rows over 365 days
    üìä HWKN 3- Training: Horizon=60d, Target=4.08% (B&H: 24.81%, Scale=0.164)
‚úÖ HWKN: Training data validated - 205 rows over 365 days
    üìä GLW 3- Training: Horizon=60d, Target=4.07% (B&H: 24.76%, Scale=0.164)
‚úÖ GLW: Training data validated - 205 rows over 365 days
    üìä ASLE 3- Training: Horizon=60d, Target=4.07% (B&H: 24.75%, Scale=0.164)
‚úÖ ASLE: Training data validated - 205 rows over 365 days
    üìä CLM 3- Training: Horizon=60d, Target=4.07% (B&H: 24.73%, Scale=0.164)
‚úÖ CLM: Training data validated - 205 rows over 365 days
    üìä PODD 3- Training: Horizon=60d, Target=4.06% (B&H: 24.69%, Scale=0.164)
‚úÖ PODD: Training data validated - 205 rows over 365 days
    üìä WUGI 3- Training: Horizon=60d, Target=4.06% (B&H: 24.68%, Scale=0.164)
‚úÖ WUGI: Training data validated - 205 rows over 365 days
    üìä RIGL 3- Training: Horizon=60d, Target=4.05% (B&H: 24.66%, Scale=0.164)
‚úÖ RIGL: Training data validated - 205 rows over 365 days
    üìä OZK 3- Training: Horizon=60d, Target=4.05% (B&H: 24.64%, Scale=0.164)
‚úÖ OZK: Training data validated - 205 rows over 365 days
    üìä HEI-A 3- Training: Horizon=60d, Target=4.04% (B&H: 24.60%, Scale=0.164)
‚úÖ HEI-A: Training data validated - 205 rows over 365 days
    üìä NTB 3- Training: Horizon=60d, Target=4.03% (B&H: 24.51%, Scale=0.164)
‚úÖ NTB: Training data validated - 205 rows over 365 days
    üìä FSK 3- Training: Horizon=60d, Target=4.03% (B&H: 24.50%, Scale=0.164)
‚úÖ FSK: Training data validated - 205 rows over 365 days
    üìä PSKY 3- Training: Horizon=60d, Target=4.02% (B&H: 24.49%, Scale=0.164)
‚úÖ PSKY: Training data validated - 205 rows over 365 days
    üìä NI 3- Training: Horizon=60d, Target=4.02% (B&H: 24.46%, Scale=0.164)
‚úÖ NI: Training data validated - 205 rows over 365 days
    üìä HDB 3- Training: Horizon=60d, Target=4.01% (B&H: 24.42%, Scale=0.164)
‚úÖ HDB: Training data validated - 205 rows over 365 days
    üìä TG 3- Training: Horizon=60d, Target=4.01% (B&H: 24.42%, Scale=0.164)
‚úÖ TG: Training data validated - 205 rows over 365 days
    üìä TD 3- Training: Horizon=60d, Target=4.00% (B&H: 24.36%, Scale=0.164)
‚úÖ TD: Training data validated - 205 rows over 365 days
    üìä NBN 3- Training: Horizon=60d, Target=4.00% (B&H: 24.35%, Scale=0.164)
‚úÖ NBN: Training data validated - 205 rows over 365 days
    üìä IDV 3- Training: Horizon=60d, Target=4.00% (B&H: 24.34%, Scale=0.164)
‚úÖ IDV: Training data validated - 205 rows over 365 days
    üìä AMZY 3- Training: Horizon=60d, Target=4.00% (B&H: 24.32%, Scale=0.164)
‚úÖ AMZY: Training data validated - 205 rows over 365 days
    üìä NRIM 3- Training: Horizon=60d, Target=3.99% (B&H: 24.30%, Scale=0.164)
‚úÖ NRIM: Training data validated - 205 rows over 365 days
    üìä JTEK 3- Training: Horizon=60d, Target=3.99% (B&H: 24.28%, Scale=0.164)
‚úÖ JTEK: Training data validated - 205 rows over 365 days
    üìä AMZN 3- Training: Horizon=60d, Target=3.98% (B&H: 24.21%, Scale=0.164)
‚úÖ AMZN: Training data validated - 205 rows over 365 days
    üìä CFG 3- Training: Horizon=60d, Target=3.97% (B&H: 24.17%, Scale=0.164)
‚úÖ CFG: Training data validated - 205 rows over 365 days
    üìä CRMT 3- Training: Horizon=60d, Target=3.97% (B&H: 24.14%, Scale=0.164)
‚úÖ CRMT: Training data validated - 205 rows over 365 days
    üìä DTST 3- Training: Horizon=60d, Target=3.97% (B&H: 24.14%, Scale=0.164)
‚úÖ DTST: Training data validated - 205 rows over 365 days
    üìä NVMI 3- Training: Horizon=60d, Target=3.97% (B&H: 24.13%, Scale=0.164)
‚úÖ NVMI: Training data validated - 205 rows over 365 days
    üìä SNX 3- Training: Horizon=60d, Target=3.96% (B&H: 24.09%, Scale=0.164)
‚úÖ SNX: Training data validated - 205 rows over 365 days
    üìä BRW 3- Training: Horizon=60d, Target=3.96% (B&H: 24.09%, Scale=0.164)
‚úÖ BRW: Training data validated - 205 rows over 365 days
    üìä GNE 3- Training: Horizon=60d, Target=3.94% (B&H: 23.99%, Scale=0.164)
‚úÖ GNE: Training data validated - 205 rows over 365 days
    üìä CHWY 3- Training: Horizon=60d, Target=3.94% (B&H: 23.97%, Scale=0.164)
‚úÖ CHWY: Training data validated - 205 rows over 365 days
    üìä WRB 3- Training: Horizon=60d, Target=3.93% (B&H: 23.93%, Scale=0.164)
‚úÖ WRB: Training data validated - 205 rows over 365 days
    üìä IQM 3- Training: Horizon=60d, Target=3.93% (B&H: 23.93%, Scale=0.164)
‚úÖ IQM: Training data validated - 205 rows over 365 days
    üìä HEI 3- Training: Horizon=60d, Target=3.93% (B&H: 23.91%, Scale=0.164)
‚úÖ HEI: Training data validated - 205 rows over 365 days
    üìä TRMK 3- Training: Horizon=60d, Target=3.93% (B&H: 23.90%, Scale=0.164)
‚úÖ TRMK: Training data validated - 205 rows over 365 days
    üìä EVC 3- Training: Horizon=60d, Target=3.93% (B&H: 23.88%, Scale=0.164)
‚úÖ EVC: Training data validated - 205 rows over 365 days
    üìä PAM 3- Training: Horizon=60d, Target=3.92% (B&H: 23.83%, Scale=0.164)
‚úÖ PAM: Training data validated - 205 rows over 365 days
    üìä COWG 3- Training: Horizon=60d, Target=3.92% (B&H: 23.83%, Scale=0.164)
‚úÖ COWG: Training data validated - 205 rows over 365 days
    üìä FDP 3- Training: Horizon=60d, Target=3.92% (B&H: 23.83%, Scale=0.164)
‚úÖ FDP: Training data validated - 205 rows over 365 days
    üìä PSLV 3- Training: Horizon=60d, Target=3.92% (B&H: 23.83%, Scale=0.164)
‚úÖ PSLV: Training data validated - 205 rows over 365 days
    üìä MO 3- Training: Horizon=60d, Target=3.91% (B&H: 23.79%, Scale=0.164)
‚úÖ MO: Training data validated - 205 rows over 365 days
    üìä TQQQ 3- Training: Horizon=60d, Target=3.91% (B&H: 23.78%, Scale=0.164)
‚úÖ TQQQ: Training data validated - 205 rows over 365 days
    üìä TRS 3- Training: Horizon=60d, Target=3.90% (B&H: 23.75%, Scale=0.164)
‚úÖ TRS: Training data validated - 205 rows over 365 days
    üìä MTSI 3- Training: Horizon=60d, Target=3.90% (B&H: 23.74%, Scale=0.164)
‚úÖ MTSI: Training data validated - 205 rows over 365 days
    üìä WCBR 3- Training: Horizon=60d, Target=3.90% (B&H: 23.71%, Scale=0.164)
‚úÖ WCBR: Training data validated - 205 rows over 365 days
    üìä MAMA 3- Training: Horizon=60d, Target=3.90% (B&H: 23.70%, Scale=0.164)
‚úÖ MAMA: Training data validated - 205 rows over 365 days
    üìä FRSH 3- Training: Horizon=60d, Target=3.88% (B&H: 23.61%, Scale=0.164)
‚úÖ FRSH: Training data validated - 205 rows over 365 days
    üìä SOBO 3- Training: Horizon=60d, Target=3.88% (B&H: 23.60%, Scale=0.164)
‚úÖ SOBO: Training data validated - 205 rows over 365 days
    üìä GGAL 3- Training: Horizon=60d, Target=3.88% (B&H: 23.59%, Scale=0.164)
‚úÖ GGAL: Training data validated - 205 rows over 365 days
    üìä AXS 3- Training: Horizon=60d, Target=3.86% (B&H: 23.50%, Scale=0.164)
‚úÖ AXS: Training data validated - 205 rows over 365 days
    üìä MASI 3- Training: Horizon=60d, Target=3.86% (B&H: 23.47%, Scale=0.164)
‚úÖ MASI: Training data validated - 205 rows over 365 days
    üìä RSG 3- Training: Horizon=60d, Target=3.84% (B&H: 23.36%, Scale=0.164)
‚úÖ RSG: Training data validated - 205 rows over 365 days
    üìä IRON 3- Training: Horizon=60d, Target=3.84% (B&H: 23.34%, Scale=0.164)
‚úÖ IRON: Training data validated - 205 rows over 365 days
    üìä CPA 3- Training: Horizon=60d, Target=3.83% (B&H: 23.33%, Scale=0.164)
‚úÖ CPA: Training data validated - 205 rows over 365 days
    üìä GEL 3- Training: Horizon=60d, Target=3.83% (B&H: 23.29%, Scale=0.164)
‚úÖ GEL: Training data validated - 205 rows over 365 days
    üìä SIMO 3- Training: Horizon=60d, Target=3.83% (B&H: 23.29%, Scale=0.164)
‚úÖ SIMO: Training data validated - 205 rows over 365 days
    üìä GT 3- Training: Horizon=60d, Target=3.83% (B&H: 23.28%, Scale=0.164)
‚úÖ GT: Training data validated - 205 rows over 365 days
    üìä PEJ 3- Training: Horizon=60d, Target=3.83% (B&H: 23.27%, Scale=0.164)
‚úÖ PEJ: Training data validated - 205 rows over 365 days
    üìä FEDU 3- Training: Horizon=60d, Target=3.82% (B&H: 23.24%, Scale=0.164)
‚úÖ FEDU: Training data validated - 205 rows over 365 days
    üìä SPRY 3- Training: Horizon=60d, Target=3.82% (B&H: 23.24%, Scale=0.164)
‚úÖ SPRY: Training data validated - 205 rows over 365 days
    üìä CFR 3- Training: Horizon=60d, Target=3.82% (B&H: 23.24%, Scale=0.164)
‚úÖ CFR: Training data validated - 205 rows over 365 days
    üìä CSGP 3- Training: Horizon=60d, Target=3.82% (B&H: 23.24%, Scale=0.164)
‚úÖ CSGP: Training data validated - 205 rows over 365 days
    üìä CPNG 3- Training: Horizon=60d, Target=3.82% (B&H: 23.22%, Scale=0.164)
‚úÖ CPNG: Training data validated - 205 rows over 365 days
    üìä UIVM 3- Training: Horizon=60d, Target=3.81% (B&H: 23.20%, Scale=0.164)
‚úÖ UIVM: Training data validated - 205 rows over 365 days
    üìä KEMQ 3- Training: Horizon=60d, Target=3.81% (B&H: 23.16%, Scale=0.164)
‚úÖ KEMQ: Training data validated - 205 rows over 365 days
    üìä WTFC 3- Training: Horizon=60d, Target=3.81% (B&H: 23.16%, Scale=0.164)
‚úÖ WTFC: Training data validated - 205 rows over 365 days
    üìä FDTS 3- Training: Horizon=60d, Target=3.80% (B&H: 23.09%, Scale=0.164)
‚úÖ FDTS: Training data validated - 205 rows over 365 days
    üìä STEL 3- Training: Horizon=60d, Target=3.79% (B&H: 23.06%, Scale=0.164)
‚úÖ STEL: Training data validated - 205 rows over 365 days
    üìä XITK 3- Training: Horizon=60d, Target=3.79% (B&H: 23.03%, Scale=0.164)
‚úÖ XITK: Training data validated - 205 rows over 365 days
    üìä VSAT 3- Training: Horizon=60d, Target=3.79% (B&H: 23.03%, Scale=0.164)
‚úÖ VSAT: Training data validated - 205 rows over 365 days
    üìä EPR 3- Training: Horizon=60d, Target=3.78% (B&H: 22.99%, Scale=0.164)
‚úÖ EPR: Training data validated - 205 rows over 365 days
    üìä SPOK 3- Training: Horizon=60d, Target=3.78% (B&H: 22.98%, Scale=0.164)
‚úÖ SPOK: Training data validated - 205 rows over 365 days
    üìä TRIP 3- Training: Horizon=60d, Target=3.78% (B&H: 22.98%, Scale=0.164)
‚úÖ TRIP: Training data validated - 205 rows over 365 days
    üìä IXG 3- Training: Horizon=60d, Target=3.78% (B&H: 22.97%, Scale=0.164)
‚úÖ IXG: Training data validated - 205 rows over 365 days
    üìä PDLB 3- Training: Horizon=60d, Target=3.77% (B&H: 22.93%, Scale=0.164)
‚úÖ PDLB: Training data validated - 205 rows over 365 days
    üìä FTDR 3- Training: Horizon=60d, Target=3.76% (B&H: 22.90%, Scale=0.164)
‚úÖ FTDR: Training data validated - 205 rows over 365 days
    üìä QLD 3- Training: Horizon=60d, Target=3.75% (B&H: 22.83%, Scale=0.164)
‚úÖ QLD: Training data validated - 205 rows over 365 days
    üìä HURN 3- Training: Horizon=60d, Target=3.75% (B&H: 22.81%, Scale=0.164)
‚úÖ HURN: Training data validated - 205 rows over 365 days
    üìä CECO 3- Training: Horizon=60d, Target=3.75% (B&H: 22.80%, Scale=0.164)
‚úÖ CECO: Training data validated - 205 rows over 365 days
    üìä WTS 3- Training: Horizon=60d, Target=3.74% (B&H: 22.76%, Scale=0.164)
‚úÖ WTS: Training data validated - 205 rows over 365 days
    üìä ALG 3- Training: Horizon=60d, Target=3.72% (B&H: 22.65%, Scale=0.164)
‚úÖ ALG: Training data validated - 205 rows over 365 days
    üìä CMPO 3- Training: Horizon=60d, Target=3.72% (B&H: 22.63%, Scale=0.164)
‚úÖ CMPO: Training data validated - 205 rows over 365 days
    üìä SMBK 3- Training: Horizon=60d, Target=3.72% (B&H: 22.62%, Scale=0.164)
‚úÖ SMBK: Training data validated - 205 rows over 365 days
    üìä AIT 3- Training: Horizon=60d, Target=3.71% (B&H: 22.59%, Scale=0.164)
‚úÖ AIT: Training data validated - 205 rows over 365 days
    üìä FDNI 3- Training: Horizon=60d, Target=3.71% (B&H: 22.57%, Scale=0.164)
‚úÖ FDNI: Training data validated - 205 rows over 365 days
    üìä CDNS 3- Training: Horizon=60d, Target=3.71% (B&H: 22.57%, Scale=0.164)
‚úÖ CDNS: Training data validated - 205 rows over 365 days
    üìä BBSI 3- Training: Horizon=60d, Target=3.71% (B&H: 22.55%, Scale=0.164)
‚úÖ BBSI: Training data validated - 205 rows over 365 days
    üìä PCOR 3- Training: Horizon=60d, Target=3.70% (B&H: 22.50%, Scale=0.164)
‚úÖ PCOR: Training data validated - 205 rows over 365 days
    üìä FGD 3- Training: Horizon=60d, Target=3.70% (B&H: 22.48%, Scale=0.164)
‚úÖ FGD: Training data validated - 205 rows over 365 days
    üìä UXI 3- Training: Horizon=60d, Target=3.69% (B&H: 22.46%, Scale=0.164)
‚úÖ UXI: Training data validated - 205 rows over 365 days
    üìä FBNC 3- Training: Horizon=60d, Target=3.69% (B&H: 22.44%, Scale=0.164)
‚úÖ FBNC: Training data validated - 205 rows over 365 days
    üìä ONLN 3- Training: Horizon=60d, Target=3.67% (B&H: 22.35%, Scale=0.164)
‚úÖ ONLN: Training data validated - 205 rows over 365 days
ü§ñ Training 3-Month models in parallel for 966 tickers using 15 processes...
üêõ DEBUG: Using torch.multiprocessing.Pool with spawn for GPU support
üêõ DEBUG: Pool started with 15 worker processes. PIDs=[195112, 195113, 195114, 195115, 195116, 195117, 195118, 195119, 195120, 195121, 195122, 195123, 195124, 195125, 195126]
üêõ DEBUG: Submitting 959 training tasks...
üêõ DEBUG: Submitted 959 tasks, waiting for results with 600s timeout per ticker...
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for OKLO
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for PRCH
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for LAES
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for RYM
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for AMPX
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for TMC
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for ARQQ
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for AEVA
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for QNTM
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for ABVX
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for KC
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for DAVE
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for SEZL
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for IONQ
[GPU] torch.cuda.is_available(): True
[GPU] XGBoost version: 3.1.2
[GPU] LightGBM version: 4.6.0
DEBUG: Script execution initiated.
üîß Using torch.multiprocessing with 'spawn' for CUDA compatibility
üêõ DEBUG: train_worker started for SRRK
  ‚öôÔ∏è Training models for OKLO (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-73 - OKLO: Initiating feature extraction for training.
  [DIAGNOSTIC] OKLO: fetch_training_data - Initial data rows: 205
   ‚Ü≥ OKLO: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ OKLO: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] OKLO: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö OKLO: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ OKLO: Training LSTM (50 epochs)...
  ‚öôÔ∏è Training models for PRCH (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-63 - PRCH: Initiating feature extraction for training.
  [DIAGNOSTIC] PRCH: fetch_training_data - Initial data rows: 205
   ‚Ü≥ PRCH: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ PRCH: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] PRCH: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö PRCH: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ PRCH: Training LSTM (50 epochs)...
  ‚öôÔ∏è Training models for LAES (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-62 - LAES: Initiating feature extraction for training.
  [DIAGNOSTIC] LAES: fetch_training_data - Initial data rows: 205
   ‚Ü≥ LAES: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ LAES: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] LAES: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö LAES: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ LAES: Training LSTM (50 epochs)...
  ‚öôÔ∏è Training models for RYM (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-68 - RYM: Initiating feature extraction for training.
  [DIAGNOSTIC] RYM: fetch_training_data - Initial data rows: 205
   ‚Ü≥ RYM: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ RYM: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] RYM: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö RYM: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ RYM: Training LSTM (50 epochs)...
  ‚öôÔ∏è Training models for AMPX (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-71 - AMPX: Initiating feature extraction for training.
  [DIAGNOSTIC] AMPX: fetch_training_data - Initial data rows: 205
   ‚Ü≥ AMPX: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ AMPX: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] AMPX: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö AMPX: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ AMPX: Training LSTM (50 epochs)...
  ‚öôÔ∏è Training models for TMC (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-61 - TMC: Initiating feature extraction for training.
  [DIAGNOSTIC] TMC: fetch_training_data - Initial data rows: 205
   ‚Ü≥ TMC: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ TMC: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] TMC: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö TMC: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ TMC: Training LSTM (50 epochs)...
  ‚öôÔ∏è Training models for ARQQ (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-65 - ARQQ: Initiating feature extraction for training.
  [DIAGNOSTIC] ARQQ: fetch_training_data - Initial data rows: 205
   ‚Ü≥ ARQQ: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ ARQQ: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] ARQQ: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö ARQQ: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ ARQQ: Training LSTM (50 epochs)...
  ‚öôÔ∏è Training models for AEVA (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-75 - AEVA: Initiating feature extraction for training.
  [DIAGNOSTIC] AEVA: fetch_training_data - Initial data rows: 205
   ‚Ü≥ AEVA: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ AEVA: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] AEVA: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö AEVA: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ AEVA: Training LSTM (50 epochs)...
  ‚öôÔ∏è Training models for QNTM (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-70 - QNTM: Initiating feature extraction for training.
  [DIAGNOSTIC] QNTM: fetch_training_data - Initial data rows: 205
   ‚Ü≥ QNTM: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ QNTM: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  ‚öôÔ∏è Training models for KC (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-64 - KC: Initiating feature extraction for training.
  [DIAGNOSTIC] KC: fetch_training_data - Initial data rows: 205
   ‚Ü≥ KC: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ KC: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  ‚öôÔ∏è Training models for ABVX (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-74 - ABVX: Initiating feature extraction for training.
  [DIAGNOSTIC] ABVX: fetch_training_data - Initial data rows: 205
   ‚Ü≥ ABVX: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ ABVX: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  ‚öôÔ∏è Training models for SEZL (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-69 - SEZL: Initiating feature extraction for training.
  [DIAGNOSTIC] SEZL: fetch_training_data - Initial data rows: 205
   ‚Ü≥ SEZL: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ SEZL: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] QNTM: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö QNTM: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ QNTM: Training LSTM (50 epochs)...
  ‚öôÔ∏è Training models for DAVE (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-66 - DAVE: Initiating feature extraction for training.
  [DIAGNOSTIC] DAVE: fetch_training_data - Initial data rows: 205
   ‚Ü≥ DAVE: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ DAVE: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] KC: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö KC: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ KC: Training LSTM (50 epochs)...
  [DIAGNOSTIC] ABVX: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö ABVX: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
  [DIAGNOSTIC] SEZL: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö SEZL: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ SEZL: Training LSTM (50 epochs)...
      üîπ ABVX: Training LSTM (50 epochs)...
  ‚öôÔ∏è Training models for SRRK (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-72 - SRRK: Initiating feature extraction for training.
  [DIAGNOSTIC] SRRK: fetch_training_data - Initial data rows: 205
   ‚Ü≥ SRRK: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ SRRK: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  ‚öôÔ∏è Training models for IONQ (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-67 - IONQ: Initiating feature extraction for training.
  [DIAGNOSTIC] IONQ: fetch_training_data - Initial data rows: 205
   ‚Ü≥ IONQ: rows after features available: 126
‚úÖ CUDA is available and working. GPU acceleration enabled with deterministic algorithms.
‚ÑπÔ∏è LightGBM: using CPU (OpenCL not compatible with NVIDIA/PoCL in WSL2).
‚úÖ XGBoostRegressor found. Configured for GPU (gpu_hist tree_method).
üéØ IONQ: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] DAVE: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö DAVE: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ DAVE: Training LSTM (50 epochs)...
  [DIAGNOSTIC] SRRK: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö SRRK: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ SRRK: Training LSTM (50 epochs)...
  [DIAGNOSTIC] IONQ: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö IONQ: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ IONQ: Training LSTM (50 epochs)...
      ‚è≥ PRCH LSTM: Epoch 10/50 (20%)
      ‚è≥ LAES LSTM: Epoch 10/50 (20%)
      ‚è≥ OKLO LSTM: Epoch 10/50 (20%)
      ‚è≥ RYM LSTM: Epoch 10/50 (20%)
      ‚è≥ ARQQ LSTM: Epoch 10/50 (20%)
      ‚è≥ AMPX LSTM: Epoch 10/50 (20%)
      ‚è≥ ABVX LSTM: Epoch 10/50 (20%)
      ‚è≥ AEVA LSTM: Epoch 10/50 (20%)
      ‚è≥ SRRK LSTM: Epoch 10/50 (20%)
      ‚è≥ KC LSTM: Epoch 10/50 (20%)
      ‚è≥ IONQ LSTM: Epoch 10/50 (20%)
      ‚è≥ TMC LSTM: Epoch 10/50 (20%)
      ‚è≥ DAVE LSTM: Epoch 10/50 (20%)
      ‚è≥ QNTM LSTM: Epoch 10/50 (20%)
      ‚è≥ SEZL LSTM: Epoch 10/50 (20%)
      ‚è≥ LAES LSTM: Epoch 20/50 (40%)
      ‚è≥ PRCH LSTM: Epoch 20/50 (40%)
      ‚è≥ OKLO LSTM: Epoch 20/50 (40%)
      ‚è≥ RYM LSTM: Epoch 20/50 (40%)
      ‚è≥ ARQQ LSTM: Epoch 20/50 (40%)
      ‚è≥ ABVX LSTM: Epoch 20/50 (40%)
      ‚è≥ AEVA LSTM: Epoch 20/50 (40%)
      ‚è≥ SRRK LSTM: Epoch 20/50 (40%)
      ‚è≥ DAVE LSTM: Epoch 20/50 (40%)
      ‚è≥ KC LSTM: Epoch 20/50 (40%)
      ‚è≥ IONQ LSTM: Epoch 20/50 (40%)
      ‚è≥ AMPX LSTM: Epoch 20/50 (40%)
      ‚è≥ TMC LSTM: Epoch 20/50 (40%)
      ‚è≥ OKLO LSTM: Epoch 30/50 (60%)
      ‚è≥ LAES LSTM: Epoch 30/50 (60%)
      ‚è≥ PRCH LSTM: Epoch 30/50 (60%)
      ‚è≥ SEZL LSTM: Epoch 20/50 (40%)
      ‚è≥ RYM LSTM: Epoch 30/50 (60%)
      ‚è≥ QNTM LSTM: Epoch 20/50 (40%)
      ‚è≥ ARQQ LSTM: Epoch 30/50 (60%)
      ‚è≥ AEVA LSTM: Epoch 30/50 (60%)
      ‚è≥ ABVX LSTM: Epoch 30/50 (60%)
      ‚è≥ SRRK LSTM: Epoch 30/50 (60%)
      ‚è≥ KC LSTM: Epoch 30/50 (60%)
      ‚è≥ IONQ LSTM: Epoch 30/50 (60%)
      ‚è≥ DAVE LSTM: Epoch 30/50 (60%)
      ‚è≥ OKLO LSTM: Epoch 40/50 (80%)
      ‚è≥ AMPX LSTM: Epoch 30/50 (60%)
      ‚è≥ PRCH LSTM: Epoch 40/50 (80%)
      ‚è≥ LAES LSTM: Epoch 40/50 (80%)
      ‚è≥ RYM LSTM: Epoch 40/50 (80%)
      ‚è≥ TMC LSTM: Epoch 30/50 (60%)
      ‚è≥ QNTM LSTM: Epoch 30/50 (60%)
      ‚è≥ SEZL LSTM: Epoch 30/50 (60%)
      ‚è≥ ARQQ LSTM: Epoch 40/50 (80%)
      ‚è≥ SRRK LSTM: Epoch 40/50 (80%)
      ‚è≥ AEVA LSTM: Epoch 40/50 (80%)
      ‚è≥ ABVX LSTM: Epoch 40/50 (80%)
      ‚è≥ KC LSTM: Epoch 40/50 (80%)
      ‚è≥ IONQ LSTM: Epoch 40/50 (80%)
      ‚è≥ DAVE LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.693452
         RMSE: 0.832738
         R¬≤ Score: -0.7627 (Poor - 76.3% variance explained)
      üîπ OKLO: Training TCN (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.289160
         RMSE: 0.537736
         R¬≤ Score: -1.0000 (Poor - 100.0% variance explained)
      üîπ PRCH: Training TCN (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.022852
         RMSE: 0.151167
         R¬≤ Score: -6.4328 (Poor - 643.3% variance explained)
      üîπ LAES: Training TCN (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.029095
         RMSE: 0.170571
         R¬≤ Score: -3.2726 (Poor - 327.3% variance explained)
      üîπ RYM: Training TCN (50 epochs)...
      ‚è≥ AMPX LSTM: Epoch 40/50 (80%)
      ‚è≥ OKLO TCN: Epoch 10/50 (20%)
      ‚è≥ TMC LSTM: Epoch 40/50 (80%)
      ‚è≥ PRCH TCN: Epoch 10/50 (20%)
      ‚è≥ SEZL LSTM: Epoch 40/50 (80%)
      ‚è≥ RYM TCN: Epoch 10/50 (20%)
      ‚è≥ LAES TCN: Epoch 10/50 (20%)
      ‚è≥ QNTM LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.358639
         RMSE: 0.598865
         R¬≤ Score: -0.9192 (Poor - 91.9% variance explained)
      üîπ ARQQ: Training TCN (50 epochs)...
      ‚è≥ OKLO TCN: Epoch 20/50 (40%)
      üìä LSTM Regression Metrics:
         MSE: 0.491893
         RMSE: 0.701351
         R¬≤ Score: -1.0297 (Poor - 103.0% variance explained)
      üîπ SRRK: Training TCN (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.203441
         RMSE: 0.451045
         R¬≤ Score: -0.4098 (Poor - 41.0% variance explained)
      üîπ ABVX: Training TCN (50 epochs)...
      ‚è≥ PRCH TCN: Epoch 20/50 (40%)
      üìä LSTM Regression Metrics:
         MSE: 0.330640
         RMSE: 0.575013
         R¬≤ Score: -1.2487 (Poor - 124.9% variance explained)
      üîπ IONQ: Training TCN (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.011326
         RMSE: 0.106422
         R¬≤ Score: -0.6143 (Poor - 61.4% variance explained)
      üîπ KC: Training TCN (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.450363
         RMSE: 0.671091
         R¬≤ Score: -1.2631 (Poor - 126.3% variance explained)
      üîπ AEVA: Training TCN (50 epochs)...
      ‚è≥ RYM TCN: Epoch 20/50 (40%)
      üìä LSTM Regression Metrics:
         MSE: 0.439928
         RMSE: 0.663271
         R¬≤ Score: -0.8467 (Poor - 84.7% variance explained)
      üîπ DAVE: Training TCN (50 epochs)...
      ‚è≥ LAES TCN: Epoch 20/50 (40%)
      ‚è≥ ARQQ TCN: Epoch 10/50 (20%)
      ‚è≥ OKLO TCN: Epoch 30/50 (60%)
      ‚è≥ ABVX TCN: Epoch 10/50 (20%)
      ‚è≥ PRCH TCN: Epoch 30/50 (60%)
      ‚è≥ SRRK TCN: Epoch 10/50 (20%)
      ‚è≥ KC TCN: Epoch 10/50 (20%)
      ‚è≥ AEVA TCN: Epoch 10/50 (20%)
      ‚è≥ IONQ TCN: Epoch 10/50 (20%)
      ‚è≥ RYM TCN: Epoch 30/50 (60%)
      ‚è≥ DAVE TCN: Epoch 10/50 (20%)
      ‚è≥ LAES TCN: Epoch 30/50 (60%)
      ‚è≥ ARQQ TCN: Epoch 20/50 (40%)
      ‚è≥ OKLO TCN: Epoch 40/50 (80%)
      ‚è≥ ABVX TCN: Epoch 20/50 (40%)
      ‚è≥ PRCH TCN: Epoch 40/50 (80%)
      ‚è≥ SRRK TCN: Epoch 20/50 (40%)
      ‚è≥ KC TCN: Epoch 20/50 (40%)
      ‚è≥ RYM TCN: Epoch 40/50 (80%)
      ‚è≥ AEVA TCN: Epoch 20/50 (40%)
      ‚è≥ IONQ TCN: Epoch 20/50 (40%)
      ‚è≥ DAVE TCN: Epoch 20/50 (40%)
      ‚è≥ LAES TCN: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.615701
         RMSE: 0.784666
         R¬≤ Score: -1.0413 (Poor - 104.1% variance explained)
      üîπ AMPX: Training TCN (50 epochs)...
      üìä TCN Regression Metrics:
         MSE: 0.688855
         RMSE: 0.829973
         R¬≤ Score: -0.7510
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä OKLO: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ OKLO Random Forest: Starting GridSearchCV fit...
      ‚è≥ ARQQ TCN: Epoch 30/50 (60%)
      ‚è≥ ABVX TCN: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.141342
         RMSE: 0.375955
         R¬≤ Score: 0.0224
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä PRCH: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ PRCH Random Forest: Starting GridSearchCV fit...
      ‚è≥ SRRK TCN: Epoch 30/50 (60%)
      ‚è≥ KC TCN: Epoch 30/50 (60%)
      ‚è≥ IONQ TCN: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.009525
         RMSE: 0.097598
         R¬≤ Score: -0.3988
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä RYM: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ RYM Random Forest: Starting GridSearchCV fit...
      ‚è≥ AEVA TCN: Epoch 30/50 (60%)
      ‚è≥ DAVE TCN: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.005278
         RMSE: 0.072650
         R¬≤ Score: -0.7168
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä LAES: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ LAES Random Forest: Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 0.499078
         RMSE: 0.706454
         R¬≤ Score: -0.7982 (Poor - 79.8% variance explained)
      üîπ TMC: Training TCN (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.456880
         RMSE: 0.675929
         R¬≤ Score: -1.0473 (Poor - 104.7% variance explained)
      üîπ SEZL: Training TCN (50 epochs)...
      ‚è≥ AMPX TCN: Epoch 10/50 (20%)
      ‚è≥ ARQQ TCN: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.261637
         RMSE: 0.511505
         R¬≤ Score: -0.7610 (Poor - 76.1% variance explained)
      üîπ QNTM: Training TCN (50 epochs)...
      ‚è≥ SRRK TCN: Epoch 40/50 (80%)
      ‚è≥ ABVX TCN: Epoch 40/50 (80%)
      ‚è≥ KC TCN: Epoch 40/50 (80%)
      ‚è≥ IONQ TCN: Epoch 40/50 (80%)
      ‚è≥ AEVA TCN: Epoch 40/50 (80%)
      ‚è≥ DAVE TCN: Epoch 40/50 (80%)
      ‚è≥ TMC TCN: Epoch 10/50 (20%)
      ‚è≥ SEZL TCN: Epoch 10/50 (20%)
      ‚è≥ AMPX TCN: Epoch 20/50 (40%)
      üìä TCN Regression Metrics:
         MSE: 0.263691
         RMSE: 0.513508
         R¬≤ Score: -0.4111
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä ARQQ: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ ARQQ Random Forest: Starting GridSearchCV fit...
      ‚è≥ QNTM TCN: Epoch 10/50 (20%)
      üìä TCN Regression Metrics:
         MSE: 0.319374
         RMSE: 0.565132
         R¬≤ Score: -0.3178
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä SRRK: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ SRRK Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.146203
         RMSE: 0.382366
         R¬≤ Score: -0.0132
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä ABVX: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ ABVX Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.197083
         RMSE: 0.443940
         R¬≤ Score: -0.3404
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä IONQ: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ IONQ Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.200922
         RMSE: 0.448243
         R¬≤ Score: -0.0096
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä AEVA: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ AEVA Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.011840
         RMSE: 0.108811
         R¬≤ Score: -0.6876
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä KC: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ KC Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.367139
         RMSE: 0.605920
         R¬≤ Score: -0.5411
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä DAVE: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ DAVE Random Forest: Starting GridSearchCV fit...
      ‚è≥ TMC TCN: Epoch 20/50 (40%)
      ‚è≥ SEZL TCN: Epoch 20/50 (40%)
      ‚è≥ AMPX TCN: Epoch 30/50 (60%)
      ‚è≥ QNTM TCN: Epoch 20/50 (40%)
      ‚è≥ SEZL TCN: Epoch 30/50 (60%)
      ‚è≥ TMC TCN: Epoch 30/50 (60%)
      ‚è≥ AMPX TCN: Epoch 40/50 (80%)
      ‚è≥ QNTM TCN: Epoch 30/50 (60%)
      ‚è≥ SEZL TCN: Epoch 40/50 (80%)
      ‚è≥ TMC TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.302027
         RMSE: 0.549570
         R¬≤ Score: -0.0013
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä AMPX: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ AMPX Random Forest: Starting GridSearchCV fit...
      ‚è≥ QNTM TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.280986
         RMSE: 0.530081
         R¬≤ Score: -0.2591
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä SEZL: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ SEZL Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.287598
         RMSE: 0.536282
         R¬≤ Score: -0.0362
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä TMC: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ TMC Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.184478
         RMSE: 0.429508
         R¬≤ Score: -0.2417
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä QNTM: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ QNTM Random Forest: Starting GridSearchCV fit...
       ‚úÖ LAES Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=3377.6165 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 3.1s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ LAES LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ OKLO Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=438.1104 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.3s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ OKLO LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ ARQQ Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=954.3916 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 3.1s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ ARQQ LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ KC Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=323.0237 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 3.0s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ KC LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ SRRK Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=20.1956 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.1s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ SRRK LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ RYM Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=681.1591 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.4s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ RYM LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ PRCH Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=951.5244 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.5s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ PRCH LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ AEVA Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=2915.4027 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 3.1s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ AEVA LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ DAVE Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=423.2286 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 3.2s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ DAVE LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ IONQ Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=146.9234 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.4s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ IONQ LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ AMPX Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=359.0904 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 3.1s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ AMPX LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ ABVX Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=14247.0553 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.4s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ ABVX LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ SEZL Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=748.7164 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.2s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ SEZL LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ TMC Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=453.7278 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 3.2s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ TMC LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ LAES LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=4238.7491 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ LAES XGBoost: Starting GridSearchCV fit...
       ‚úÖ QNTM Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=1446.4740 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.2s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ QNTM LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ OKLO LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=542.2383 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ OKLO XGBoost: Starting GridSearchCV fit...
       ‚úÖ ARQQ LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=918.6564 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ ARQQ XGBoost: Starting GridSearchCV fit...
       ‚úÖ SRRK LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=26.1031 (Best Params: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ SRRK XGBoost: Starting GridSearchCV fit...
       ‚úÖ RYM LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=2110.5706 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ RYM XGBoost: Starting GridSearchCV fit...
       ‚úÖ KC LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=700.2891 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ KC XGBoost: Starting GridSearchCV fit...
       ‚úÖ PRCH LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=826.8349 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ PRCH XGBoost: Starting GridSearchCV fit...
       ‚úÖ AEVA LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=3879.0384 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ AEVA XGBoost: Starting GridSearchCV fit...
       ‚úÖ DAVE LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=397.2072 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ DAVE XGBoost: Starting GridSearchCV fit...
       ‚úÖ IONQ LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=221.2162 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ IONQ XGBoost: Starting GridSearchCV fit...
       ‚úÖ AMPX LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=766.4788 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ AMPX XGBoost: Starting GridSearchCV fit...
       ‚úÖ ABVX LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=13377.0101 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ ABVX XGBoost: Starting GridSearchCV fit...
       ‚úÖ SEZL LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=1011.8016 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ SEZL XGBoost: Starting GridSearchCV fit...
       ‚úÖ TMC LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=695.7269 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ TMC XGBoost: Starting GridSearchCV fit...
       ‚úÖ QNTM LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=2025.1683 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ QNTM XGBoost: Starting GridSearchCV fit...
       ‚úÖ LAES XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=3083.5140 (Best Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}) | Time: 130.5s
    - LSTM: MSE=0.0229
    - TCN: MSE=0.0053
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 134.3 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0053
        ‚Ä¢ LSTM: MSE=0.0229
        ‚Ä¢ XGBoost: MSE=3083.5140
        ‚Ä¢ Random Forest: MSE=3377.6165
        ‚Ä¢ LightGBM Regressor (CPU): MSE=4238.7491
   ‚úÖ LAES: Phase 3/3 - Model selection complete!
  üèÜ WINNER for LAES (TargetReturn): TCN with MSE=0.0053
üêõ DEBUG: LAES - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for LAES.
üêõ DEBUG: LAES - Moving model to CPU before return...
üêõ DEBUG [22:19:41.338]: LAES - Returning result metadata...
üêõ DEBUG: train_worker started for HOOD
  ‚öôÔ∏è Training models for HOOD (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-62 - HOOD: Initiating feature extraction for training.
  [DIAGNOSTIC] HOOD: fetch_training_data - Initial data rows: 205
   ‚Ü≥ HOOD: rows after features available: 126
üéØ HOOD: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] HOOD: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö HOOD: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ HOOD: Training LSTM (50 epochs)...
      ‚è≥ HOOD LSTM: Epoch 10/50 (20%)
       ‚úÖ RYM XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=745.6468 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}) | Time: 131.0s
    - LSTM: MSE=0.0291
    - TCN: MSE=0.0095
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 135.2 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0095
        ‚Ä¢ LSTM: MSE=0.0291
        ‚Ä¢ Random Forest: MSE=681.1591
        ‚Ä¢ XGBoost: MSE=745.6468
        ‚Ä¢ LightGBM Regressor (CPU): MSE=2110.5706
   ‚úÖ RYM: Phase 3/3 - Model selection complete!
  üèÜ WINNER for RYM (TargetReturn): TCN with MSE=0.0095
üêõ DEBUG: RYM - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for RYM.
üêõ DEBUG: RYM - Moving model to CPU before return...
üêõ DEBUG [22:19:42.187]: RYM - Returning result metadata...
üêõ DEBUG: train_worker started for SMR
  ‚öôÔ∏è Training models for SMR (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-68 - SMR: Initiating feature extraction for training.
  [DIAGNOSTIC] SMR: fetch_training_data - Initial data rows: 205
   ‚Ü≥ SMR: rows after features available: 126
üéØ SMR: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] SMR: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö SMR: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ SMR: Training LSTM (50 epochs)...
      ‚è≥ HOOD LSTM: Epoch 20/50 (40%)
      ‚è≥ SMR LSTM: Epoch 10/50 (20%)
      ‚è≥ HOOD LSTM: Epoch 30/50 (60%)
       ‚úÖ OKLO XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=611.2795 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 131.9s
    - LSTM: MSE=0.6935
    - TCN: MSE=0.6889
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 136.0 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.6889
        ‚Ä¢ LSTM: MSE=0.6935
        ‚Ä¢ Random Forest: MSE=438.1104
        ‚Ä¢ LightGBM Regressor (CPU): MSE=542.2383
        ‚Ä¢ XGBoost: MSE=611.2795
   ‚úÖ OKLO: Phase 3/3 - Model selection complete!
  üèÜ WINNER for OKLO (TargetReturn): TCN with MSE=0.6889
üêõ DEBUG: OKLO - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for OKLO.
üêõ DEBUG: OKLO - Moving model to CPU before return...
üêõ DEBUG [22:19:42.907]: OKLO - Returning result metadata...
üêõ DEBUG: train_worker started for UAMY
üêõ DEBUG [22:19:42.908]: Main received result for OKLO
  ‚öôÔ∏è Training models for UAMY (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-73 - UAMY: Initiating feature extraction for training.
  [DIAGNOSTIC] UAMY: fetch_training_data - Initial data rows: 205
   ‚Ü≥ UAMY: rows after features available: 126
üéØ UAMY: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] UAMY: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö UAMY: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ UAMY: Training LSTM (50 epochs)...
      ‚è≥ SMR LSTM: Epoch 20/50 (40%)
      ‚è≥ HOOD LSTM: Epoch 40/50 (80%)
      ‚è≥ UAMY LSTM: Epoch 10/50 (20%)
       ‚úÖ ARQQ XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=1499.0862 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}) | Time: 132.6s
    - LSTM: MSE=0.3586
    - TCN: MSE=0.2637
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 136.4 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.2637
        ‚Ä¢ LSTM: MSE=0.3586
        ‚Ä¢ LightGBM Regressor (CPU): MSE=918.6564
        ‚Ä¢ Random Forest: MSE=954.3916
        ‚Ä¢ XGBoost: MSE=1499.0862
   ‚úÖ ARQQ: Phase 3/3 - Model selection complete!
  üèÜ WINNER for ARQQ (TargetReturn): TCN with MSE=0.2637
üêõ DEBUG: ARQQ - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for ARQQ.
üêõ DEBUG: ARQQ - Moving model to CPU before return...
üêõ DEBUG [22:19:43.622]: ARQQ - Returning result metadata...
üêõ DEBUG: train_worker started for PSIX
  ‚öôÔ∏è Training models for PSIX (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-65 - PSIX: Initiating feature extraction for training.
  [DIAGNOSTIC] PSIX: fetch_training_data - Initial data rows: 205
   ‚Ü≥ PSIX: rows after features available: 126
üéØ PSIX: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] PSIX: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö PSIX: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ PSIX: Training LSTM (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.796117
         RMSE: 0.892254
         R¬≤ Score: -1.4697 (Poor - 147.0% variance explained)
      üîπ HOOD: Training TCN (50 epochs)...
      ‚è≥ SMR LSTM: Epoch 30/50 (60%)
       ‚úÖ KC XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=485.6149 (Best Params: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100}) | Time: 132.7s
    - LSTM: MSE=0.0113
    - TCN: MSE=0.0118
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 136.6 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.0113
        ‚Ä¢ TCN: MSE=0.0118
        ‚Ä¢ Random Forest: MSE=323.0237
        ‚Ä¢ XGBoost: MSE=485.6149
        ‚Ä¢ LightGBM Regressor (CPU): MSE=700.2891
   ‚úÖ KC: Phase 3/3 - Model selection complete!
  üèÜ WINNER for KC (TargetReturn): LSTM with MSE=0.0113
üêõ DEBUG: KC - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for KC.
üêõ DEBUG: KC - Moving model to CPU before return...
üêõ DEBUG [22:19:43.879]: KC - Returning result metadata...
üêõ DEBUG: train_worker started for LEU
      ‚è≥ HOOD TCN: Epoch 10/50 (20%)
      ‚è≥ UAMY LSTM: Epoch 20/50 (40%)
  ‚öôÔ∏è Training models for LEU (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-64 - LEU: Initiating feature extraction for training.
  [DIAGNOSTIC] LEU: fetch_training_data - Initial data rows: 205
   ‚Ü≥ LEU: rows after features available: 126
üéØ LEU: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] LEU: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö LEU: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ LEU: Training LSTM (50 epochs)...
      ‚è≥ HOOD TCN: Epoch 20/50 (40%)
      ‚è≥ HOOD TCN: Epoch 30/50 (60%)
      ‚è≥ PSIX LSTM: Epoch 10/50 (20%)
      ‚è≥ HOOD TCN: Epoch 40/50 (80%)
      ‚è≥ SMR LSTM: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.771732
         RMSE: 0.878483
         R¬≤ Score: -1.3940
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä HOOD: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ HOOD Random Forest: Starting GridSearchCV fit...
      ‚è≥ UAMY LSTM: Epoch 30/50 (60%)
      ‚è≥ LEU LSTM: Epoch 10/50 (20%)
      ‚è≥ PSIX LSTM: Epoch 20/50 (40%)
       ‚úÖ PRCH XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=644.4748 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 133.6s
    - LSTM: MSE=0.2892
    - TCN: MSE=0.1413
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 137.9 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1413
        ‚Ä¢ LSTM: MSE=0.2892
        ‚Ä¢ XGBoost: MSE=644.4748
        ‚Ä¢ LightGBM Regressor (CPU): MSE=826.8349
        ‚Ä¢ Random Forest: MSE=951.5244
   ‚úÖ PRCH: Phase 3/3 - Model selection complete!
  üèÜ WINNER for PRCH (TargetReturn): TCN with MSE=0.1413
üêõ DEBUG: PRCH - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for PRCH.
üêõ DEBUG: PRCH - Moving model to CPU before return...
üêõ DEBUG [22:19:44.855]: PRCH - Returning result metadata...
üêõ DEBUG: train_worker started for PLTR
üêõ DEBUG [22:19:44.858]: Main received result for PRCH
üêõ DEBUG [22:19:44.858]: Main received result for LAES
üêõ DEBUG [22:19:44.858]: Main received result for RYM
üêõ DEBUG: Training progress: 4/959 done
  ‚öôÔ∏è Training models for PLTR (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-63 - PLTR: Initiating feature extraction for training.
  [DIAGNOSTIC] PLTR: fetch_training_data - Initial data rows: 205
   ‚Ü≥ PLTR: rows after features available: 126
üéØ PLTR: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] PLTR: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö PLTR: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ PLTR: Training LSTM (50 epochs)...
      ‚è≥ UAMY LSTM: Epoch 40/50 (80%)
       ‚úÖ ABVX XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=15526.7949 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}) | Time: 133.4s
    - LSTM: MSE=0.2034
    - TCN: MSE=0.1462
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 137.7 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1462
        ‚Ä¢ LSTM: MSE=0.2034
        ‚Ä¢ LightGBM Regressor (CPU): MSE=13377.0101
        ‚Ä¢ Random Forest: MSE=14247.0553
        ‚Ä¢ XGBoost: MSE=15526.7949
   ‚úÖ ABVX: Phase 3/3 - Model selection complete!
  üèÜ WINNER for ABVX (TargetReturn): TCN with MSE=0.1462
üêõ DEBUG: ABVX - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for ABVX.
üêõ DEBUG: ABVX - Moving model to CPU before return...
üêõ DEBUG [22:19:44.945]: ABVX - Returning result metadata...
üêõ DEBUG: train_worker started for OUST
      üìä LSTM Regression Metrics:
         MSE: 0.783067
         RMSE: 0.884911
         R¬≤ Score: -1.4678 (Poor - 146.8% variance explained)
      üîπ SMR: Training TCN (50 epochs)...
  ‚öôÔ∏è Training models for OUST (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-74 - OUST: Initiating feature extraction for training.
  [DIAGNOSTIC] OUST: fetch_training_data - Initial data rows: 205
   ‚Ü≥ OUST: rows after features available: 126
üéØ OUST: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] OUST: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö OUST: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ OUST: Training LSTM (50 epochs)...
      ‚è≥ SMR TCN: Epoch 10/50 (20%)
      ‚è≥ LEU LSTM: Epoch 20/50 (40%)
      ‚è≥ SMR TCN: Epoch 20/50 (40%)
       ‚úÖ AEVA XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=3856.6504 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 134.0s
    - LSTM: MSE=0.4504
    - TCN: MSE=0.2009
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 137.9 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.2009
        ‚Ä¢ LSTM: MSE=0.4504
        ‚Ä¢ Random Forest: MSE=2915.4027
        ‚Ä¢ XGBoost: MSE=3856.6504
        ‚Ä¢ LightGBM Regressor (CPU): MSE=3879.0384
   ‚úÖ AEVA: Phase 3/3 - Model selection complete!
  üèÜ WINNER for AEVA (TargetReturn): TCN with MSE=0.2009
üêõ DEBUG: AEVA - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for AEVA.
üêõ DEBUG: AEVA - Moving model to CPU before return...
üêõ DEBUG [22:19:45.242]: AEVA - Returning result metadata...
üêõ DEBUG: train_worker started for BKSY
  ‚öôÔ∏è Training models for BKSY (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-75 - BKSY: Initiating feature extraction for training.
  [DIAGNOSTIC] BKSY: fetch_training_data - Initial data rows: 205
   ‚Ü≥ BKSY: rows after features available: 126
üéØ BKSY: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] BKSY: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö BKSY: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ BKSY: Training LSTM (50 epochs)...
      ‚è≥ SMR TCN: Epoch 30/50 (60%)
      ‚è≥ PSIX LSTM: Epoch 30/50 (60%)
      üìä LSTM Regression Metrics:
         MSE: 0.171477
         RMSE: 0.414097
         R¬≤ Score: -1.7020 (Poor - 170.2% variance explained)
      üîπ UAMY: Training TCN (50 epochs)...
      ‚è≥ SMR TCN: Epoch 40/50 (80%)
      ‚è≥ PLTR LSTM: Epoch 10/50 (20%)
      üìä TCN Regression Metrics:
         MSE: 0.601371
         RMSE: 0.775481
         R¬≤ Score: -0.8952
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä SMR: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ SMR Random Forest: Starting GridSearchCV fit...
      ‚è≥ OUST LSTM: Epoch 10/50 (20%)
      ‚è≥ UAMY TCN: Epoch 10/50 (20%)
       ‚úÖ AMPX XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=371.0217 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 134.2s
    - LSTM: MSE=0.6157
    - TCN: MSE=0.3020
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 138.1 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.3020
        ‚Ä¢ LSTM: MSE=0.6157
        ‚Ä¢ Random Forest: MSE=359.0904
        ‚Ä¢ XGBoost: MSE=371.0217
        ‚Ä¢ LightGBM Regressor (CPU): MSE=766.4788
   ‚úÖ AMPX: Phase 3/3 - Model selection complete!
  üèÜ WINNER for AMPX (TargetReturn): TCN with MSE=0.3020
üêõ DEBUG: AMPX - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for AMPX.
üêõ DEBUG: AMPX - Moving model to CPU before return...
üêõ DEBUG [22:19:45.699]: AMPX - Returning result metadata...
üêõ DEBUG [22:19:45.700]: Main received result for AMPX
üêõ DEBUG: train_worker started for GRRR
  ‚öôÔ∏è Training models for GRRR (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-71 - GRRR: Initiating feature extraction for training.
  [DIAGNOSTIC] GRRR: fetch_training_data - Initial data rows: 205
   ‚Ü≥ GRRR: rows after features available: 126
üéØ GRRR: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] GRRR: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö GRRR: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ GRRR: Training LSTM (50 epochs)...
      ‚è≥ UAMY TCN: Epoch 20/50 (40%)
      ‚è≥ LEU LSTM: Epoch 30/50 (60%)
      ‚è≥ BKSY LSTM: Epoch 10/50 (20%)
      ‚è≥ UAMY TCN: Epoch 30/50 (60%)
      ‚è≥ PSIX LSTM: Epoch 40/50 (80%)
       ‚úÖ TMC XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=439.7524 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 134.5s
    - LSTM: MSE=0.4991
    - TCN: MSE=0.2876
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 138.4 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.2876
        ‚Ä¢ LSTM: MSE=0.4991
        ‚Ä¢ XGBoost: MSE=439.7524
        ‚Ä¢ Random Forest: MSE=453.7278
        ‚Ä¢ LightGBM Regressor (CPU): MSE=695.7269
   ‚úÖ TMC: Phase 3/3 - Model selection complete!
  üèÜ WINNER for TMC (TargetReturn): TCN with MSE=0.2876
üêõ DEBUG: TMC - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for TMC.
üêõ DEBUG: TMC - Moving model to CPU before return...
üêõ DEBUG [22:19:46.093]: TMC - Returning result metadata...
üêõ DEBUG: train_worker started for TSSI
üêõ DEBUG [22:19:46.096]: Main received result for TMC
üêõ DEBUG [22:19:46.096]: Main received result for ARQQ
üêõ DEBUG [22:19:46.096]: Main received result for AEVA
üêõ DEBUG: Training progress: 8/959 done
      ‚è≥ UAMY TCN: Epoch 40/50 (80%)
  ‚öôÔ∏è Training models for TSSI (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-61 - TSSI: Initiating feature extraction for training.
  [DIAGNOSTIC] TSSI: fetch_training_data - Initial data rows: 205
   ‚Ü≥ TSSI: rows after features available: 126
üéØ TSSI: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] TSSI: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö TSSI: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ TSSI: Training LSTM (50 epochs)...
      ‚è≥ PLTR LSTM: Epoch 20/50 (40%)
      ‚è≥ OUST LSTM: Epoch 20/50 (40%)
      üìä TCN Regression Metrics:
         MSE: 0.078412
         RMSE: 0.280021
         R¬≤ Score: -0.2355
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä UAMY: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ UAMY Random Forest: Starting GridSearchCV fit...
       ‚úÖ SRRK XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=24.9797 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 135.3s
    - LSTM: MSE=0.4919
    - TCN: MSE=0.3194
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 139.2 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.3194
        ‚Ä¢ LSTM: MSE=0.4919
        ‚Ä¢ Random Forest: MSE=20.1956
        ‚Ä¢ XGBoost: MSE=24.9797
        ‚Ä¢ LightGBM Regressor (CPU): MSE=26.1031
   ‚úÖ SRRK: Phase 3/3 - Model selection complete!
  üèÜ WINNER for SRRK (TargetReturn): TCN with MSE=0.3194
üêõ DEBUG: SRRK - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for SRRK.
üêõ DEBUG: SRRK - Moving model to CPU before return...
üêõ DEBUG [22:19:46.448]: SRRK - Returning result metadata...
üêõ DEBUG: train_worker started for ASPI
  ‚öôÔ∏è Training models for ASPI (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-72 - ASPI: Initiating feature extraction for training.
  [DIAGNOSTIC] ASPI: fetch_training_data - Initial data rows: 205
   ‚Ü≥ ASPI: rows after features available: 126
üéØ ASPI: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] ASPI: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö ASPI: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ ASPI: Training LSTM (50 epochs)...
      ‚è≥ LEU LSTM: Epoch 40/50 (80%)
      ‚è≥ GRRR LSTM: Epoch 10/50 (20%)
      ‚è≥ BKSY LSTM: Epoch 20/50 (40%)
       ‚úÖ SEZL XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=1023.0949 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 135.2s
    - LSTM: MSE=0.4569
    - TCN: MSE=0.2810
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 139.1 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.2810
        ‚Ä¢ LSTM: MSE=0.4569
        ‚Ä¢ Random Forest: MSE=748.7164
        ‚Ä¢ LightGBM Regressor (CPU): MSE=1011.8016
        ‚Ä¢ XGBoost: MSE=1023.0949
   ‚úÖ SEZL: Phase 3/3 - Model selection complete!
  üèÜ WINNER for SEZL (TargetReturn): TCN with MSE=0.2810
üêõ DEBUG: SEZL - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for SEZL.
üêõ DEBUG: SEZL - Moving model to CPU before return...
üêõ DEBUG [22:19:46.757]: SEZL - Returning result metadata...
üêõ DEBUG: train_worker started for RCAT
      üìä LSTM Regression Metrics:
         MSE: 0.765974
         RMSE: 0.875199
         R¬≤ Score: -1.3904 (Poor - 139.0% variance explained)
      üîπ PSIX: Training TCN (50 epochs)...
  ‚öôÔ∏è Training models for RCAT (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-69 - RCAT: Initiating feature extraction for training.
  [DIAGNOSTIC] RCAT: fetch_training_data - Initial data rows: 205
   ‚Ü≥ RCAT: rows after features available: 126
üéØ RCAT: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] RCAT: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö RCAT: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ RCAT: Training LSTM (50 epochs)...
      ‚è≥ TSSI LSTM: Epoch 10/50 (20%)
       ‚úÖ QNTM XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=1601.5973 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 135.1s
    - LSTM: MSE=0.2616
    - TCN: MSE=0.1845
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 139.2 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1845
        ‚Ä¢ LSTM: MSE=0.2616
        ‚Ä¢ Random Forest: MSE=1446.4740
        ‚Ä¢ XGBoost: MSE=1601.5973
        ‚Ä¢ LightGBM Regressor (CPU): MSE=2025.1683
   ‚úÖ QNTM: Phase 3/3 - Model selection complete!
  üèÜ WINNER for QNTM (TargetReturn): TCN with MSE=0.1845
üêõ DEBUG: QNTM - train_and_evaluate_models completed
       ‚úÖ IONQ XGBoost: GridSearchCV complete
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for QNTM.
üêõ DEBUG: QNTM - Moving model to CPU before return...
üêõ DEBUG [22:19:46.921]: QNTM - Returning result metadata...
    ‚úÖ üéØ BEST! XGBoost: MSE=121.4363 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 135.5s
    - LSTM: MSE=0.3306
    - TCN: MSE=0.1971
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 139.6 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1971
        ‚Ä¢ LSTM: MSE=0.3306
        ‚Ä¢ XGBoost: MSE=121.4363
        ‚Ä¢ Random Forest: MSE=146.9234
        ‚Ä¢ LightGBM Regressor (CPU): MSE=221.2162
   ‚úÖ IONQ: Phase 3/3 - Model selection complete!
  üèÜ WINNER for IONQ (TargetReturn): TCN with MSE=0.1971
üêõ DEBUG: IONQ - train_and_evaluate_models completed
      ‚è≥ PSIX TCN: Epoch 10/50 (20%)
üêõ DEBUG [22:19:46.924]: Main received result for QNTM
üêõ DEBUG: train_worker started for ACHR
üêõ DEBUG [22:19:46.924]: Main received result for ABVX
üêõ DEBUG [22:19:46.924]: Main received result for KC
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for IONQ.
üêõ DEBUG: IONQ - Moving model to CPU before return...
üêõ DEBUG [22:19:46.930]: IONQ - Returning result metadata...
üêõ DEBUG: train_worker started for NVTS
  ‚öôÔ∏è Training models for NVTS (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-67 - NVTS: Initiating feature extraction for training.
  [DIAGNOSTIC] NVTS: fetch_training_data - Initial data rows: 205
   ‚Ü≥ NVTS: rows after features available: 126
üéØ NVTS: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  ‚öôÔ∏è Training models for ACHR (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-70 - ACHR: Initiating feature extraction for training.
  [DIAGNOSTIC] ACHR: fetch_training_data - Initial data rows: 205
   ‚Ü≥ ACHR: rows after features available: 126
üéØ ACHR: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] NVTS: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö NVTS: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ NVTS: Training LSTM (50 epochs)...
  [DIAGNOSTIC] ACHR: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö ACHR: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ ACHR: Training LSTM (50 epochs)...
      ‚è≥ PLTR LSTM: Epoch 30/50 (60%)
      ‚è≥ OUST LSTM: Epoch 30/50 (60%)
      ‚è≥ PSIX TCN: Epoch 20/50 (40%)
       ‚úÖ DAVE XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=419.2261 (Best Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}) | Time: 135.8s
    - LSTM: MSE=0.4399
    - TCN: MSE=0.3671
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 139.8 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.3671
        ‚Ä¢ LSTM: MSE=0.4399
        ‚Ä¢ LightGBM Regressor (CPU): MSE=397.2072
        ‚Ä¢ XGBoost: MSE=419.2261
        ‚Ä¢ Random Forest: MSE=423.2286
   ‚úÖ DAVE: Phase 3/3 - Model selection complete!
  üèÜ WINNER for DAVE (TargetReturn): TCN with MSE=0.3671
üêõ DEBUG: DAVE - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for DAVE.
üêõ DEBUG: DAVE - Moving model to CPU before return...
üêõ DEBUG [22:19:47.134]: DAVE - Returning result metadata...
üêõ DEBUG [22:19:47.135]: Main received result for DAVE
üêõ DEBUG: Training progress: 12/959 done
üêõ DEBUG: train_worker started for KOD
üêõ DEBUG [22:19:47.136]: Main received result for SEZL
üêõ DEBUG [22:19:47.136]: Main received result for IONQ
üêõ DEBUG [22:19:47.136]: Main received result for SRRK
  ‚öôÔ∏è Training models for KOD (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-66 - KOD: Initiating feature extraction for training.
  [DIAGNOSTIC] KOD: fetch_training_data - Initial data rows: 205
   ‚Ü≥ KOD: rows after features available: 126
üéØ KOD: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] KOD: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö KOD: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ KOD: Training LSTM (50 epochs)...
      ‚è≥ ASPI LSTM: Epoch 10/50 (20%)
      ‚è≥ PSIX TCN: Epoch 30/50 (60%)
      üìä LSTM Regression Metrics:
         MSE: 1.065716
         RMSE: 1.032335
         R¬≤ Score: -1.6960 (Poor - 169.6% variance explained)
      üîπ LEU: Training TCN (50 epochs)...
      ‚è≥ GRRR LSTM: Epoch 20/50 (40%)
      ‚è≥ BKSY LSTM: Epoch 30/50 (60%)
      ‚è≥ PSIX TCN: Epoch 40/50 (80%)
      ‚è≥ LEU TCN: Epoch 10/50 (20%)
      ‚è≥ TSSI LSTM: Epoch 20/50 (40%)
      üìä TCN Regression Metrics:
         MSE: 0.484742
         RMSE: 0.696234
         R¬≤ Score: -0.5128
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä PSIX: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ PSIX Random Forest: Starting GridSearchCV fit...
      ‚è≥ RCAT LSTM: Epoch 10/50 (20%)
      ‚è≥ LEU TCN: Epoch 20/50 (40%)
      ‚è≥ PLTR LSTM: Epoch 40/50 (80%)
      ‚è≥ NVTS LSTM: Epoch 10/50 (20%)
      ‚è≥ OUST LSTM: Epoch 40/50 (80%)
      ‚è≥ ACHR LSTM: Epoch 10/50 (20%)
      ‚è≥ LEU TCN: Epoch 30/50 (60%)
      ‚è≥ ASPI LSTM: Epoch 20/50 (40%)
      ‚è≥ KOD LSTM: Epoch 10/50 (20%)
      ‚è≥ LEU TCN: Epoch 40/50 (80%)
      ‚è≥ GRRR LSTM: Epoch 30/50 (60%)
      ‚è≥ BKSY LSTM: Epoch 40/50 (80%)
       ‚úÖ HOOD Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=266.7814 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.9s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ HOOD LightGBM Regressor (CPU): Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.418402
         RMSE: 0.646840
         R¬≤ Score: -0.0585
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä LEU: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ LEU Random Forest: Starting GridSearchCV fit...
      ‚è≥ TSSI LSTM: Epoch 30/50 (60%)
      üìä LSTM Regression Metrics:
         MSE: 0.360167
         RMSE: 0.600139
         R¬≤ Score: -1.4262 (Poor - 142.6% variance explained)
      üîπ PLTR: Training TCN (50 epochs)...
      ‚è≥ RCAT LSTM: Epoch 20/50 (40%)
      ‚è≥ NVTS LSTM: Epoch 20/50 (40%)
      ‚è≥ ACHR LSTM: Epoch 20/50 (40%)
      üìä LSTM Regression Metrics:
         MSE: 0.959024
         RMSE: 0.979298
         R¬≤ Score: -2.1157 (Poor - 211.6% variance explained)
      üîπ OUST: Training TCN (50 epochs)...
      ‚è≥ PLTR TCN: Epoch 10/50 (20%)
      ‚è≥ ASPI LSTM: Epoch 30/50 (60%)
      ‚è≥ OUST TCN: Epoch 10/50 (20%)
      ‚è≥ KOD LSTM: Epoch 20/50 (40%)
      ‚è≥ PLTR TCN: Epoch 20/50 (40%)
      ‚è≥ OUST TCN: Epoch 20/50 (40%)
      ‚è≥ GRRR LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.762231
         RMSE: 0.873059
         R¬≤ Score: -1.5151 (Poor - 151.5% variance explained)
      üîπ BKSY: Training TCN (50 epochs)...
      ‚è≥ PLTR TCN: Epoch 30/50 (60%)
      ‚è≥ TSSI LSTM: Epoch 40/50 (80%)
      ‚è≥ OUST TCN: Epoch 30/50 (60%)
      ‚è≥ BKSY TCN: Epoch 10/50 (20%)
      ‚è≥ PLTR TCN: Epoch 40/50 (80%)
      ‚è≥ NVTS LSTM: Epoch 30/50 (60%)
      ‚è≥ OUST TCN: Epoch 40/50 (80%)
       ‚úÖ HOOD LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=207.5341 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 1.2s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ HOOD XGBoost: Starting GridSearchCV fit...
      ‚è≥ RCAT LSTM: Epoch 30/50 (60%)
      ‚è≥ BKSY TCN: Epoch 20/50 (40%)
      ‚è≥ ACHR LSTM: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.304059
         RMSE: 0.551416
         R¬≤ Score: -1.0483
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä PLTR: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ PLTR Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.477584
         RMSE: 0.691075
         R¬≤ Score: -0.5516
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä OUST: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ OUST Random Forest: Starting GridSearchCV fit...
      ‚è≥ ASPI LSTM: Epoch 40/50 (80%)
      ‚è≥ BKSY TCN: Epoch 30/50 (60%)
      ‚è≥ KOD LSTM: Epoch 30/50 (60%)
      ‚è≥ BKSY TCN: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.011203
         RMSE: 0.105845
         R¬≤ Score: -1.0062 (Poor - 100.6% variance explained)
      üîπ GRRR: Training TCN (50 epochs)...
      üìä TCN Regression Metrics:
         MSE: 0.470413
         RMSE: 0.685867
         R¬≤ Score: -0.5522
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä BKSY: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ BKSY Random Forest: Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 1.042517
         RMSE: 1.021037
         R¬≤ Score: -1.6830 (Poor - 168.3% variance explained)
      üîπ TSSI: Training TCN (50 epochs)...
       ‚úÖ SMR Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=385.3084 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 4.4s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ SMR LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ GRRR TCN: Epoch 10/50 (20%)
      ‚è≥ TSSI TCN: Epoch 10/50 (20%)
      ‚è≥ NVTS LSTM: Epoch 40/50 (80%)
      ‚è≥ ACHR LSTM: Epoch 40/50 (80%)
      ‚è≥ GRRR TCN: Epoch 20/50 (40%)
      ‚è≥ TSSI TCN: Epoch 20/50 (40%)
      ‚è≥ RCAT LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.246710
         RMSE: 0.496699
         R¬≤ Score: -0.4471 (Poor - 44.7% variance explained)
      üîπ ASPI: Training TCN (50 epochs)...
      ‚è≥ GRRR TCN: Epoch 30/50 (60%)
      ‚è≥ TSSI TCN: Epoch 30/50 (60%)
      ‚è≥ ASPI TCN: Epoch 10/50 (20%)
      ‚è≥ KOD LSTM: Epoch 40/50 (80%)
      ‚è≥ GRRR TCN: Epoch 40/50 (80%)
      ‚è≥ TSSI TCN: Epoch 40/50 (80%)
      ‚è≥ ASPI TCN: Epoch 20/50 (40%)
      üìä TCN Regression Metrics:
         MSE: 0.009157
         RMSE: 0.095690
         R¬≤ Score: -0.6397
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä GRRR: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ GRRR Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.770795
         RMSE: 0.877950
         R¬≤ Score: -0.9837
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä TSSI: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ TSSI Random Forest: Starting GridSearchCV fit...
       ‚úÖ UAMY Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=263.7356 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 4.6s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ UAMY LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ ASPI TCN: Epoch 30/50 (60%)
      üìä LSTM Regression Metrics:
         MSE: 0.797583
         RMSE: 0.893075
         R¬≤ Score: -0.9521 (Poor - 95.2% variance explained)
      üîπ NVTS: Training TCN (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.063537
         RMSE: 0.252066
         R¬≤ Score: -0.8729 (Poor - 87.3% variance explained)
      üîπ ACHR: Training TCN (50 epochs)...
      ‚è≥ ASPI TCN: Epoch 40/50 (80%)
      ‚è≥ NVTS TCN: Epoch 10/50 (20%)
      ‚è≥ ACHR TCN: Epoch 10/50 (20%)
      üìä TCN Regression Metrics:
         MSE: 0.253998
         RMSE: 0.503982
         R¬≤ Score: -0.4898
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä ASPI: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ ASPI Random Forest: Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 0.304704
         RMSE: 0.552000
         R¬≤ Score: -1.3668 (Poor - 136.7% variance explained)
      üîπ RCAT: Training TCN (50 epochs)...
       ‚úÖ SMR LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=261.5929 (Best Params: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 200}) | Time: 1.2s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ SMR XGBoost: Starting GridSearchCV fit...
      ‚è≥ NVTS TCN: Epoch 20/50 (40%)
      ‚è≥ ACHR TCN: Epoch 20/50 (40%)
      üìä LSTM Regression Metrics:
         MSE: 0.519629
         RMSE: 0.720853
         R¬≤ Score: -1.5292 (Poor - 152.9% variance explained)
      üîπ KOD: Training TCN (50 epochs)...
      ‚è≥ RCAT TCN: Epoch 10/50 (20%)
      ‚è≥ NVTS TCN: Epoch 30/50 (60%)
      ‚è≥ ACHR TCN: Epoch 30/50 (60%)
      ‚è≥ KOD TCN: Epoch 10/50 (20%)
      ‚è≥ RCAT TCN: Epoch 20/50 (40%)
      ‚è≥ NVTS TCN: Epoch 40/50 (80%)
      ‚è≥ ACHR TCN: Epoch 40/50 (80%)
      ‚è≥ KOD TCN: Epoch 20/50 (40%)
      ‚è≥ RCAT TCN: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.070860
         RMSE: 0.266195
         R¬≤ Score: -1.0887
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä ACHR: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ ACHR Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.906359
         RMSE: 0.952029
         R¬≤ Score: -1.2184
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä NVTS: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ NVTS Random Forest: Starting GridSearchCV fit...
      ‚è≥ KOD TCN: Epoch 30/50 (60%)
       ‚úÖ UAMY LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=342.0728 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 1.0s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ UAMY XGBoost: Starting GridSearchCV fit...
      ‚è≥ RCAT TCN: Epoch 40/50 (80%)
      ‚è≥ KOD TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.448399
         RMSE: 0.669626
         R¬≤ Score: -1.1825
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä KOD: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ KOD Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.199448
         RMSE: 0.446596
         R¬≤ Score: -0.5492
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä RCAT: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ RCAT Random Forest: Starting GridSearchCV fit...
       ‚úÖ PSIX Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=572.2533 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 4.5s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ PSIX LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ LEU Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=898.3984 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 4.4s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ LEU LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ PSIX LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=780.2259 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 100}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ PSIX XGBoost: Starting GridSearchCV fit...
       ‚úÖ LEU LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=678.8349 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ LEU XGBoost: Starting GridSearchCV fit...
       ‚úÖ OUST Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=1030.6599 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 4.0s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ OUST LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ PLTR Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=95.4295 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 4.3s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ PLTR LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ BKSY Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=520.0179 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.9s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ BKSY LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ OUST LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=729.2499 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ OUST XGBoost: Starting GridSearchCV fit...
       ‚úÖ GRRR Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=2915.8157 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ GRRR LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ TSSI Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=570.7483 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ TSSI LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ BKSY LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=285.7639 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ BKSY XGBoost: Starting GridSearchCV fit...
       ‚úÖ PLTR LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=136.2601 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 1.0s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ PLTR XGBoost: Starting GridSearchCV fit...
       ‚úÖ ASPI Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=212.3672 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ ASPI LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ TSSI LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=613.4824 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ TSSI XGBoost: Starting GridSearchCV fit...
       ‚úÖ ACHR Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=133.2526 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.7s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ ACHR LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ GRRR LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=3272.0158 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ GRRR XGBoost: Starting GridSearchCV fit...
       ‚úÖ NVTS Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=541.8545 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ NVTS LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ KOD Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=117.6751 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 3.6s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ KOD LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ RCAT Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=317.5232 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.6s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ RCAT LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ ASPI LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=200.2992 (Best Params: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ ASPI XGBoost: Starting GridSearchCV fit...
       ‚úÖ ACHR LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=234.4106 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ ACHR XGBoost: Starting GridSearchCV fit...
       ‚úÖ NVTS LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=797.0439 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ NVTS XGBoost: Starting GridSearchCV fit...
       ‚úÖ KOD LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=232.3084 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ KOD XGBoost: Starting GridSearchCV fit...
       ‚úÖ RCAT LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=405.9426 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ RCAT XGBoost: Starting GridSearchCV fit...
       ‚úÖ HOOD XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=296.7064 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 120.0s
    - LSTM: MSE=0.7961
    - TCN: MSE=0.7717
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 125.0 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.7717
        ‚Ä¢ LSTM: MSE=0.7961
        ‚Ä¢ LightGBM Regressor (CPU): MSE=207.5341
        ‚Ä¢ Random Forest: MSE=266.7814
        ‚Ä¢ XGBoost: MSE=296.7064
   ‚úÖ HOOD: Phase 3/3 - Model selection complete!
  üèÜ WINNER for HOOD (TargetReturn): TCN with MSE=0.7717
üêõ DEBUG: HOOD - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for HOOD.
üêõ DEBUG: HOOD - Moving model to CPU before return...
üêõ DEBUG [22:21:49.420]: HOOD - Returning result metadata...
üêõ DEBUG [22:21:49.421]: Main received result for HOODüêõ DEBUG: train_worker started for GRPN

üêõ DEBUG: Training progress: 16/959 done
  ‚öôÔ∏è Training models for GRPN (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-62 - GRPN: Initiating feature extraction for training.
  [DIAGNOSTIC] GRPN: fetch_training_data - Initial data rows: 205
   ‚Ü≥ GRPN: rows after features available: 126
üéØ GRPN: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] GRPN: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö GRPN: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ GRPN: Training LSTM (50 epochs)...
      ‚è≥ GRPN LSTM: Epoch 10/50 (20%)
      ‚è≥ GRPN LSTM: Epoch 20/50 (40%)
      ‚è≥ GRPN LSTM: Epoch 30/50 (60%)
      ‚è≥ GRPN LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.165687
         RMSE: 0.407047
         R¬≤ Score: -0.5925 (Poor - 59.3% variance explained)
      üîπ GRPN: Training TCN (50 epochs)...
      ‚è≥ GRPN TCN: Epoch 10/50 (20%)
      ‚è≥ GRPN TCN: Epoch 20/50 (40%)
      ‚è≥ GRPN TCN: Epoch 30/50 (60%)
      ‚è≥ GRPN TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.105116
         RMSE: 0.324217
         R¬≤ Score: -0.0103
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä GRPN: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ GRPN Random Forest: Starting GridSearchCV fit...
       ‚úÖ GRPN Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=258.8612 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 2.6s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ GRPN LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ GRPN LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=238.6251 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.6s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ GRPN XGBoost: Starting GridSearchCV fit...
       ‚úÖ UAMY XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=338.7838 (Best Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}) | Time: 126.8s
    - LSTM: MSE=0.1715
    - TCN: MSE=0.0784
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 132.4 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0784
        ‚Ä¢ LSTM: MSE=0.1715
        ‚Ä¢ Random Forest: MSE=263.7356
        ‚Ä¢ XGBoost: MSE=338.7838
        ‚Ä¢ LightGBM Regressor (CPU): MSE=342.0728
   ‚úÖ UAMY: Phase 3/3 - Model selection complete!
  üèÜ WINNER for UAMY (TargetReturn): TCN with MSE=0.0784
üêõ DEBUG: UAMY - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for UAMY.
üêõ DEBUG: UAMY - Moving model to CPU before return...
üêõ DEBUG [22:21:58.661]: UAMY - Returning result metadata...
üêõ DEBUG: train_worker started for CLS
  ‚öôÔ∏è Training models for CLS (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-73 - CLS: Initiating feature extraction for training.
  [DIAGNOSTIC] CLS: fetch_training_data - Initial data rows: 205
   ‚Ü≥ CLS: rows after features available: 126
üéØ CLS: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] CLS: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö CLS: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ CLS: Training LSTM (50 epochs)...
      ‚è≥ CLS LSTM: Epoch 10/50 (20%)
       ‚úÖ SMR XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=358.3666 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 128.2s
    - LSTM: MSE=0.7831
    - TCN: MSE=0.6014
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 133.8 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.6014
        ‚Ä¢ LSTM: MSE=0.7831
        ‚Ä¢ LightGBM Regressor (CPU): MSE=261.5929
        ‚Ä¢ XGBoost: MSE=358.3666
        ‚Ä¢ Random Forest: MSE=385.3084
   ‚úÖ SMR: Phase 3/3 - Model selection complete!
  üèÜ WINNER for SMR (TargetReturn): TCN with MSE=0.6014
üêõ DEBUG: SMR - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for SMR.
üêõ DEBUG: SMR - Moving model to CPU before return...
üêõ DEBUG [22:21:59.467]: SMR - Returning result metadata...
üêõ DEBUG: train_worker started for CRDO
üêõ DEBUG [22:21:59.469]: Main received result for SMR
üêõ DEBUG [22:21:59.469]: Main received result for UAMY
  ‚öôÔ∏è Training models for CRDO (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-68 - CRDO: Initiating feature extraction for training.
  [DIAGNOSTIC] CRDO: fetch_training_data - Initial data rows: 205
   ‚Ü≥ CRDO: rows after features available: 126
üéØ CRDO: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] CRDO: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö CRDO: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ CRDO: Training LSTM (50 epochs)...
      ‚è≥ CLS LSTM: Epoch 20/50 (40%)
      ‚è≥ CRDO LSTM: Epoch 10/50 (20%)
      ‚è≥ CLS LSTM: Epoch 30/50 (60%)
      ‚è≥ CRDO LSTM: Epoch 20/50 (40%)
      ‚è≥ CLS LSTM: Epoch 40/50 (80%)
      ‚è≥ CRDO LSTM: Epoch 30/50 (60%)
      üìä LSTM Regression Metrics:
         MSE: 0.607385
         RMSE: 0.779349
         R¬≤ Score: -0.7534 (Poor - 75.3% variance explained)
      üîπ CLS: Training TCN (50 epochs)...
      ‚è≥ CRDO LSTM: Epoch 40/50 (80%)
      ‚è≥ CLS TCN: Epoch 10/50 (20%)
      ‚è≥ CLS TCN: Epoch 20/50 (40%)
      ‚è≥ CLS TCN: Epoch 30/50 (60%)
      ‚è≥ CLS TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.869887
         RMSE: 0.932677
         R¬≤ Score: -1.5112
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä CLS: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ CLS Random Forest: Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 0.568953
         RMSE: 0.754290
         R¬≤ Score: -0.5353 (Poor - 53.5% variance explained)
      üîπ CRDO: Training TCN (50 epochs)...
      ‚è≥ CRDO TCN: Epoch 10/50 (20%)
      ‚è≥ CRDO TCN: Epoch 20/50 (40%)
      ‚è≥ CRDO TCN: Epoch 30/50 (60%)
      ‚è≥ CRDO TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.929761
         RMSE: 0.964241
         R¬≤ Score: -1.5090
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä CRDO: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ CRDO Random Forest: Starting GridSearchCV fit...
       ‚úÖ CLS Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=251.8098 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 2.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ CLS LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ CRDO Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=258.4516 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.0s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ CRDO LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ CLS LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=134.1547 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ CLS XGBoost: Starting GridSearchCV fit...
       ‚úÖ CRDO LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=165.5983 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ CRDO XGBoost: Starting GridSearchCV fit...
       ‚úÖ PSIX XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=1024.4189 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 135.4s
    - LSTM: MSE=0.7660
    - TCN: MSE=0.4847
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 140.7 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.4847
        ‚Ä¢ LSTM: MSE=0.7660
        ‚Ä¢ Random Forest: MSE=572.2533
        ‚Ä¢ LightGBM Regressor (CPU): MSE=780.2259
        ‚Ä¢ XGBoost: MSE=1024.4189
   ‚úÖ PSIX: Phase 3/3 - Model selection complete!
  üèÜ WINNER for PSIX (TargetReturn): TCN with MSE=0.4847
üêõ DEBUG: PSIX - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for PSIX.
üêõ DEBUG: PSIX - Moving model to CPU before return...
üêõ DEBUG [22:22:08.433]: PSIX - Returning result metadata...
üêõ DEBUG: train_worker started for ROOT
üêõ DEBUG [22:22:08.433]: Main received result for PSIX
  ‚öôÔ∏è Training models for ROOT (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-65 - ROOT: Initiating feature extraction for training.
  [DIAGNOSTIC] ROOT: fetch_training_data - Initial data rows: 205
   ‚Ü≥ ROOT: rows after features available: 126
üéØ ROOT: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] ROOT: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö ROOT: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ ROOT: Training LSTM (50 epochs)...
      ‚è≥ ROOT LSTM: Epoch 10/50 (20%)
      ‚è≥ ROOT LSTM: Epoch 20/50 (40%)
       ‚úÖ BKSY XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=648.6837 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}) | Time: 134.9s
    - LSTM: MSE=0.7622
    - TCN: MSE=0.4704
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 139.7 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.4704
        ‚Ä¢ LSTM: MSE=0.7622
        ‚Ä¢ LightGBM Regressor (CPU): MSE=285.7639
        ‚Ä¢ Random Forest: MSE=520.0179
        ‚Ä¢ XGBoost: MSE=648.6837
   ‚úÖ BKSY: Phase 3/3 - Model selection complete!
  üèÜ WINNER for BKSY (TargetReturn): TCN with MSE=0.4704
üêõ DEBUG: BKSY - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for BKSY.
üêõ DEBUG: BKSY - Moving model to CPU before return...
üêõ DEBUG [22:22:09.675]: BKSY - Returning result metadata...
üêõ DEBUG: train_worker started for BE
  ‚öôÔ∏è Training models for BE (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-75 - BE: Initiating feature extraction for training.
  [DIAGNOSTIC] BE: fetch_training_data - Initial data rows: 205
   ‚Ü≥ BE: rows after features available: 126
üéØ BE: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] BE: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö BE: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ BE: Training LSTM (50 epochs)...
      ‚è≥ ROOT LSTM: Epoch 30/50 (60%)
      ‚è≥ BE LSTM: Epoch 10/50 (20%)
      ‚è≥ ROOT LSTM: Epoch 40/50 (80%)
      ‚è≥ BE LSTM: Epoch 20/50 (40%)
       ‚úÖ PLTR XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=116.8214 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 136.3s
    - LSTM: MSE=0.3602
    - TCN: MSE=0.3041
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 141.5 seconds (2.4 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.3041
        ‚Ä¢ LSTM: MSE=0.3602
        ‚Ä¢ Random Forest: MSE=95.4295
        ‚Ä¢ XGBoost: MSE=116.8214
        ‚Ä¢ LightGBM Regressor (CPU): MSE=136.2601
   ‚úÖ PLTR: Phase 3/3 - Model selection complete!
  üèÜ WINNER for PLTR (TargetReturn): TCN with MSE=0.3041
üêõ DEBUG: PLTR - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for PLTR.
üêõ DEBUG: PLTR - Moving model to CPU before return...
üêõ DEBUG [22:22:11.057]: PLTR - Returning result metadata...
üêõ DEBUG: train_worker started for SLDP
      üìä LSTM Regression Metrics:
         MSE: 0.136834
         RMSE: 0.369910
         R¬≤ Score: -0.7613 (Poor - 76.1% variance explained)
      üîπ ROOT: Training TCN (50 epochs)...
  ‚öôÔ∏è Training models for SLDP (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-63 - SLDP: Initiating feature extraction for training.
  [DIAGNOSTIC] SLDP: fetch_training_data - Initial data rows: 205
   ‚Ü≥ SLDP: rows after features available: 126
üéØ SLDP: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] SLDP: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö SLDP: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ SLDP: Training LSTM (50 epochs)...
      ‚è≥ BE LSTM: Epoch 30/50 (60%)
      ‚è≥ ROOT TCN: Epoch 10/50 (20%)
      ‚è≥ ROOT TCN: Epoch 20/50 (40%)
      ‚è≥ ROOT TCN: Epoch 30/50 (60%)
      ‚è≥ ROOT TCN: Epoch 40/50 (80%)
      ‚è≥ BE LSTM: Epoch 40/50 (80%)
      ‚è≥ SLDP LSTM: Epoch 10/50 (20%)
      üìä TCN Regression Metrics:
         MSE: 0.093781
         RMSE: 0.306236
         R¬≤ Score: -0.2072
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä ROOT: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ ROOT Random Forest: Starting GridSearchCV fit...
      ‚è≥ SLDP LSTM: Epoch 20/50 (40%)
      üìä LSTM Regression Metrics:
         MSE: 0.112057
         RMSE: 0.334749
         R¬≤ Score: -0.9794 (Poor - 97.9% variance explained)
      üîπ BE: Training TCN (50 epochs)...
      ‚è≥ BE TCN: Epoch 10/50 (20%)
       ‚úÖ GRRR XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=2344.9219 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 137.0s
    - LSTM: MSE=0.0112
    - TCN: MSE=0.0092
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 141.7 seconds (2.4 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0092
        ‚Ä¢ LSTM: MSE=0.0112
        ‚Ä¢ XGBoost: MSE=2344.9219
        ‚Ä¢ Random Forest: MSE=2915.8157
        ‚Ä¢ LightGBM Regressor (CPU): MSE=3272.0158
   ‚úÖ GRRR: Phase 3/3 - Model selection complete!
  üèÜ WINNER for GRRR (TargetReturn): TCN with MSE=0.0092
üêõ DEBUG: GRRR - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for GRRR.
üêõ DEBUG: GRRR - Moving model to CPU before return...
üêõ DEBUG [22:22:12.447]: GRRR - Returning result metadata...
üêõ DEBUG: train_worker started for SGHC
  ‚öôÔ∏è Training models for SGHC (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-71 - SGHC: Initiating feature extraction for training.
  [DIAGNOSTIC] SGHC: fetch_training_data - Initial data rows: 205
   ‚Ü≥ SGHC: rows after features available: 126
üéØ SGHC: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
      ‚è≥ BE TCN: Epoch 20/50 (40%)
  [DIAGNOSTIC] SGHC: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö SGHC: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ SGHC: Training LSTM (50 epochs)...
      ‚è≥ BE TCN: Epoch 30/50 (60%)
       ‚úÖ LEU XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=1001.4411 (Best Params: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200}) | Time: 139.1s
    - LSTM: MSE=1.0657
    - TCN: MSE=0.4184
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 144.3 seconds (2.4 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.4184
        ‚Ä¢ LSTM: MSE=1.0657
        ‚Ä¢ LightGBM Regressor (CPU): MSE=678.8349
        ‚Ä¢ Random Forest: MSE=898.3984
        ‚Ä¢ XGBoost: MSE=1001.4411
   ‚úÖ LEU: Phase 3/3 - Model selection complete!
  üèÜ WINNER for LEU (TargetReturn): TCN with MSE=0.4184
üêõ DEBUG: LEU - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for LEU.
üêõ DEBUG: LEU - Moving model to CPU before return...
üêõ DEBUG [22:22:12.644]: LEU - Returning result metadata...
üêõ DEBUG [22:22:12.644]: Main received result for LEU
üêõ DEBUG: Training progress: 20/959 done
üêõ DEBUG [22:22:12.644]: Main received result for PLTR
üêõ DEBUG: train_worker started for HIMS
  ‚öôÔ∏è Training models for HIMS (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-64 - HIMS: Initiating feature extraction for training.
  [DIAGNOSTIC] HIMS: fetch_training_data - Initial data rows: 205
   ‚Ü≥ HIMS: rows after features available: 126
üéØ HIMS: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] HIMS: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö HIMS: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ HIMS: Training LSTM (50 epochs)...
      ‚è≥ SLDP LSTM: Epoch 30/50 (60%)
      ‚è≥ BE TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.077703
         RMSE: 0.278753
         R¬≤ Score: -0.3725
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä BE: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ BE Random Forest: Starting GridSearchCV fit...
      ‚è≥ SGHC LSTM: Epoch 10/50 (20%)
       ‚úÖ ACHR XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=148.4294 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}) | Time: 137.0s
    - LSTM: MSE=0.0635
    - TCN: MSE=0.0709
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 141.4 seconds (2.4 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.0635
        ‚Ä¢ TCN: MSE=0.0709
        ‚Ä¢ Random Forest: MSE=133.2526
        ‚Ä¢ XGBoost: MSE=148.4294
        ‚Ä¢ LightGBM Regressor (CPU): MSE=234.4106
   ‚úÖ ACHR: Phase 3/3 - Model selection complete!
  üèÜ WINNER for ACHR (TargetReturn): LSTM with MSE=0.0635
üêõ DEBUG: ACHR - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for ACHR.
üêõ DEBUG: ACHR - Moving model to CPU before return...
üêõ DEBUG [22:22:13.146]: ACHR - Returning result metadata...
üêõ DEBUG: train_worker started for ATAI
  ‚öôÔ∏è Training models for ATAI (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-70 - ATAI: Initiating feature extraction for training.
  [DIAGNOSTIC] ATAI: fetch_training_data - Initial data rows: 205
   ‚Ü≥ ATAI: rows after features available: 126
üéØ ATAI: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] ATAI: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö ATAI: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ ATAI: Training LSTM (50 epochs)...
      ‚è≥ HIMS LSTM: Epoch 10/50 (20%)
      ‚è≥ SLDP LSTM: Epoch 40/50 (80%)
      ‚è≥ SGHC LSTM: Epoch 20/50 (40%)
      ‚è≥ ATAI LSTM: Epoch 10/50 (20%)
       ‚úÖ OUST XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=995.2932 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 139.4s
    - LSTM: MSE=0.9590
    - TCN: MSE=0.4776
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 144.2 seconds (2.4 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.4776
        ‚Ä¢ LSTM: MSE=0.9590
        ‚Ä¢ LightGBM Regressor (CPU): MSE=729.2499
        ‚Ä¢ XGBoost: MSE=995.2932
        ‚Ä¢ Random Forest: MSE=1030.6599
   ‚úÖ OUST: Phase 3/3 - Model selection complete!
  üèÜ WINNER for OUST (TargetReturn): TCN with MSE=0.4776
üêõ DEBUG: OUST - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for OUST.
üêõ DEBUG: OUST - Moving model to CPU before return...
üêõ DEBUG [22:22:13.848]: OUST - Returning result metadata...
üêõ DEBUG: train_worker started for QURE
üêõ DEBUG [22:22:13.849]: Main received result for OUST
üêõ DEBUG [22:22:13.849]: Main received result for BKSY
üêõ DEBUG [22:22:13.849]: Main received result for GRRR
üêõ DEBUG: Training progress: 24/959 done
       ‚úÖ KOD XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=99.9767 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}) | Time: 137.4s
    - LSTM: MSE=0.5196
    - TCN: MSE=0.4484
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 141.8 seconds (2.4 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.4484
        ‚Ä¢ LSTM: MSE=0.5196
        ‚Ä¢ XGBoost: MSE=99.9767
        ‚Ä¢ Random Forest: MSE=117.6751
        ‚Ä¢ LightGBM Regressor (CPU): MSE=232.3084
   ‚úÖ KOD: Phase 3/3 - Model selection complete!
  üèÜ WINNER for KOD (TargetReturn): TCN with MSE=0.4484
üêõ DEBUG: KOD - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for KOD.
üêõ DEBUG: KOD - Moving model to CPU before return...
üêõ DEBUG [22:22:13.860]: KOD - Returning result metadata...
üêõ DEBUG: train_worker started for ZVIA
  ‚öôÔ∏è Training models for QURE (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-74 - QURE: Initiating feature extraction for training.
  [DIAGNOSTIC] QURE: fetch_training_data - Initial data rows: 205
   ‚Ü≥ QURE: rows after features available: 126
üéØ QURE: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] QURE: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö QURE: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ QURE: Training LSTM (50 epochs)...
  ‚öôÔ∏è Training models for ZVIA (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-66 - ZVIA: Initiating feature extraction for training.
  [DIAGNOSTIC] ZVIA: fetch_training_data - Initial data rows: 205
   ‚Ü≥ ZVIA: rows after features available: 126
üéØ ZVIA: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] ZVIA: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö ZVIA: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ ZVIA: Training LSTM (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.527642
         RMSE: 0.726390
         R¬≤ Score: -1.1508 (Poor - 115.1% variance explained)
      üîπ SLDP: Training TCN (50 epochs)...
      ‚è≥ HIMS LSTM: Epoch 20/50 (40%)
      ‚è≥ SLDP TCN: Epoch 10/50 (20%)
      ‚è≥ SLDP TCN: Epoch 20/50 (40%)
      ‚è≥ SGHC LSTM: Epoch 30/50 (60%)
      ‚è≥ SLDP TCN: Epoch 30/50 (60%)
      ‚è≥ ATAI LSTM: Epoch 20/50 (40%)
      ‚è≥ ZVIA LSTM: Epoch 10/50 (20%)
      ‚è≥ QURE LSTM: Epoch 10/50 (20%)
       ‚úÖ TSSI XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=505.9753 (Best Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}) | Time: 139.2s
    - LSTM: MSE=1.0425
    - TCN: MSE=0.7708
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 143.8 seconds (2.4 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.7708
        ‚Ä¢ LSTM: MSE=1.0425
        ‚Ä¢ XGBoost: MSE=505.9753
        ‚Ä¢ Random Forest: MSE=570.7483
        ‚Ä¢ LightGBM Regressor (CPU): MSE=613.4824
   ‚úÖ TSSI: Phase 3/3 - Model selection complete!
  üèÜ WINNER for TSSI (TargetReturn): TCN with MSE=0.7708
üêõ DEBUG: TSSI - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for TSSI.
üêõ DEBUG: TSSI - Moving model to CPU before return...
üêõ DEBUG [22:22:14.641]: TSSI - Returning result metadata...
üêõ DEBUG: train_worker started for PGY
üêõ DEBUG [22:22:14.643]: Main received result for TSSI
      ‚è≥ HIMS LSTM: Epoch 30/50 (60%)
      ‚è≥ SLDP TCN: Epoch 40/50 (80%)
  ‚öôÔ∏è Training models for PGY (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-61 - PGY: Initiating feature extraction for training.
  [DIAGNOSTIC] PGY: fetch_training_data - Initial data rows: 205
   ‚Ü≥ PGY: rows after features available: 126
üéØ PGY: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] PGY: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö PGY: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ PGY: Training LSTM (50 epochs)...
      üìä TCN Regression Metrics:
         MSE: 0.600474
         RMSE: 0.774903
         R¬≤ Score: -1.4477
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä SLDP: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ SLDP Random Forest: Starting GridSearchCV fit...
      ‚è≥ SGHC LSTM: Epoch 40/50 (80%)
      ‚è≥ ATAI LSTM: Epoch 30/50 (60%)
      ‚è≥ QURE LSTM: Epoch 20/50 (40%)
      ‚è≥ ZVIA LSTM: Epoch 20/50 (40%)
      ‚è≥ PGY LSTM: Epoch 10/50 (20%)
      ‚è≥ HIMS LSTM: Epoch 40/50 (80%)
       ‚úÖ NVTS XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=617.0351 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 139.1s
    - LSTM: MSE=0.7976
    - TCN: MSE=0.9064
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 143.7 seconds (2.4 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.7976
        ‚Ä¢ TCN: MSE=0.9064
        ‚Ä¢ Random Forest: MSE=541.8545
        ‚Ä¢ XGBoost: MSE=617.0351
        ‚Ä¢ LightGBM Regressor (CPU): MSE=797.0439
   ‚úÖ NVTS: Phase 3/3 - Model selection complete!
  üèÜ WINNER for NVTS (TargetReturn): LSTM with MSE=0.7976
üêõ DEBUG: NVTS - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for NVTS.
üêõ DEBUG: NVTS - Moving model to CPU before return...
üêõ DEBUG [22:22:15.456]: NVTS - Returning result metadata...
üêõ DEBUG: train_worker started for INOD
  ‚öôÔ∏è Training models for INOD (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-67 - INOD: Initiating feature extraction for training.
  [DIAGNOSTIC] INOD: fetch_training_data - Initial data rows: 205
   ‚Ü≥ INOD: rows after features available: 126
üéØ INOD: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] INOD: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö INOD: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ INOD: Training LSTM (50 epochs)...
       ‚úÖ ROOT Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=128.6593 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ ROOT LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ RCAT XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=291.9062 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 139.5s
    - LSTM: MSE=0.3047
    - TCN: MSE=0.1994
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 143.8 seconds (2.4 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1994
        ‚Ä¢ LSTM: MSE=0.3047
        ‚Ä¢ XGBoost: MSE=291.9062
        ‚Ä¢ Random Forest: MSE=317.5232
        ‚Ä¢ LightGBM Regressor (CPU): MSE=405.9426
   ‚úÖ RCAT: Phase 3/3 - Model selection complete!
  üèÜ WINNER for RCAT (TargetReturn): TCN with MSE=0.1994
üêõ DEBUG: RCAT - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for RCAT.
üêõ DEBUG: RCAT - Moving model to CPU before return...
üêõ DEBUG [22:22:15.911]: RCAT - Returning result metadata...
üêõ DEBUG: train_worker started for GRAL
  ‚öôÔ∏è Training models for GRAL (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-69 - GRAL: Initiating feature extraction for training.
  [DIAGNOSTIC] GRAL: fetch_training_data - Initial data rows: 205
   ‚Ü≥ GRAL: rows after features available: 126
üéØ GRAL: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] GRAL: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö GRAL: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ GRAL: Training LSTM (50 epochs)...
      ‚è≥ ZVIA LSTM: Epoch 30/50 (60%)
      ‚è≥ QURE LSTM: Epoch 30/50 (60%)
      üìä LSTM Regression Metrics:
         MSE: 0.321206
         RMSE: 0.566751
         R¬≤ Score: -0.6115 (Poor - 61.1% variance explained)
      üîπ SGHC: Training TCN (50 epochs)...
      ‚è≥ ATAI LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.190100
         RMSE: 0.436004
         R¬≤ Score: -0.9291 (Poor - 92.9% variance explained)
      üîπ HIMS: Training TCN (50 epochs)...
      ‚è≥ PGY LSTM: Epoch 20/50 (40%)
      ‚è≥ SGHC TCN: Epoch 10/50 (20%)
      ‚è≥ HIMS TCN: Epoch 10/50 (20%)
      ‚è≥ SGHC TCN: Epoch 20/50 (40%)
      ‚è≥ INOD LSTM: Epoch 10/50 (20%)
      ‚è≥ HIMS TCN: Epoch 20/50 (40%)
      ‚è≥ SGHC TCN: Epoch 30/50 (60%)
       ‚úÖ ASPI XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=271.7473 (Best Params: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200}) | Time: 140.8s
    - LSTM: MSE=0.2467
    - TCN: MSE=0.2540
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 145.4 seconds (2.4 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.2467
        ‚Ä¢ TCN: MSE=0.2540
        ‚Ä¢ LightGBM Regressor (CPU): MSE=200.2992
        ‚Ä¢ Random Forest: MSE=212.3672
        ‚Ä¢ XGBoost: MSE=271.7473
   ‚úÖ ASPI: Phase 3/3 - Model selection complete!
  üèÜ WINNER for ASPI (TargetReturn): LSTM with MSE=0.2467
üêõ DEBUG: ASPI - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for ASPI.
üêõ DEBUG: ASPI - Moving model to CPU before return...
üêõ DEBUG [22:22:16.624]: ASPI - Returning result metadata...
üêõ DEBUG: train_worker started for CRNC
üêõ DEBUG [22:22:16.626]: Main received result for ASPI
üêõ DEBUG [22:22:16.626]: Main received result for RCAT
üêõ DEBUG [22:22:16.626]: Main received result for ACHR
üêõ DEBUG: Training progress: 28/959 done
üêõ DEBUG [22:22:16.626]: Main received result for NVTS
üêõ DEBUG [22:22:16.626]: Main received result for KOD
       ‚úÖ ROOT LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=136.4446 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 1.1s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ ROOT XGBoost: Starting GridSearchCV fit...
  ‚öôÔ∏è Training models for CRNC (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-72 - CRNC: Initiating feature extraction for training.
  [DIAGNOSTIC] CRNC: fetch_training_data - Initial data rows: 205
   ‚Ü≥ CRNC: rows after features available: 126
üéØ CRNC: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] CRNC: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö CRNC: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ CRNC: Training LSTM (50 epochs)...
      ‚è≥ HIMS TCN: Epoch 30/50 (60%)
      ‚è≥ SGHC TCN: Epoch 40/50 (80%)
      ‚è≥ GRAL LSTM: Epoch 10/50 (20%)
      ‚è≥ HIMS TCN: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.553557
         RMSE: 0.744014
         R¬≤ Score: -0.9519 (Poor - 95.2% variance explained)
      üîπ ATAI: Training TCN (50 epochs)...
      ‚è≥ QURE LSTM: Epoch 40/50 (80%)
      ‚è≥ PGY LSTM: Epoch 30/50 (60%)
      ‚è≥ ZVIA LSTM: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.358857
         RMSE: 0.599047
         R¬≤ Score: -0.8003
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä SGHC: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ SGHC Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.179231
         RMSE: 0.423357
         R¬≤ Score: -0.8188
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä HIMS: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ HIMS Random Forest: Starting GridSearchCV fit...
      ‚è≥ ATAI TCN: Epoch 10/50 (20%)
      ‚è≥ ATAI TCN: Epoch 20/50 (40%)
      ‚è≥ INOD LSTM: Epoch 20/50 (40%)
       ‚úÖ BE Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=162.5681 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 4.4s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ BE LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ ATAI TCN: Epoch 30/50 (60%)
      ‚è≥ CRNC LSTM: Epoch 10/50 (20%)
      ‚è≥ ATAI TCN: Epoch 40/50 (80%)
      ‚è≥ GRAL LSTM: Epoch 20/50 (40%)
      üìä LSTM Regression Metrics:
         MSE: 0.075550
         RMSE: 0.274863
         R¬≤ Score: -0.8294 (Poor - 82.9% variance explained)
      üîπ ZVIA: Training TCN (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.092158
         RMSE: 0.303576
         R¬≤ Score: -1.2372 (Poor - 123.7% variance explained)
      üîπ QURE: Training TCN (50 epochs)...
      ‚è≥ PGY LSTM: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.646634
         RMSE: 0.804136
         R¬≤ Score: -1.2801
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä ATAI: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ ATAI Random Forest: Starting GridSearchCV fit...
      ‚è≥ QURE TCN: Epoch 10/50 (20%)
      ‚è≥ ZVIA TCN: Epoch 10/50 (20%)
      ‚è≥ QURE TCN: Epoch 20/50 (40%)
      ‚è≥ INOD LSTM: Epoch 30/50 (60%)
      ‚è≥ ZVIA TCN: Epoch 20/50 (40%)
      ‚è≥ QURE TCN: Epoch 30/50 (60%)
      ‚è≥ ZVIA TCN: Epoch 30/50 (60%)
      ‚è≥ CRNC LSTM: Epoch 20/50 (40%)
      ‚è≥ ZVIA TCN: Epoch 40/50 (80%)
      ‚è≥ QURE TCN: Epoch 40/50 (80%)
      ‚è≥ GRAL LSTM: Epoch 30/50 (60%)
      üìä LSTM Regression Metrics:
         MSE: 0.563557
         RMSE: 0.750704
         R¬≤ Score: -1.1642 (Poor - 116.4% variance explained)
      üîπ PGY: Training TCN (50 epochs)...
       ‚úÖ BE LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=245.8882 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 1.0s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ BE XGBoost: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.063600
         RMSE: 0.252190
         R¬≤ Score: -0.5400
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä ZVIA: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ ZVIA Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.059095
         RMSE: 0.243095
         R¬≤ Score: -0.4345
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä QURE: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ QURE Random Forest: Starting GridSearchCV fit...
      ‚è≥ PGY TCN: Epoch 10/50 (20%)
      ‚è≥ PGY TCN: Epoch 20/50 (40%)
      ‚è≥ INOD LSTM: Epoch 40/50 (80%)
      ‚è≥ PGY TCN: Epoch 30/50 (60%)
      ‚è≥ CRNC LSTM: Epoch 30/50 (60%)
      ‚è≥ PGY TCN: Epoch 40/50 (80%)
      ‚è≥ GRAL LSTM: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.587261
         RMSE: 0.766329
         R¬≤ Score: -1.2552
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä PGY: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ PGY Random Forest: Starting GridSearchCV fit...
       ‚úÖ SLDP Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=417.7357 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 4.3s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ SLDP LightGBM Regressor (CPU): Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 0.297306
         RMSE: 0.545257
         R¬≤ Score: -0.7178 (Poor - 71.8% variance explained)
      üîπ INOD: Training TCN (50 epochs)...
      ‚è≥ INOD TCN: Epoch 10/50 (20%)
      ‚è≥ CRNC LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.104298
         RMSE: 0.322952
         R¬≤ Score: -0.8407 (Poor - 84.1% variance explained)
      üîπ GRAL: Training TCN (50 epochs)...
      ‚è≥ INOD TCN: Epoch 20/50 (40%)
      ‚è≥ GRAL TCN: Epoch 10/50 (20%)
      ‚è≥ INOD TCN: Epoch 30/50 (60%)
      ‚è≥ GRAL TCN: Epoch 20/50 (40%)
      ‚è≥ INOD TCN: Epoch 40/50 (80%)
      ‚è≥ GRAL TCN: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.270916
         RMSE: 0.520496
         R¬≤ Score: -0.5653
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä INOD: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ INOD Random Forest: Starting GridSearchCV fit...
      ‚è≥ GRAL TCN: Epoch 40/50 (80%)
       ‚úÖ SLDP LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=507.0025 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 1.0s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ SLDP XGBoost: Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 0.033965
         RMSE: 0.184296
         R¬≤ Score: -1.5776 (Poor - 157.8% variance explained)
      üîπ CRNC: Training TCN (50 epochs)...
      üìä TCN Regression Metrics:
         MSE: 0.068152
         RMSE: 0.261060
         R¬≤ Score: -0.2028
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä GRAL: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ GRAL Random Forest: Starting GridSearchCV fit...
      ‚è≥ CRNC TCN: Epoch 10/50 (20%)
      ‚è≥ CRNC TCN: Epoch 20/50 (40%)
      ‚è≥ CRNC TCN: Epoch 30/50 (60%)
      ‚è≥ CRNC TCN: Epoch 40/50 (80%)
       ‚úÖ SGHC Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=117.3415 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ SGHC LightGBM Regressor (CPU): Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.019083
         RMSE: 0.138142
         R¬≤ Score: -0.4482
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä CRNC: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ CRNC Random Forest: Starting GridSearchCV fit...
       ‚úÖ HIMS Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=309.5122 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 4.0s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ HIMS LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ SGHC LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=129.0095 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ SGHC XGBoost: Starting GridSearchCV fit...
       ‚úÖ ATAI Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=249.3573 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.9s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ ATAI LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ HIMS LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=320.5228 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ HIMS XGBoost: Starting GridSearchCV fit...
       ‚úÖ QURE Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=139.6773 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ QURE LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ ZVIA Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=158.1405 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 4.0s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ ZVIA LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ ATAI LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=249.9630 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ ATAI XGBoost: Starting GridSearchCV fit...
       ‚úÖ PGY Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=895.8462 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ PGY LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ QURE LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=300.4418 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ QURE XGBoost: Starting GridSearchCV fit...
       ‚úÖ ZVIA LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=437.5204 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ ZVIA XGBoost: Starting GridSearchCV fit...
       ‚úÖ INOD Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=126.7237 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 3.4s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ INOD LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ PGY LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=753.2332 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ PGY XGBoost: Starting GridSearchCV fit...
       ‚úÖ GRAL Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=373.0307 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.4s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ GRAL LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ CRNC Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=350.5879 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.3s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ CRNC LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ INOD LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=144.0420 (Best Params: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ INOD XGBoost: Starting GridSearchCV fit...
       ‚úÖ GRAL LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=483.8855 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ GRAL XGBoost: Starting GridSearchCV fit...
       ‚úÖ CRNC LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=1121.1279 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ CRNC XGBoost: Starting GridSearchCV fit...
       ‚úÖ GRPN XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=265.7002 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 119.6s
    - LSTM: MSE=0.1657
    - TCN: MSE=0.1051
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 122.8 seconds (2.0 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1051
        ‚Ä¢ LSTM: MSE=0.1657
        ‚Ä¢ LightGBM Regressor (CPU): MSE=238.6251
        ‚Ä¢ Random Forest: MSE=258.8612
        ‚Ä¢ XGBoost: MSE=265.7002
   ‚úÖ GRPN: Phase 3/3 - Model selection complete!
  üèÜ WINNER for GRPN (TargetReturn): TCN with MSE=0.1051
üêõ DEBUG: GRPN - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for GRPN.
üêõ DEBUG: GRPN - Moving model to CPU before return...
üêõ DEBUG [22:23:55.143]: GRPN - Returning result metadata...
üêõ DEBUG: train_worker started for NNE
üêõ DEBUG [22:23:55.145]: Main received result for GRPN
  ‚öôÔ∏è Training models for NNE (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-62 - NNE: Initiating feature extraction for training.
  [DIAGNOSTIC] NNE: fetch_training_data - Initial data rows: 205
   ‚Ü≥ NNE: rows after features available: 126
üéØ NNE: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] NNE: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö NNE: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ NNE: Training LSTM (50 epochs)...
      ‚è≥ NNE LSTM: Epoch 10/50 (20%)
      ‚è≥ NNE LSTM: Epoch 20/50 (40%)
      ‚è≥ NNE LSTM: Epoch 30/50 (60%)
      ‚è≥ NNE LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.391682
         RMSE: 0.625845
         R¬≤ Score: -1.4771 (Poor - 147.7% variance explained)
      üîπ NNE: Training TCN (50 epochs)...
      ‚è≥ NNE TCN: Epoch 10/50 (20%)
      ‚è≥ NNE TCN: Epoch 20/50 (40%)
      ‚è≥ NNE TCN: Epoch 30/50 (60%)
      ‚è≥ NNE TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.269702
         RMSE: 0.519329
         R¬≤ Score: -0.7057
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä NNE: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ NNE Random Forest: Starting GridSearchCV fit...
       ‚úÖ NNE Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=184.3177 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 2.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ NNE LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ NNE LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=205.3232 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ NNE XGBoost: Starting GridSearchCV fit...
       ‚úÖ CLS XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=179.8892 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 118.2s
    - LSTM: MSE=0.6074
    - TCN: MSE=0.8699
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 121.8 seconds (2.0 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.6074
        ‚Ä¢ TCN: MSE=0.8699
        ‚Ä¢ LightGBM Regressor (CPU): MSE=134.1547
        ‚Ä¢ XGBoost: MSE=179.8892
        ‚Ä¢ Random Forest: MSE=251.8098
   ‚úÖ CLS: Phase 3/3 - Model selection complete!
  üèÜ WINNER for CLS (TargetReturn): LSTM with MSE=0.6074
üêõ DEBUG: CLS - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for CLS.
üêõ DEBUG: CLS - Moving model to CPU before return...
üêõ DEBUG [22:24:03.885]: CLS - Returning result metadata...
üêõ DEBUG [22:24:03.885]: Main received result for CLS
üêõ DEBUG: Training progress: 32/959 done
üêõ DEBUG: train_worker started for KOPN
  ‚öôÔ∏è Training models for KOPN (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-73 - KOPN: Initiating feature extraction for training.
  [DIAGNOSTIC] KOPN: fetch_training_data - Initial data rows: 205
   ‚Ü≥ KOPN: rows after features available: 126
üéØ KOPN: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] KOPN: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö KOPN: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ KOPN: Training LSTM (50 epochs)...
      ‚è≥ KOPN LSTM: Epoch 10/50 (20%)
      ‚è≥ KOPN LSTM: Epoch 20/50 (40%)
      ‚è≥ KOPN LSTM: Epoch 30/50 (60%)
      ‚è≥ KOPN LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.497386
         RMSE: 0.705256
         R¬≤ Score: -1.4027 (Poor - 140.3% variance explained)
      üîπ KOPN: Training TCN (50 epochs)...
      ‚è≥ KOPN TCN: Epoch 10/50 (20%)
      ‚è≥ KOPN TCN: Epoch 20/50 (40%)
      ‚è≥ KOPN TCN: Epoch 30/50 (60%)
      ‚è≥ KOPN TCN: Epoch 40/50 (80%)
       ‚úÖ CRDO XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=220.8067 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 120.8s
    - LSTM: MSE=0.5690
    - TCN: MSE=0.9298
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 124.5 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.5690
        ‚Ä¢ TCN: MSE=0.9298
        ‚Ä¢ LightGBM Regressor (CPU): MSE=165.5983
        ‚Ä¢ XGBoost: MSE=220.8067
        ‚Ä¢ Random Forest: MSE=258.4516
   ‚úÖ CRDO: Phase 3/3 - Model selection complete!
  üèÜ WINNER for CRDO (TargetReturn): LSTM with MSE=0.5690
üêõ DEBUG: CRDO - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for CRDO.
üêõ DEBUG: CRDO - Moving model to CPU before return...
üêõ DEBUG [22:24:07.133]: CRDO - Returning result metadata...
üêõ DEBUG [22:24:07.134]: Main received result for CRDO
üêõ DEBUG: train_worker started for CANG
  ‚öôÔ∏è Training models for CANG (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-68 - CANG: Initiating feature extraction for training.
  [DIAGNOSTIC] CANG: fetch_training_data - Initial data rows: 205
   ‚Ü≥ CANG: rows after features available: 126
üéØ CANG: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] CANG: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö CANG: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ CANG: Training LSTM (50 epochs)...
      üìä TCN Regression Metrics:
         MSE: 0.386662
         RMSE: 0.621822
         R¬≤ Score: -0.8678
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä KOPN: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ KOPN Random Forest: Starting GridSearchCV fit...
      ‚è≥ CANG LSTM: Epoch 10/50 (20%)
      ‚è≥ CANG LSTM: Epoch 20/50 (40%)
      ‚è≥ CANG LSTM: Epoch 30/50 (60%)
      ‚è≥ CANG LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.173052
         RMSE: 0.415996
         R¬≤ Score: -1.3114 (Poor - 131.1% variance explained)
      üîπ CANG: Training TCN (50 epochs)...
      ‚è≥ CANG TCN: Epoch 10/50 (20%)
      ‚è≥ CANG TCN: Epoch 20/50 (40%)
      ‚è≥ CANG TCN: Epoch 30/50 (60%)
      ‚è≥ CANG TCN: Epoch 40/50 (80%)
       ‚úÖ KOPN Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=240.6503 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 2.9s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ KOPN LightGBM Regressor (CPU): Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.122577
         RMSE: 0.350110
         R¬≤ Score: -0.6372
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä CANG: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ CANG Random Forest: Starting GridSearchCV fit...
       ‚úÖ KOPN LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=139.0153 (Best Params: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ KOPN XGBoost: Starting GridSearchCV fit...
       ‚úÖ CANG Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=105.0344 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 2.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ CANG LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ CANG LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=129.5871 (Best Params: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.6s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ CANG XGBoost: Starting GridSearchCV fit...
       ‚úÖ ROOT XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=121.5170 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 125.2s
    - LSTM: MSE=0.1368
    - TCN: MSE=0.0938
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 130.1 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0938
        ‚Ä¢ LSTM: MSE=0.1368
        ‚Ä¢ XGBoost: MSE=121.5170
        ‚Ä¢ Random Forest: MSE=128.6593
        ‚Ä¢ LightGBM Regressor (CPU): MSE=136.4446
   ‚úÖ ROOT: Phase 3/3 - Model selection complete!
  üèÜ WINNER for ROOT (TargetReturn): TCN with MSE=0.0938
üêõ DEBUG: ROOT - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for ROOT.
üêõ DEBUG: ROOT - Moving model to CPU before return...
üêõ DEBUG [22:24:21.863]: ROOT - Returning result metadata...
üêõ DEBUG [22:24:21.863]: Main received result for ROOT
üêõ DEBUG: train_worker started for APP
  ‚öôÔ∏è Training models for APP (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-65 - APP: Initiating feature extraction for training.
  [DIAGNOSTIC] APP: fetch_training_data - Initial data rows: 205
   ‚Ü≥ APP: rows after features available: 126
üéØ APP: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] APP: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö APP: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ APP: Training LSTM (50 epochs)...
      ‚è≥ APP LSTM: Epoch 10/50 (20%)
      ‚è≥ APP LSTM: Epoch 20/50 (40%)
      ‚è≥ APP LSTM: Epoch 30/50 (60%)
      ‚è≥ APP LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.200507
         RMSE: 0.447780
         R¬≤ Score: -0.6395 (Poor - 63.9% variance explained)
      üîπ APP: Training TCN (50 epochs)...
      ‚è≥ APP TCN: Epoch 10/50 (20%)
      ‚è≥ APP TCN: Epoch 20/50 (40%)
      ‚è≥ APP TCN: Epoch 30/50 (60%)
      ‚è≥ APP TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.174071
         RMSE: 0.417218
         R¬≤ Score: -0.4233
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä APP: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ APP Random Forest: Starting GridSearchCV fit...
       ‚úÖ SLDP XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=618.1293 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 127.0s
    - LSTM: MSE=0.5276
    - TCN: MSE=0.6005
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 132.4 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.5276
        ‚Ä¢ TCN: MSE=0.6005
        ‚Ä¢ Random Forest: MSE=417.7357
        ‚Ä¢ LightGBM Regressor (CPU): MSE=507.0025
        ‚Ä¢ XGBoost: MSE=618.1293
   ‚úÖ SLDP: Phase 3/3 - Model selection complete!
  üèÜ WINNER for SLDP (TargetReturn): LSTM with MSE=0.5276
üêõ DEBUG: SLDP - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for SLDP.
üêõ DEBUG: SLDP - Moving model to CPU before return...
üêõ DEBUG [22:24:27.251]: SLDP - Returning result metadata...
üêõ DEBUG: train_worker started for ONDS
  ‚öôÔ∏è Training models for ONDS (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-63 - ONDS: Initiating feature extraction for training.
  [DIAGNOSTIC] ONDS: fetch_training_data - Initial data rows: 205
   ‚Ü≥ ONDS: rows after features available: 126
üéØ ONDS: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] ONDS: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö ONDS: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ ONDS: Training LSTM (50 epochs)...
       ‚úÖ BE XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=154.7919 (Best Params: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200}) | Time: 128.9s
    - LSTM: MSE=0.1121
    - TCN: MSE=0.0777
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 134.4 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0777
        ‚Ä¢ LSTM: MSE=0.1121
        ‚Ä¢ XGBoost: MSE=154.7919
        ‚Ä¢ Random Forest: MSE=162.5681
        ‚Ä¢ LightGBM Regressor (CPU): MSE=245.8882
   ‚úÖ BE: Phase 3/3 - Model selection complete!
  üèÜ WINNER for BE (TargetReturn): TCN with MSE=0.0777
üêõ DEBUG: BE - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for BE.
üêõ DEBUG: BE - Moving model to CPU before return...
üêõ DEBUG [22:24:27.314]: BE - Returning result metadata...
üêõ DEBUG: train_worker started for SOFI
üêõ DEBUG [22:24:27.314]: Main received result for BE
üêõ DEBUG [22:24:27.315]: Main received result for SLDP
üêõ DEBUG: Training progress: 36/959 done
  ‚öôÔ∏è Training models for SOFI (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-75 - SOFI: Initiating feature extraction for training.
  [DIAGNOSTIC] SOFI: fetch_training_data - Initial data rows: 205
   ‚Ü≥ SOFI: rows after features available: 126
üéØ SOFI: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] SOFI: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö SOFI: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ SOFI: Training LSTM (50 epochs)...
       ‚úÖ APP Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=139.3172 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 2.7s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ APP LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ ONDS LSTM: Epoch 10/50 (20%)
      ‚è≥ SOFI LSTM: Epoch 10/50 (20%)
      ‚è≥ SOFI LSTM: Epoch 20/50 (40%)
      ‚è≥ ONDS LSTM: Epoch 20/50 (40%)
       ‚úÖ APP LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=137.4236 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ APP XGBoost: Starting GridSearchCV fit...
      ‚è≥ ONDS LSTM: Epoch 30/50 (60%)
      ‚è≥ SOFI LSTM: Epoch 30/50 (60%)
      ‚è≥ ONDS LSTM: Epoch 40/50 (80%)
      ‚è≥ SOFI LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.585222
         RMSE: 0.764998
         R¬≤ Score: -0.8342 (Poor - 83.4% variance explained)
      üîπ SOFI: Training TCN (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.793494
         RMSE: 0.890783
         R¬≤ Score: -0.9032 (Poor - 90.3% variance explained)
      üîπ ONDS: Training TCN (50 epochs)...
      ‚è≥ SOFI TCN: Epoch 10/50 (20%)
      ‚è≥ ONDS TCN: Epoch 10/50 (20%)
      ‚è≥ SOFI TCN: Epoch 20/50 (40%)
      ‚è≥ ONDS TCN: Epoch 20/50 (40%)
      ‚è≥ SOFI TCN: Epoch 30/50 (60%)
      ‚è≥ ONDS TCN: Epoch 30/50 (60%)
      ‚è≥ SOFI TCN: Epoch 40/50 (80%)
      ‚è≥ ONDS TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.483448
         RMSE: 0.695304
         R¬≤ Score: -0.5152
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä SOFI: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ SOFI Random Forest: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.582098
         RMSE: 0.762954
         R¬≤ Score: -0.3961
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä ONDS: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ ONDS Random Forest: Starting GridSearchCV fit...
       ‚úÖ SGHC XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=105.1179 (Best Params: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200}) | Time: 131.0s
    - LSTM: MSE=0.3212
    - TCN: MSE=0.3589
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 135.8 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.3212
        ‚Ä¢ TCN: MSE=0.3589
        ‚Ä¢ XGBoost: MSE=105.1179
        ‚Ä¢ Random Forest: MSE=117.3415
        ‚Ä¢ LightGBM Regressor (CPU): MSE=129.0095
   ‚úÖ SGHC: Phase 3/3 - Model selection complete!
  üèÜ WINNER for SGHC (TargetReturn): LSTM with MSE=0.3212
üêõ DEBUG: SGHC - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for SGHC.
üêõ DEBUG: SGHC - Moving model to CPU before return...
üêõ DEBUG [22:24:32.755]: SGHC - Returning result metadata...
üêõ DEBUG: train_worker started for AKBA
üêõ DEBUG [22:24:32.756]: Main received result for SGHC
  ‚öôÔ∏è Training models for AKBA (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-71 - AKBA: Initiating feature extraction for training.
  [DIAGNOSTIC] AKBA: fetch_training_data - Initial data rows: 205
   ‚Ü≥ AKBA: rows after features available: 126
üéØ AKBA: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] AKBA: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö AKBA: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ AKBA: Training LSTM (50 epochs)...
       ‚úÖ ONDS Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=544.1467 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 2.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ ONDS LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ SOFI Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=72.7626 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 2.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ SOFI LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ AKBA LSTM: Epoch 10/50 (20%)
       ‚úÖ ZVIA XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=181.5376 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}) | Time: 130.4s
    - LSTM: MSE=0.0755
    - TCN: MSE=0.0636
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 135.2 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0636
        ‚Ä¢ LSTM: MSE=0.0755
        ‚Ä¢ Random Forest: MSE=158.1405
        ‚Ä¢ XGBoost: MSE=181.5376
        ‚Ä¢ LightGBM Regressor (CPU): MSE=437.5204
   ‚úÖ ZVIA: Phase 3/3 - Model selection complete!
  üèÜ WINNER for ZVIA (TargetReturn): TCN with MSE=0.0636
üêõ DEBUG: ZVIA - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for ZVIA.
üêõ DEBUG: ZVIA - Moving model to CPU before return...
üêõ DEBUG [22:24:33.576]: ZVIA - Returning result metadata...
üêõ DEBUG: train_worker started for MPU
  ‚öôÔ∏è Training models for MPU (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-66 - MPU: Initiating feature extraction for training.
  [DIAGNOSTIC] MPU: fetch_training_data - Initial data rows: 205
   ‚Ü≥ MPU: rows after features available: 126
üéØ MPU: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] MPU: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö MPU: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ MPU: Training LSTM (50 epochs)...
      ‚è≥ AKBA LSTM: Epoch 20/50 (40%)
       ‚úÖ HIMS XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=422.3157 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 132.1s
    - LSTM: MSE=0.1901
    - TCN: MSE=0.1792
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 137.0 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1792
        ‚Ä¢ LSTM: MSE=0.1901
        ‚Ä¢ Random Forest: MSE=309.5122
        ‚Ä¢ LightGBM Regressor (CPU): MSE=320.5228
        ‚Ä¢ XGBoost: MSE=422.3157
   ‚úÖ HIMS: Phase 3/3 - Model selection complete!
  üèÜ WINNER for HIMS (TargetReturn): TCN with MSE=0.1792
üêõ DEBUG: HIMS - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for HIMS.
üêõ DEBUG: HIMS - Moving model to CPU before return...
üêõ DEBUG [22:24:34.061]: HIMS - Returning result metadata...
üêõ DEBUG: train_worker started for RBRK
üêõ DEBUG [22:24:34.062]: Main received result for HIMS
       ‚úÖ ONDS LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=363.2798 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ ONDS XGBoost: Starting GridSearchCV fit...
  ‚öôÔ∏è Training models for RBRK (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-64 - RBRK: Initiating feature extraction for training.
  [DIAGNOSTIC] RBRK: fetch_training_data - Initial data rows: 205
   ‚Ü≥ RBRK: rows after features available: 126
üéØ RBRK: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] RBRK: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö RBRK: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ RBRK: Training LSTM (50 epochs)...
      ‚è≥ MPU LSTM: Epoch 10/50 (20%)
       ‚úÖ ATAI XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=299.6049 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 131.8s
    - LSTM: MSE=0.5536
    - TCN: MSE=0.6466
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 136.6 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.5536
        ‚Ä¢ TCN: MSE=0.6466
        ‚Ä¢ Random Forest: MSE=249.3573
        ‚Ä¢ LightGBM Regressor (CPU): MSE=249.9630
        ‚Ä¢ XGBoost: MSE=299.6049
   ‚úÖ ATAI: Phase 3/3 - Model selection complete!
  üèÜ WINNER for ATAI (TargetReturn): LSTM with MSE=0.5536
üêõ DEBUG: ATAI - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for ATAI.
üêõ DEBUG: ATAI - Moving model to CPU before return...
üêõ DEBUG [22:24:34.332]: ATAI - Returning result metadata...
üêõ DEBUG: train_worker started for ALLT
üêõ DEBUG [22:24:34.333]: Main received result for ATAI
  ‚öôÔ∏è Training models for ALLT (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-70 - ALLT: Initiating feature extraction for training.
  [DIAGNOSTIC] ALLT: fetch_training_data - Initial data rows: 205
   ‚Ü≥ ALLT: rows after features available: 126
üéØ ALLT: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] ALLT: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö ALLT: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ ALLT: Training LSTM (50 epochs)...
       ‚úÖ SOFI LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=81.0129 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 1.1s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ SOFI XGBoost: Starting GridSearchCV fit...
      ‚è≥ AKBA LSTM: Epoch 30/50 (60%)
      ‚è≥ RBRK LSTM: Epoch 10/50 (20%)
      ‚è≥ MPU LSTM: Epoch 20/50 (40%)
       ‚úÖ PGY XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=1002.9628 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 131.2s
    - LSTM: MSE=0.5636
    - TCN: MSE=0.5873
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 135.7 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.5636
        ‚Ä¢ TCN: MSE=0.5873
        ‚Ä¢ LightGBM Regressor (CPU): MSE=753.2332
        ‚Ä¢ Random Forest: MSE=895.8462
        ‚Ä¢ XGBoost: MSE=1002.9628
   ‚úÖ PGY: Phase 3/3 - Model selection complete!
  üèÜ WINNER for PGY (TargetReturn): LSTM with MSE=0.5636
üêõ DEBUG: PGY - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for PGY.
üêõ DEBUG: PGY - Moving model to CPU before return...
üêõ DEBUG [22:24:34.837]: PGY - Returning result metadata...
üêõ DEBUG: train_worker started for ORLA
  ‚öôÔ∏è Training models for ORLA (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-61 - ORLA: Initiating feature extraction for training.
  [DIAGNOSTIC] ORLA: fetch_training_data - Initial data rows: 205
   ‚Ü≥ ORLA: rows after features available: 126
üéØ ORLA: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] ORLA: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö ORLA: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ ORLA: Training LSTM (50 epochs)...
      ‚è≥ ALLT LSTM: Epoch 10/50 (20%)
       ‚úÖ GRAL XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=404.2139 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}) | Time: 130.6s
    - LSTM: MSE=0.1043
    - TCN: MSE=0.0682
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 134.8 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0682
        ‚Ä¢ LSTM: MSE=0.1043
        ‚Ä¢ Random Forest: MSE=373.0307
        ‚Ä¢ XGBoost: MSE=404.2139
        ‚Ä¢ LightGBM Regressor (CPU): MSE=483.8855
   ‚úÖ GRAL: Phase 3/3 - Model selection complete!
  üèÜ WINNER for GRAL (TargetReturn): TCN with MSE=0.0682
üêõ DEBUG: GRAL - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for GRAL.
üêõ DEBUG: GRAL - Moving model to CPU before return...
üêõ DEBUG [22:24:35.189]: GRAL - Returning result metadata...
üêõ DEBUG: train_worker started for LX
      ‚è≥ AKBA LSTM: Epoch 40/50 (80%)
  ‚öôÔ∏è Training models for LX (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-69 - LX: Initiating feature extraction for training.
  [DIAGNOSTIC] LX: fetch_training_data - Initial data rows: 205
   ‚Ü≥ LX: rows after features available: 126
üéØ LX: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] LX: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö LX: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ LX: Training LSTM (50 epochs)...
      ‚è≥ RBRK LSTM: Epoch 20/50 (40%)
      ‚è≥ MPU LSTM: Epoch 30/50 (60%)
      ‚è≥ ALLT LSTM: Epoch 20/50 (40%)
      ‚è≥ ORLA LSTM: Epoch 10/50 (20%)
      ‚è≥ RBRK LSTM: Epoch 30/50 (60%)
       ‚úÖ QURE XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=101.4229 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 132.8s
    - LSTM: MSE=0.0922
    - TCN: MSE=0.0591
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 137.4 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0591
        ‚Ä¢ LSTM: MSE=0.0922
        ‚Ä¢ XGBoost: MSE=101.4229
        ‚Ä¢ Random Forest: MSE=139.6773
        ‚Ä¢ LightGBM Regressor (CPU): MSE=300.4418
   ‚úÖ QURE: Phase 3/3 - Model selection complete!
  üèÜ WINNER for QURE (TargetReturn): TCN with MSE=0.0591
üêõ DEBUG: QURE - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for QURE.
üêõ DEBUG: QURE - Moving model to CPU before return...
üêõ DEBUG [22:24:35.895]: QURE - Returning result metadata...
üêõ DEBUG: train_worker started for SEI
üêõ DEBUG [22:24:35.896]: Main received result for QURE
üêõ DEBUG: Training progress: 40/959 done
üêõ DEBUG [22:24:35.896]: Main received result for ZVIA
üêõ DEBUG [22:24:35.896]: Main received result for PGY
      ‚è≥ LX LSTM: Epoch 10/50 (20%)
  ‚öôÔ∏è Training models for SEI (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-74 - SEI: Initiating feature extraction for training.
  [DIAGNOSTIC] SEI: fetch_training_data - Initial data rows: 205
   ‚Ü≥ SEI: rows after features available: 126
üéØ SEI: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
      ‚è≥ MPU LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.323245
         RMSE: 0.568546
         R¬≤ Score: -0.6530 (Poor - 65.3% variance explained)
      üîπ AKBA: Training TCN (50 epochs)...
  [DIAGNOSTIC] SEI: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö SEI: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ SEI: Training LSTM (50 epochs)...
       ‚úÖ CRNC XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=1305.4981 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}) | Time: 130.9s
    - LSTM: MSE=0.0340
    - TCN: MSE=0.0191
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 135.1 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0191
        ‚Ä¢ LSTM: MSE=0.0340
        ‚Ä¢ Random Forest: MSE=350.5879
        ‚Ä¢ LightGBM Regressor (CPU): MSE=1121.1279
        ‚Ä¢ XGBoost: MSE=1305.4981
   ‚úÖ CRNC: Phase 3/3 - Model selection complete!
  üèÜ WINNER for CRNC (TargetReturn): TCN with MSE=0.0191
üêõ DEBUG: CRNC - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for CRNC.
üêõ DEBUG: CRNC - Moving model to CPU before return...
üêõ DEBUG [22:24:35.993]: CRNC - Returning result metadata...
üêõ DEBUG: train_worker started for ETON
  ‚öôÔ∏è Training models for ETON (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-72 - ETON: Initiating feature extraction for training.
  [DIAGNOSTIC] ETON: fetch_training_data - Initial data rows: 205
   ‚Ü≥ ETON: rows after features available: 126
üéØ ETON: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] ETON: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö ETON: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ ETON: Training LSTM (50 epochs)...
      ‚è≥ AKBA TCN: Epoch 10/50 (20%)
      ‚è≥ ALLT LSTM: Epoch 30/50 (60%)
      ‚è≥ ORLA LSTM: Epoch 20/50 (40%)
      ‚è≥ AKBA TCN: Epoch 20/50 (40%)
      ‚è≥ AKBA TCN: Epoch 30/50 (60%)
      ‚è≥ RBRK LSTM: Epoch 40/50 (80%)
      ‚è≥ AKBA TCN: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.407770
         RMSE: 0.638569
         R¬≤ Score: -1.1218 (Poor - 112.2% variance explained)
      üîπ MPU: Training TCN (50 epochs)...
      ‚è≥ LX LSTM: Epoch 20/50 (40%)
      ‚è≥ SEI LSTM: Epoch 10/50 (20%)
      üìä TCN Regression Metrics:
         MSE: 0.313898
         RMSE: 0.560266
         R¬≤ Score: -0.6052
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä AKBA: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ AKBA Random Forest: Starting GridSearchCV fit...
      ‚è≥ MPU TCN: Epoch 10/50 (20%)
      ‚è≥ ETON LSTM: Epoch 10/50 (20%)
      ‚è≥ ORLA LSTM: Epoch 30/50 (60%)
      ‚è≥ ALLT LSTM: Epoch 40/50 (80%)
      ‚è≥ MPU TCN: Epoch 20/50 (40%)
      ‚è≥ MPU TCN: Epoch 30/50 (60%)
      ‚è≥ MPU TCN: Epoch 40/50 (80%)
      ‚è≥ LX LSTM: Epoch 30/50 (60%)
      üìä LSTM Regression Metrics:
         MSE: 0.373461
         RMSE: 0.611115
         R¬≤ Score: -0.9987 (Poor - 99.9% variance explained)
      üîπ RBRK: Training TCN (50 epochs)...
      ‚è≥ SEI LSTM: Epoch 20/50 (40%)
      üìä TCN Regression Metrics:
         MSE: 0.305081
         RMSE: 0.552341
         R¬≤ Score: -0.5875
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä MPU: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ MPU Random Forest: Starting GridSearchCV fit...
      ‚è≥ ETON LSTM: Epoch 20/50 (40%)
      ‚è≥ RBRK TCN: Epoch 10/50 (20%)
      üìä LSTM Regression Metrics:
         MSE: 0.269273
         RMSE: 0.518915
         R¬≤ Score: -0.8188 (Poor - 81.9% variance explained)
      üîπ ALLT: Training TCN (50 epochs)...
      ‚è≥ ORLA LSTM: Epoch 40/50 (80%)
      ‚è≥ RBRK TCN: Epoch 20/50 (40%)
      ‚è≥ ALLT TCN: Epoch 10/50 (20%)
      ‚è≥ RBRK TCN: Epoch 30/50 (60%)
      ‚è≥ ALLT TCN: Epoch 20/50 (40%)
      ‚è≥ RBRK TCN: Epoch 40/50 (80%)
      ‚è≥ ALLT TCN: Epoch 30/50 (60%)
      ‚è≥ LX LSTM: Epoch 40/50 (80%)
       ‚úÖ INOD XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=128.6075 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 133.9s
    - LSTM: MSE=0.2973
    - TCN: MSE=0.2709
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 138.0 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.2709
        ‚Ä¢ LSTM: MSE=0.2973
        ‚Ä¢ Random Forest: MSE=126.7237
        ‚Ä¢ XGBoost: MSE=128.6075
        ‚Ä¢ LightGBM Regressor (CPU): MSE=144.0420
   ‚úÖ INOD: Phase 3/3 - Model selection complete!
  üèÜ WINNER for INOD (TargetReturn): TCN with MSE=0.2709
üêõ DEBUG: INOD - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for INOD.
üêõ DEBUG: INOD - Moving model to CPU before return...
üêõ DEBUG [22:24:38.134]: INOD - Returning result metadata...
üêõ DEBUG [22:24:38.134]: Main received result for INOD
üêõ DEBUG [22:24:38.134]: Main received result for GRAL
üêõ DEBUG: Training progress: 44/959 done
üêõ DEBUG [22:24:38.134]: Main received result for CRNC
üêõ DEBUG: train_worker started for KTOS
      ‚è≥ SEI LSTM: Epoch 30/50 (60%)
      ‚è≥ ALLT TCN: Epoch 40/50 (80%)
  ‚öôÔ∏è Training models for KTOS (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-67 - KTOS: Initiating feature extraction for training.
  [DIAGNOSTIC] KTOS: fetch_training_data - Initial data rows: 205
   ‚Ü≥ KTOS: rows after features available: 126
üéØ KTOS: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
      üìä TCN Regression Metrics:
         MSE: 0.255725
         RMSE: 0.505692
         R¬≤ Score: -0.3686
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä RBRK: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ RBRK Random Forest: Starting GridSearchCV fit...
  [DIAGNOSTIC] KTOS: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö KTOS: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ KTOS: Training LSTM (50 epochs)...
      ‚è≥ ETON LSTM: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.258017
         RMSE: 0.507954
         R¬≤ Score: -0.7428
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä ALLT: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ ALLT Random Forest: Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 0.405910
         RMSE: 0.637111
         R¬≤ Score: -0.7824 (Poor - 78.2% variance explained)
      üîπ ORLA: Training TCN (50 epochs)...
      ‚è≥ ORLA TCN: Epoch 10/50 (20%)
      ‚è≥ ORLA TCN: Epoch 20/50 (40%)
      ‚è≥ ORLA TCN: Epoch 30/50 (60%)
      üìä LSTM Regression Metrics:
         MSE: 0.063387
         RMSE: 0.251769
         R¬≤ Score: -2.5568 (Poor - 255.7% variance explained)
      üîπ LX: Training TCN (50 epochs)...
      ‚è≥ SEI LSTM: Epoch 40/50 (80%)
      ‚è≥ ETON LSTM: Epoch 40/50 (80%)
      ‚è≥ ORLA TCN: Epoch 40/50 (80%)
      ‚è≥ KTOS LSTM: Epoch 10/50 (20%)
      ‚è≥ LX TCN: Epoch 10/50 (20%)
      üìä TCN Regression Metrics:
         MSE: 0.386755
         RMSE: 0.621896
         R¬≤ Score: -0.6983
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä ORLA: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ ORLA Random Forest: Starting GridSearchCV fit...
      ‚è≥ LX TCN: Epoch 20/50 (40%)
      ‚è≥ LX TCN: Epoch 30/50 (60%)
      ‚è≥ LX TCN: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.118856
         RMSE: 0.344754
         R¬≤ Score: -1.1654 (Poor - 116.5% variance explained)
      üîπ ETON: Training TCN (50 epochs)...
      üìä TCN Regression Metrics:
         MSE: 0.017276
         RMSE: 0.131440
         R¬≤ Score: 0.0306
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä LX: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ LX Random Forest: Starting GridSearchCV fit...
      ‚è≥ KTOS LSTM: Epoch 20/50 (40%)
      ‚è≥ ETON TCN: Epoch 10/50 (20%)
      üìä LSTM Regression Metrics:
         MSE: 0.259320
         RMSE: 0.509235
         R¬≤ Score: -0.9500 (Poor - 95.0% variance explained)
      üîπ SEI: Training TCN (50 epochs)...
      ‚è≥ ETON TCN: Epoch 20/50 (40%)
      ‚è≥ SEI TCN: Epoch 10/50 (20%)
      ‚è≥ ETON TCN: Epoch 30/50 (60%)
      ‚è≥ SEI TCN: Epoch 20/50 (40%)
      ‚è≥ ETON TCN: Epoch 40/50 (80%)
      ‚è≥ SEI TCN: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.054694
         RMSE: 0.233868
         R¬≤ Score: 0.0035
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä ETON: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ ETON Random Forest: Starting GridSearchCV fit...
      ‚è≥ SEI TCN: Epoch 40/50 (80%)
      ‚è≥ KTOS LSTM: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.191002
         RMSE: 0.437037
         R¬≤ Score: -0.4363
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä SEI: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ SEI Random Forest: Starting GridSearchCV fit...
       ‚úÖ AKBA Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=185.8752 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 3.9s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ AKBA LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ KTOS LSTM: Epoch 40/50 (80%)
       ‚úÖ AKBA LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=234.6810 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 1.0s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ AKBA XGBoost: Starting GridSearchCV fit...
       ‚úÖ MPU Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=194.7452 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 4.3s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ MPU LightGBM Regressor (CPU): Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 0.499188
         RMSE: 0.706532
         R¬≤ Score: -1.2155 (Poor - 121.6% variance explained)
      üîπ KTOS: Training TCN (50 epochs)...
      ‚è≥ KTOS TCN: Epoch 10/50 (20%)
       ‚úÖ RBRK Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=51.6070 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ RBRK LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ KTOS TCN: Epoch 20/50 (40%)
      ‚è≥ KTOS TCN: Epoch 30/50 (60%)
       ‚úÖ ALLT Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=84.8721 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 4.0s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ ALLT LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ KTOS TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.395916
         RMSE: 0.629219
         R¬≤ Score: -0.7572
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä KTOS: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ KTOS Random Forest: Starting GridSearchCV fit...
       ‚úÖ MPU LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=483.3389 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ MPU XGBoost: Starting GridSearchCV fit...
       ‚úÖ ORLA Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=78.6007 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ ORLA LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ RBRK LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=55.6822 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ RBRK XGBoost: Starting GridSearchCV fit...
       ‚úÖ ALLT LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=107.7470 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ ALLT XGBoost: Starting GridSearchCV fit...
       ‚úÖ LX Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=105.7017 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 4.0s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ LX LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ ORLA LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=74.0505 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ ORLA XGBoost: Starting GridSearchCV fit...
       ‚úÖ ETON Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=42.0282 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 3.6s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ ETON LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ SEI Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=137.5024 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ SEI LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ LX LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=132.7167 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ LX XGBoost: Starting GridSearchCV fit...
       ‚úÖ ETON LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=69.9160 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ ETON XGBoost: Starting GridSearchCV fit...
       ‚úÖ SEI LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=137.9801 (Best Params: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ SEI XGBoost: Starting GridSearchCV fit...
       ‚úÖ KTOS Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=52.4171 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 3.2s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ KTOS LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ KTOS LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=45.1987 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ KTOS XGBoost: Starting GridSearchCV fit...
       ‚úÖ NNE XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=190.0298 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}) | Time: 121.8s
    - LSTM: MSE=0.3917
    - TCN: MSE=0.2697
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 125.3 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.2697
        ‚Ä¢ LSTM: MSE=0.3917
        ‚Ä¢ Random Forest: MSE=184.3177
        ‚Ä¢ XGBoost: MSE=190.0298
        ‚Ä¢ LightGBM Regressor (CPU): MSE=205.3232
   ‚úÖ NNE: Phase 3/3 - Model selection complete!
  üèÜ WINNER for NNE (TargetReturn): TCN with MSE=0.2697
üêõ DEBUG: NNE - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for NNE.
üêõ DEBUG: NNE - Moving model to CPU before return...
üêõ DEBUG [22:26:03.374]: NNE - Returning result metadata...
üêõ DEBUG [22:26:03.374]: Main received result for NNE
üêõ DEBUG: train_worker started for NAGE
  ‚öôÔ∏è Training models for NAGE (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-62 - NAGE: Initiating feature extraction for training.
  [DIAGNOSTIC] NAGE: fetch_training_data - Initial data rows: 205
   ‚Ü≥ NAGE: rows after features available: 126
üéØ NAGE: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] NAGE: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö NAGE: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ NAGE: Training LSTM (50 epochs)...
      ‚è≥ NAGE LSTM: Epoch 10/50 (20%)
      ‚è≥ NAGE LSTM: Epoch 20/50 (40%)
      ‚è≥ NAGE LSTM: Epoch 30/50 (60%)
      ‚è≥ NAGE LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.251943
         RMSE: 0.501939
         R¬≤ Score: -1.0427 (Poor - 104.3% variance explained)
      üîπ NAGE: Training TCN (50 epochs)...
      ‚è≥ NAGE TCN: Epoch 10/50 (20%)
      ‚è≥ NAGE TCN: Epoch 20/50 (40%)
      ‚è≥ NAGE TCN: Epoch 30/50 (60%)
      ‚è≥ NAGE TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.127022
         RMSE: 0.356401
         R¬≤ Score: -0.0298
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä NAGE: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ NAGE Random Forest: Starting GridSearchCV fit...
       ‚úÖ NAGE Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=185.9476 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 2.7s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ NAGE LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ NAGE LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=132.1669 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.6s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ NAGE XGBoost: Starting GridSearchCV fit...
       ‚úÖ KOPN XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=164.2276 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 123.3s
    - LSTM: MSE=0.4974
    - TCN: MSE=0.3867
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 126.9 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.3867
        ‚Ä¢ LSTM: MSE=0.4974
        ‚Ä¢ LightGBM Regressor (CPU): MSE=139.0153
        ‚Ä¢ XGBoost: MSE=164.2276
        ‚Ä¢ Random Forest: MSE=240.6503
   ‚úÖ KOPN: Phase 3/3 - Model selection complete!
  üèÜ WINNER for KOPN (TargetReturn): TCN with MSE=0.3867
üêõ DEBUG: KOPN - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for KOPN.
üêõ DEBUG: KOPN - Moving model to CPU before return...
üêõ DEBUG [22:26:14.152]: KOPN - Returning result metadata...
üêõ DEBUG: train_worker started for QMCO
üêõ DEBUG [22:26:14.153]: Main received result for KOPN
  ‚öôÔ∏è Training models for QMCO (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-73 - QMCO: Initiating feature extraction for training.
  [DIAGNOSTIC] QMCO: fetch_training_data - Initial data rows: 205
   ‚Ü≥ QMCO: rows after features available: 126
üéØ QMCO: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] QMCO: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö QMCO: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ QMCO: Training LSTM (50 epochs)...
      ‚è≥ QMCO LSTM: Epoch 10/50 (20%)
      ‚è≥ QMCO LSTM: Epoch 20/50 (40%)
       ‚úÖ CANG XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=115.3653 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}) | Time: 121.9s
    - LSTM: MSE=0.1731
    - TCN: MSE=0.1226
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 125.3 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1226
        ‚Ä¢ LSTM: MSE=0.1731
        ‚Ä¢ Random Forest: MSE=105.0344
        ‚Ä¢ XGBoost: MSE=115.3653
        ‚Ä¢ LightGBM Regressor (CPU): MSE=129.5871
   ‚úÖ CANG: Phase 3/3 - Model selection complete!
  üèÜ WINNER for CANG (TargetReturn): TCN with MSE=0.1226
üêõ DEBUG: CANG - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for CANG.
üêõ DEBUG: CANG - Moving model to CPU before return...
üêõ DEBUG [22:26:15.500]: CANG - Returning result metadata...
üêõ DEBUG: train_worker started for GEV
üêõ DEBUG [22:26:15.501]: Main received result for CANG
üêõ DEBUG: Training progress: 48/959 done
  ‚öôÔ∏è Training models for GEV (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-68 - GEV: Initiating feature extraction for training.
  [DIAGNOSTIC] GEV: fetch_training_data - Initial data rows: 205
   ‚Ü≥ GEV: rows after features available: 126
üéØ GEV: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] GEV: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö GEV: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ GEV: Training LSTM (50 epochs)...
      ‚è≥ QMCO LSTM: Epoch 30/50 (60%)
      ‚è≥ GEV LSTM: Epoch 10/50 (20%)
      ‚è≥ QMCO LSTM: Epoch 40/50 (80%)
      ‚è≥ GEV LSTM: Epoch 20/50 (40%)
      üìä LSTM Regression Metrics:
         MSE: 0.012893
         RMSE: 0.113548
         R¬≤ Score: -2.2486 (Poor - 224.9% variance explained)
      üîπ QMCO: Training TCN (50 epochs)...
      ‚è≥ QMCO TCN: Epoch 10/50 (20%)
      ‚è≥ QMCO TCN: Epoch 20/50 (40%)
      ‚è≥ GEV LSTM: Epoch 30/50 (60%)
      ‚è≥ QMCO TCN: Epoch 30/50 (60%)
      ‚è≥ QMCO TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.004507
         RMSE: 0.067135
         R¬≤ Score: -0.1356
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä QMCO: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ QMCO Random Forest: Starting GridSearchCV fit...
      ‚è≥ GEV LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.352167
         RMSE: 0.593436
         R¬≤ Score: -0.4986 (Poor - 49.9% variance explained)
      üîπ GEV: Training TCN (50 epochs)...
      ‚è≥ GEV TCN: Epoch 10/50 (20%)
      ‚è≥ GEV TCN: Epoch 20/50 (40%)
      ‚è≥ GEV TCN: Epoch 30/50 (60%)
      ‚è≥ GEV TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.326399
         RMSE: 0.571314
         R¬≤ Score: -0.3890
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä GEV: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ GEV Random Forest: Starting GridSearchCV fit...
       ‚úÖ QMCO Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=707.4518 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 2.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ QMCO LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ QMCO LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=2205.7179 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ QMCO XGBoost: Starting GridSearchCV fit...
       ‚úÖ GEV Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=91.1056 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.0s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ GEV LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ GEV LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=75.2107 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.6s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ GEV XGBoost: Starting GridSearchCV fit...
       ‚úÖ APP XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=158.8256 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 125.8s
    - LSTM: MSE=0.2005
    - TCN: MSE=0.1741
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 129.3 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1741
        ‚Ä¢ LSTM: MSE=0.2005
        ‚Ä¢ LightGBM Regressor (CPU): MSE=137.4236
        ‚Ä¢ Random Forest: MSE=139.3172
        ‚Ä¢ XGBoost: MSE=158.8256
   ‚úÖ APP: Phase 3/3 - Model selection complete!
  üèÜ WINNER for APP (TargetReturn): TCN with MSE=0.1741
üêõ DEBUG: APP - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for APP.
üêõ DEBUG: APP - Moving model to CPU before return...
üêõ DEBUG [22:26:34.210]: APP - Returning result metadata...
üêõ DEBUG: train_worker started for AMLX
üêõ DEBUG [22:26:34.215]: Main received result for APP
  ‚öôÔ∏è Training models for AMLX (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-65 - AMLX: Initiating feature extraction for training.
  [DIAGNOSTIC] AMLX: fetch_training_data - Initial data rows: 205
   ‚Ü≥ AMLX: rows after features available: 126
üéØ AMLX: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] AMLX: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö AMLX: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ AMLX: Training LSTM (50 epochs)...
      ‚è≥ AMLX LSTM: Epoch 10/50 (20%)
      ‚è≥ AMLX LSTM: Epoch 20/50 (40%)
      ‚è≥ AMLX LSTM: Epoch 30/50 (60%)
      ‚è≥ AMLX LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.229792
         RMSE: 0.479367
         R¬≤ Score: -1.4121 (Poor - 141.2% variance explained)
      üîπ AMLX: Training TCN (50 epochs)...
      ‚è≥ AMLX TCN: Epoch 10/50 (20%)
       ‚úÖ ONDS XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=726.0720 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 122.6s
    - LSTM: MSE=0.7935
    - TCN: MSE=0.5821
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 126.2 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.5821
        ‚Ä¢ LSTM: MSE=0.7935
        ‚Ä¢ LightGBM Regressor (CPU): MSE=363.2798
        ‚Ä¢ Random Forest: MSE=544.1467
        ‚Ä¢ XGBoost: MSE=726.0720
   ‚úÖ ONDS: Phase 3/3 - Model selection complete!
  üèÜ WINNER for ONDS (TargetReturn): TCN with MSE=0.5821
üêõ DEBUG: ONDS - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for ONDS.
üêõ DEBUG: ONDS - Moving model to CPU before return...
üêõ DEBUG [22:26:36.684]: ONDS - Returning result metadata...
üêõ DEBUG: train_worker started for SOUN
üêõ DEBUG [22:26:36.684]: Main received result for ONDS
      ‚è≥ AMLX TCN: Epoch 20/50 (40%)
  ‚öôÔ∏è Training models for SOUN (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-63 - SOUN: Initiating feature extraction for training.
  [DIAGNOSTIC] SOUN: fetch_training_data - Initial data rows: 205
   ‚Ü≥ SOUN: rows after features available: 126
üéØ SOUN: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] SOUN: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö SOUN: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ SOUN: Training LSTM (50 epochs)...
      ‚è≥ AMLX TCN: Epoch 30/50 (60%)
      ‚è≥ AMLX TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.104577
         RMSE: 0.323384
         R¬≤ Score: -0.0977
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä AMLX: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ AMLX Random Forest: Starting GridSearchCV fit...
      ‚è≥ SOUN LSTM: Epoch 10/50 (20%)
      ‚è≥ SOUN LSTM: Epoch 20/50 (40%)
      ‚è≥ SOUN LSTM: Epoch 30/50 (60%)
      ‚è≥ SOUN LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.086507
         RMSE: 0.294121
         R¬≤ Score: -0.7925 (Poor - 79.3% variance explained)
      üîπ SOUN: Training TCN (50 epochs)...
      ‚è≥ SOUN TCN: Epoch 10/50 (20%)
       ‚úÖ SOFI XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=74.5335 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 125.1s
    - LSTM: MSE=0.5852
    - TCN: MSE=0.4834
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 129.0 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.4834
        ‚Ä¢ LSTM: MSE=0.5852
        ‚Ä¢ Random Forest: MSE=72.7626
        ‚Ä¢ XGBoost: MSE=74.5335
        ‚Ä¢ LightGBM Regressor (CPU): MSE=81.0129
   ‚úÖ SOFI: Phase 3/3 - Model selection complete!
  üèÜ WINNER for SOFI (TargetReturn): TCN with MSE=0.4834
üêõ DEBUG: SOFI - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for SOFI.
üêõ DEBUG: SOFI - Moving model to CPU before return...
üêõ DEBUG [22:26:39.516]: SOFI - Returning result metadata...
üêõ DEBUG [22:26:39.517]: Main received result for SOFI
üêõ DEBUG: train_worker started for TTMI
      ‚è≥ SOUN TCN: Epoch 20/50 (40%)
  ‚öôÔ∏è Training models for TTMI (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-75 - TTMI: Initiating feature extraction for training.
  [DIAGNOSTIC] TTMI: fetch_training_data - Initial data rows: 205
   ‚Ü≥ TTMI: rows after features available: 126
üéØ TTMI: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] TTMI: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö TTMI: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ TTMI: Training LSTM (50 epochs)...
      ‚è≥ SOUN TCN: Epoch 30/50 (60%)
      ‚è≥ SOUN TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.056017
         RMSE: 0.236680
         R¬≤ Score: -0.1607
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä SOUN: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ SOUN Random Forest: Starting GridSearchCV fit...
      ‚è≥ TTMI LSTM: Epoch 10/50 (20%)
       ‚úÖ AMLX Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=258.2212 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.3s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ AMLX LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ TTMI LSTM: Epoch 20/50 (40%)
      ‚è≥ TTMI LSTM: Epoch 30/50 (60%)
       ‚úÖ AMLX LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=223.6297 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ AMLX XGBoost: Starting GridSearchCV fit...
      ‚è≥ TTMI LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.558867
         RMSE: 0.747574
         R¬≤ Score: -0.5419 (Poor - 54.2% variance explained)
      üîπ TTMI: Training TCN (50 epochs)...
      ‚è≥ TTMI TCN: Epoch 10/50 (20%)
      ‚è≥ TTMI TCN: Epoch 20/50 (40%)
      ‚è≥ TTMI TCN: Epoch 30/50 (60%)
      ‚è≥ TTMI TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.561191
         RMSE: 0.749127
         R¬≤ Score: -0.5483
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä TTMI: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ TTMI Random Forest: Starting GridSearchCV fit...
       ‚úÖ SOUN Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=171.7725 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.0s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ SOUN LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ SOUN LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=361.3210 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ SOUN XGBoost: Starting GridSearchCV fit...
       ‚úÖ TTMI Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=43.4548 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 2.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ TTMI LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ TTMI LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=59.0920 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.6s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ TTMI XGBoost: Starting GridSearchCV fit...
       ‚úÖ AKBA XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=215.4598 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 128.2s
    - LSTM: MSE=0.3232
    - TCN: MSE=0.3139
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 133.1 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.3139
        ‚Ä¢ LSTM: MSE=0.3232
        ‚Ä¢ Random Forest: MSE=185.8752
        ‚Ä¢ XGBoost: MSE=215.4598
        ‚Ä¢ LightGBM Regressor (CPU): MSE=234.6810
   ‚úÖ AKBA: Phase 3/3 - Model selection complete!
  üèÜ WINNER for AKBA (TargetReturn): TCN with MSE=0.3139
üêõ DEBUG: AKBA - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for AKBA.
üêõ DEBUG: AKBA - Moving model to CPU before return...
üêõ DEBUG [22:26:49.942]: AKBA - Returning result metadata...
üêõ DEBUG [22:26:49.943]: Main received result for AKBAüêõ DEBUG: train_worker started for SBET

üêõ DEBUG: Training progress: 52/959 done
  ‚öôÔ∏è Training models for SBET (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-71 - SBET: Initiating feature extraction for training.
  [DIAGNOSTIC] SBET: fetch_training_data - Initial data rows: 205
   ‚Ü≥ SBET: rows after features available: 126
üéØ SBET: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] SBET: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö SBET: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ SBET: Training LSTM (50 epochs)...
      ‚è≥ SBET LSTM: Epoch 10/50 (20%)
      ‚è≥ SBET LSTM: Epoch 20/50 (40%)
       ‚úÖ LX XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=192.2712 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}) | Time: 126.7s
    - LSTM: MSE=0.0634
    - TCN: MSE=0.0173
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 131.5 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0173
        ‚Ä¢ LSTM: MSE=0.0634
        ‚Ä¢ Random Forest: MSE=105.7017
        ‚Ä¢ LightGBM Regressor (CPU): MSE=132.7167
        ‚Ä¢ XGBoost: MSE=192.2712
   ‚úÖ LX: Phase 3/3 - Model selection complete!
  üèÜ WINNER for LX (TargetReturn): TCN with MSE=0.0173
üêõ DEBUG: LX - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for LX.
üêõ DEBUG: LX - Moving model to CPU before return...
üêõ DEBUG [22:26:51.150]: LX - Returning result metadata...
üêõ DEBUG: train_worker started for AISP
  ‚öôÔ∏è Training models for AISP (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-69 - AISP: Initiating feature extraction for training.
  [DIAGNOSTIC] AISP: fetch_training_data - Initial data rows: 205
   ‚Ü≥ AISP: rows after features available: 126
üéØ AISP: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] AISP: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö AISP: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ AISP: Training LSTM (50 epochs)...
      ‚è≥ SBET LSTM: Epoch 30/50 (60%)
       ‚úÖ MPU XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=220.9919 (Best Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}) | Time: 128.8s
    - LSTM: MSE=0.4078
    - TCN: MSE=0.3051
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 134.0 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.3051
        ‚Ä¢ LSTM: MSE=0.4078
        ‚Ä¢ Random Forest: MSE=194.7452
        ‚Ä¢ XGBoost: MSE=220.9919
        ‚Ä¢ LightGBM Regressor (CPU): MSE=483.3389
   ‚úÖ MPU: Phase 3/3 - Model selection complete!
  üèÜ WINNER for MPU (TargetReturn): TCN with MSE=0.3051
üêõ DEBUG: MPU - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for MPU.
üêõ DEBUG: MPU - Moving model to CPU before return...
üêõ DEBUG [22:26:51.535]: MPU - Returning result metadata...
üêõ DEBUG: train_worker started for OPFI
üêõ DEBUG [22:26:51.536]: Main received result for MPU
  ‚öôÔ∏è Training models for OPFI (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-66 - OPFI: Initiating feature extraction for training.
  [DIAGNOSTIC] OPFI: fetch_training_data - Initial data rows: 205
   ‚Ü≥ OPFI: rows after features available: 126
üéØ OPFI: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] OPFI: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö OPFI: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ OPFI: Training LSTM (50 epochs)...
      ‚è≥ AISP LSTM: Epoch 10/50 (20%)
      ‚è≥ SBET LSTM: Epoch 40/50 (80%)
      ‚è≥ OPFI LSTM: Epoch 10/50 (20%)
      ‚è≥ AISP LSTM: Epoch 20/50 (40%)
      ‚è≥ OPFI LSTM: Epoch 20/50 (40%)
      üìä LSTM Regression Metrics:
         MSE: 0.572573
         RMSE: 0.756686
         R¬≤ Score: -0.7492 (Poor - 74.9% variance explained)
      üîπ SBET: Training TCN (50 epochs)...
      ‚è≥ AISP LSTM: Epoch 30/50 (60%)
      ‚è≥ SBET TCN: Epoch 10/50 (20%)
       ‚úÖ SEI XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=188.7202 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}) | Time: 127.7s
    - LSTM: MSE=0.2593
    - TCN: MSE=0.1910
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 132.3 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1910
        ‚Ä¢ LSTM: MSE=0.2593
        ‚Ä¢ Random Forest: MSE=137.5024
        ‚Ä¢ LightGBM Regressor (CPU): MSE=137.9801
        ‚Ä¢ XGBoost: MSE=188.7202
   ‚úÖ SEI: Phase 3/3 - Model selection complete!
  üèÜ WINNER for SEI (TargetReturn): TCN with MSE=0.1910
üêõ DEBUG: SEI - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for SEI.
üêõ DEBUG: SEI - Moving model to CPU before return...
üêõ DEBUG [22:26:52.845]: SEI - Returning result metadata...
üêõ DEBUG: train_worker started for NET
       ‚úÖ ORLA XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=58.1087 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 129.1s
    - LSTM: MSE=0.4059
    - TCN: MSE=0.3868
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 133.7 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.3868
        ‚Ä¢ LSTM: MSE=0.4059
        ‚Ä¢ XGBoost: MSE=58.1087
        ‚Ä¢ LightGBM Regressor (CPU): MSE=74.0505
        ‚Ä¢ Random Forest: MSE=78.6007
   ‚úÖ ORLA: Phase 3/3 - Model selection complete!
  üèÜ WINNER for ORLA (TargetReturn): TCN with MSE=0.3868
üêõ DEBUG: ORLA - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for ORLA.
üêõ DEBUG: ORLA - Moving model to CPU before return...
üêõ DEBUG [22:26:52.861]: ORLA - Returning result metadata...
üêõ DEBUG: train_worker started for LGCY
  ‚öôÔ∏è Training models for NET (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-74 - NET: Initiating feature extraction for training.
  [DIAGNOSTIC] NET: fetch_training_data - Initial data rows: 205
   ‚Ü≥ NET: rows after features available: 126
üéØ NET: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] NET: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö NET: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ NET: Training LSTM (50 epochs)...
  ‚öôÔ∏è Training models for LGCY (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-61 - LGCY: Initiating feature extraction for training.
  [DIAGNOSTIC] LGCY: fetch_training_data - Initial data rows: 205
   ‚Ü≥ LGCY: rows after features available: 126
üéØ LGCY: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] LGCY: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö LGCY: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ LGCY: Training LSTM (50 epochs)...
      ‚è≥ SBET TCN: Epoch 20/50 (40%)
      ‚è≥ SBET TCN: Epoch 30/50 (60%)
      ‚è≥ SBET TCN: Epoch 40/50 (80%)
      ‚è≥ OPFI LSTM: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.321306
         RMSE: 0.566839
         R¬≤ Score: 0.0184
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä SBET: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ SBET Random Forest: Starting GridSearchCV fit...
       ‚úÖ RBRK XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=110.2153 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 130.5s
    - LSTM: MSE=0.3735
    - TCN: MSE=0.2557
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 135.2 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.2557
        ‚Ä¢ LSTM: MSE=0.3735
        ‚Ä¢ Random Forest: MSE=51.6070
        ‚Ä¢ LightGBM Regressor (CPU): MSE=55.6822
        ‚Ä¢ XGBoost: MSE=110.2153
   ‚úÖ RBRK: Phase 3/3 - Model selection complete!
  üèÜ WINNER for RBRK (TargetReturn): TCN with MSE=0.2557
üêõ DEBUG: RBRK - train_and_evaluate_models completed
      ‚è≥ AISP LSTM: Epoch 40/50 (80%)
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for RBRK.
üêõ DEBUG: RBRK - Moving model to CPU before return...
üêõ DEBUG [22:26:53.452]: RBRK - Returning result metadata...
üêõ DEBUG: train_worker started for BITU
üêõ DEBUG [22:26:53.453]: Main received result for RBRK
  ‚öôÔ∏è Training models for BITU (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-64 - BITU: Initiating feature extraction for training.
  [DIAGNOSTIC] BITU: fetch_training_data - Initial data rows: 205
   ‚Ü≥ BITU: rows after features available: 126
üéØ BITU: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] BITU: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö BITU: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ BITU: Training LSTM (50 epochs)...
       ‚úÖ ALLT XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=127.4174 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 130.4s
    - LSTM: MSE=0.2693
    - TCN: MSE=0.2580
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 135.2 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.2580
        ‚Ä¢ LSTM: MSE=0.2693
        ‚Ä¢ Random Forest: MSE=84.8721
        ‚Ä¢ LightGBM Regressor (CPU): MSE=107.7470
        ‚Ä¢ XGBoost: MSE=127.4174
   ‚úÖ ALLT: Phase 3/3 - Model selection complete!
  üèÜ WINNER for ALLT (TargetReturn): TCN with MSE=0.2580
üêõ DEBUG: ALLT - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for ALLT.
üêõ DEBUG: ALLT - Moving model to CPU before return...
üêõ DEBUG [22:26:53.530]: ALLT - Returning result metadata...
üêõ DEBUG: train_worker started for LMND
üêõ DEBUG [22:26:53.532]: Main received result for ALLT
üêõ DEBUG [22:26:53.532]: Main received result for ORLA
üêõ DEBUG: Training progress: 56/959 done
üêõ DEBUG [22:26:53.532]: Main received result for LX
üêõ DEBUG [22:26:53.532]: Main received result for SEI
      ‚è≥ LGCY LSTM: Epoch 10/50 (20%)
      ‚è≥ NET LSTM: Epoch 10/50 (20%)
  ‚öôÔ∏è Training models for LMND (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-70 - LMND: Initiating feature extraction for training.
  [DIAGNOSTIC] LMND: fetch_training_data - Initial data rows: 205
   ‚Ü≥ LMND: rows after features available: 126
üéØ LMND: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] LMND: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö LMND: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ LMND: Training LSTM (50 epochs)...
      ‚è≥ OPFI LSTM: Epoch 40/50 (80%)
      ‚è≥ BITU LSTM: Epoch 10/50 (20%)
      ‚è≥ LMND LSTM: Epoch 10/50 (20%)
      üìä LSTM Regression Metrics:
         MSE: 0.175083
         RMSE: 0.418429
         R¬≤ Score: -0.5827 (Poor - 58.3% variance explained)
      üîπ AISP: Training TCN (50 epochs)...
      ‚è≥ NET LSTM: Epoch 20/50 (40%)
      ‚è≥ LGCY LSTM: Epoch 20/50 (40%)
      ‚è≥ AISP TCN: Epoch 10/50 (20%)
      ‚è≥ AISP TCN: Epoch 20/50 (40%)
      ‚è≥ AISP TCN: Epoch 30/50 (60%)
      ‚è≥ AISP TCN: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.161105
         RMSE: 0.401379
         R¬≤ Score: -1.1717 (Poor - 117.2% variance explained)
      üîπ OPFI: Training TCN (50 epochs)...
      ‚è≥ LMND LSTM: Epoch 20/50 (40%)
      ‚è≥ NET LSTM: Epoch 30/50 (60%)
      ‚è≥ LGCY LSTM: Epoch 30/50 (60%)
      ‚è≥ OPFI TCN: Epoch 10/50 (20%)
      üìä TCN Regression Metrics:
         MSE: 0.139363
         RMSE: 0.373314
         R¬≤ Score: -0.2598
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä AISP: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ AISP Random Forest: Starting GridSearchCV fit...
      ‚è≥ BITU LSTM: Epoch 20/50 (40%)
      ‚è≥ OPFI TCN: Epoch 20/50 (40%)
      ‚è≥ OPFI TCN: Epoch 30/50 (60%)
       ‚úÖ ETON XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=50.0459 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 130.6s
    - LSTM: MSE=0.1189
    - TCN: MSE=0.0547
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 135.0 seconds (2.3 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0547
        ‚Ä¢ LSTM: MSE=0.1189
        ‚Ä¢ Random Forest: MSE=42.0282
        ‚Ä¢ XGBoost: MSE=50.0459
        ‚Ä¢ LightGBM Regressor (CPU): MSE=69.9160
   ‚úÖ ETON: Phase 3/3 - Model selection complete!
  üèÜ WINNER for ETON (TargetReturn): TCN with MSE=0.0547
üêõ DEBUG: ETON - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for ETON.
üêõ DEBUG: ETON - Moving model to CPU before return...
üêõ DEBUG [22:26:55.333]: ETON - Returning result metadata...
üêõ DEBUG [22:26:55.334]: Main received result for ETON
üêõ DEBUG: train_worker started for MSTR
      ‚è≥ OPFI TCN: Epoch 40/50 (80%)
  ‚öôÔ∏è Training models for MSTR (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-72 - MSTR: Initiating feature extraction for training.
  [DIAGNOSTIC] MSTR: fetch_training_data - Initial data rows: 205
   ‚Ü≥ MSTR: rows after features available: 126
üéØ MSTR: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] MSTR: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö MSTR: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ MSTR: Training LSTM (50 epochs)...
      ‚è≥ LMND LSTM: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.099676
         RMSE: 0.315715
         R¬≤ Score: -0.3436
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä OPFI: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ OPFI Random Forest: Starting GridSearchCV fit...
      ‚è≥ LGCY LSTM: Epoch 40/50 (80%)
      ‚è≥ BITU LSTM: Epoch 30/50 (60%)
      ‚è≥ NET LSTM: Epoch 40/50 (80%)
      ‚è≥ MSTR LSTM: Epoch 10/50 (20%)
      ‚è≥ LMND LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.616571
         RMSE: 0.785221
         R¬≤ Score: -0.5494 (Poor - 54.9% variance explained)
      üîπ LGCY: Training TCN (50 epochs)...
      ‚è≥ BITU LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.521052
         RMSE: 0.721839
         R¬≤ Score: -0.5141 (Poor - 51.4% variance explained)
      üîπ NET: Training TCN (50 epochs)...
      ‚è≥ LGCY TCN: Epoch 10/50 (20%)
      ‚è≥ LGCY TCN: Epoch 20/50 (40%)
      ‚è≥ NET TCN: Epoch 10/50 (20%)
      ‚è≥ LGCY TCN: Epoch 30/50 (60%)
      ‚è≥ MSTR LSTM: Epoch 20/50 (40%)
      ‚è≥ NET TCN: Epoch 20/50 (40%)
      ‚è≥ LGCY TCN: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.283975
         RMSE: 0.532893
         R¬≤ Score: -0.5734 (Poor - 57.3% variance explained)
      üîπ LMND: Training TCN (50 epochs)...
      ‚è≥ NET TCN: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.575066
         RMSE: 0.758331
         R¬≤ Score: -0.4451
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä LGCY: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ LGCY Random Forest: Starting GridSearchCV fit...
      ‚è≥ LMND TCN: Epoch 10/50 (20%)
      ‚è≥ NET TCN: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.308095
         RMSE: 0.555063
         R¬≤ Score: -0.8642 (Poor - 86.4% variance explained)
      üîπ BITU: Training TCN (50 epochs)...
      ‚è≥ LMND TCN: Epoch 20/50 (40%)
      üìä TCN Regression Metrics:
         MSE: 0.612287
         RMSE: 0.782488
         R¬≤ Score: -0.7793
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä NET: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ NET Random Forest: Starting GridSearchCV fit...
      ‚è≥ BITU TCN: Epoch 10/50 (20%)
      ‚è≥ LMND TCN: Epoch 30/50 (60%)
       ‚úÖ KTOS XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=84.7298 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 130.8s
    - LSTM: MSE=0.4992
    - TCN: MSE=0.3959
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 134.7 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.3959
        ‚Ä¢ LSTM: MSE=0.4992
        ‚Ä¢ LightGBM Regressor (CPU): MSE=45.1987
        ‚Ä¢ Random Forest: MSE=52.4171
        ‚Ä¢ XGBoost: MSE=84.7298
   ‚úÖ KTOS: Phase 3/3 - Model selection complete!
  üèÜ WINNER for KTOS (TargetReturn): TCN with MSE=0.3959
üêõ DEBUG: KTOS - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for KTOS.
üêõ DEBUG: KTOS - Moving model to CPU before return...
üêõ DEBUG [22:26:57.269]: KTOS - Returning result metadata...
üêõ DEBUG [22:26:57.270]: Main received result for KTOS
üêõ DEBUG: Training progress: 60/959 done
üêõ DEBUG: train_worker started for NEXT
      ‚è≥ MSTR LSTM: Epoch 30/50 (60%)
      ‚è≥ BITU TCN: Epoch 20/50 (40%)
  ‚öôÔ∏è Training models for NEXT (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-67 - NEXT: Initiating feature extraction for training.
  [DIAGNOSTIC] NEXT: fetch_training_data - Initial data rows: 205
   ‚Ü≥ NEXT: rows after features available: 126
üéØ NEXT: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] NEXT: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö NEXT: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ NEXT: Training LSTM (50 epochs)...
       ‚úÖ SBET Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=24697.6494 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 4.0s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ SBET LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ LMND TCN: Epoch 40/50 (80%)
      ‚è≥ BITU TCN: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.292108
         RMSE: 0.540471
         R¬≤ Score: -0.6185
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä LMND: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ LMND Random Forest: Starting GridSearchCV fit...
      ‚è≥ BITU TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.196923
         RMSE: 0.443760
         R¬≤ Score: -0.1915
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä BITU: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ BITU Random Forest: Starting GridSearchCV fit...
      ‚è≥ NEXT LSTM: Epoch 10/50 (20%)
      ‚è≥ MSTR LSTM: Epoch 40/50 (80%)
       ‚úÖ SBET LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=26069.3750 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 1.0s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ SBET XGBoost: Starting GridSearchCV fit...
      ‚è≥ NEXT LSTM: Epoch 20/50 (40%)
      üìä LSTM Regression Metrics:
         MSE: 0.132255
         RMSE: 0.363669
         R¬≤ Score: -0.4862 (Poor - 48.6% variance explained)
      üîπ MSTR: Training TCN (50 epochs)...
      ‚è≥ MSTR TCN: Epoch 10/50 (20%)
      ‚è≥ MSTR TCN: Epoch 20/50 (40%)
       ‚úÖ AISP Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=179.0719 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 4.0s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ AISP LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ MSTR TCN: Epoch 30/50 (60%)
      ‚è≥ MSTR TCN: Epoch 40/50 (80%)
      ‚è≥ NEXT LSTM: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.092210
         RMSE: 0.303662
         R¬≤ Score: -0.0362
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä MSTR: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ MSTR Random Forest: Starting GridSearchCV fit...
       ‚úÖ OPFI Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=136.0601 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ OPFI LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ NEXT LSTM: Epoch 40/50 (80%)
       ‚úÖ AISP LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=237.1278 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ AISP XGBoost: Starting GridSearchCV fit...
       ‚úÖ OPFI LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=231.8172 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ OPFI XGBoost: Starting GridSearchCV fit...
       ‚úÖ LGCY Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=35.9144 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.6s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ LGCY LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ NET Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=75.6564 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 3.4s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ NET LightGBM Regressor (CPU): Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 0.359805
         RMSE: 0.599838
         R¬≤ Score: -0.4591 (Poor - 45.9% variance explained)
      üîπ NEXT: Training TCN (50 epochs)...
      ‚è≥ NEXT TCN: Epoch 10/50 (20%)
      ‚è≥ NEXT TCN: Epoch 20/50 (40%)
      ‚è≥ NEXT TCN: Epoch 30/50 (60%)
       ‚úÖ BITU Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=74.4473 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 3.3s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ BITU LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ NEXT TCN: Epoch 40/50 (80%)
       ‚úÖ LMND Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=62.6268 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 3.7s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ LMND LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ LGCY LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=37.8035 (Best Params: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ LGCY XGBoost: Starting GridSearchCV fit...
      üìä TCN Regression Metrics:
         MSE: 0.358645
         RMSE: 0.598869
         R¬≤ Score: -0.4543
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä NEXT: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ NEXT Random Forest: Starting GridSearchCV fit...
       ‚úÖ NET LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=70.8419 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ NET XGBoost: Starting GridSearchCV fit...
       ‚úÖ BITU LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=57.5348 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ BITU XGBoost: Starting GridSearchCV fit...
       ‚úÖ LMND LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=88.1574 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ LMND XGBoost: Starting GridSearchCV fit...
       ‚úÖ MSTR Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=55.1613 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 3.1s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ MSTR LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ MSTR LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=58.3629 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ MSTR XGBoost: Starting GridSearchCV fit...
       ‚úÖ NEXT Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=72.5657 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.0s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ NEXT LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ NEXT LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=63.4641 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ NEXT XGBoost: Starting GridSearchCV fit...
       ‚úÖ NAGE XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=148.5576 (Best Params: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200}) | Time: 122.5s
    - LSTM: MSE=0.2519
    - TCN: MSE=0.1270
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 125.9 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1270
        ‚Ä¢ LSTM: MSE=0.2519
        ‚Ä¢ LightGBM Regressor (CPU): MSE=132.1669
        ‚Ä¢ XGBoost: MSE=148.5576
        ‚Ä¢ Random Forest: MSE=185.9476
   ‚úÖ NAGE: Phase 3/3 - Model selection complete!
  üèÜ WINNER for NAGE (TargetReturn): TCN with MSE=0.1270
üêõ DEBUG: NAGE - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for NAGE.
üêõ DEBUG: NAGE - Moving model to CPU before return...
üêõ DEBUG [22:28:11.939]: NAGE - Returning result metadata...
üêõ DEBUG: train_worker started for BITX
üêõ DEBUG [22:28:11.940]: Main received result for NAGE
  ‚öôÔ∏è Training models for BITX (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-62 - BITX: Initiating feature extraction for training.
  [DIAGNOSTIC] BITX: fetch_training_data - Initial data rows: 205
   ‚Ü≥ BITX: rows after features available: 126
üéØ BITX: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] BITX: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö BITX: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ BITX: Training LSTM (50 epochs)...
      ‚è≥ BITX LSTM: Epoch 10/50 (20%)
      ‚è≥ BITX LSTM: Epoch 20/50 (40%)
      ‚è≥ BITX LSTM: Epoch 30/50 (60%)
      ‚è≥ BITX LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.386929
         RMSE: 0.622036
         R¬≤ Score: -1.3146 (Poor - 131.5% variance explained)
      üîπ BITX: Training TCN (50 epochs)...
      ‚è≥ BITX TCN: Epoch 10/50 (20%)
      ‚è≥ BITX TCN: Epoch 20/50 (40%)
      ‚è≥ BITX TCN: Epoch 30/50 (60%)
      ‚è≥ BITX TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.234741
         RMSE: 0.484501
         R¬≤ Score: -0.4042
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä BITX: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ BITX Random Forest: Starting GridSearchCV fit...
       ‚úÖ QMCO XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=1513.0495 (Best Params: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100}) | Time: 115.4s
    - LSTM: MSE=0.0129
    - TCN: MSE=0.0045
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 118.9 seconds (2.0 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0045
        ‚Ä¢ LSTM: MSE=0.0129
        ‚Ä¢ Random Forest: MSE=707.4518
        ‚Ä¢ XGBoost: MSE=1513.0495
        ‚Ä¢ LightGBM Regressor (CPU): MSE=2205.7179
   ‚úÖ QMCO: Phase 3/3 - Model selection complete!
  üèÜ WINNER for QMCO (TargetReturn): TCN with MSE=0.0045
üêõ DEBUG: QMCO - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for QMCO.
üêõ DEBUG: QMCO - Moving model to CPU before return...
üêõ DEBUG [22:28:16.290]: QMCO - Returning result metadata...
üêõ DEBUG: train_worker started for AS
üêõ DEBUG [22:28:16.290]: Main received result for QMCO
  ‚öôÔ∏è Training models for AS (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-73 - AS: Initiating feature extraction for training.
  [DIAGNOSTIC] AS: fetch_training_data - Initial data rows: 205
   ‚Ü≥ AS: rows after features available: 126
üéØ AS: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] AS: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö AS: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ AS: Training LSTM (50 epochs)...
      ‚è≥ AS LSTM: Epoch 10/50 (20%)
       ‚úÖ BITX Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=88.4541 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 2.7s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ BITX LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ AS LSTM: Epoch 20/50 (40%)
      ‚è≥ AS LSTM: Epoch 30/50 (60%)
       ‚úÖ BITX LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=74.2392 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ BITX XGBoost: Starting GridSearchCV fit...
      ‚è≥ AS LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.651954
         RMSE: 0.807436
         R¬≤ Score: -1.3195 (Poor - 132.0% variance explained)
      üîπ AS: Training TCN (50 epochs)...
      ‚è≥ AS TCN: Epoch 10/50 (20%)
      ‚è≥ AS TCN: Epoch 20/50 (40%)
      ‚è≥ AS TCN: Epoch 30/50 (60%)
      ‚è≥ AS TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.429554
         RMSE: 0.655404
         R¬≤ Score: -0.5283
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä AS: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ AS Random Forest: Starting GridSearchCV fit...
       ‚úÖ GEV XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=119.0849 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 119.3s
    - LSTM: MSE=0.3522
    - TCN: MSE=0.3264
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 122.9 seconds (2.0 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.3264
        ‚Ä¢ LSTM: MSE=0.3522
        ‚Ä¢ LightGBM Regressor (CPU): MSE=75.2107
        ‚Ä¢ Random Forest: MSE=91.1056
        ‚Ä¢ XGBoost: MSE=119.0849
   ‚úÖ GEV: Phase 3/3 - Model selection complete!
  üèÜ WINNER for GEV (TargetReturn): TCN with MSE=0.3264
üêõ DEBUG: GEV - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for GEV.
üêõ DEBUG: GEV - Moving model to CPU before return...
üêõ DEBUG [22:28:21.415]: GEV - Returning result metadata...
üêõ DEBUG: train_worker started for CAR
üêõ DEBUG [22:28:21.416]: Main received result for GEV
  ‚öôÔ∏è Training models for CAR (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-68 - CAR: Initiating feature extraction for training.
  [DIAGNOSTIC] CAR: fetch_training_data - Initial data rows: 205
   ‚Ü≥ CAR: rows after features available: 126
üéØ CAR: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] CAR: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö CAR: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ CAR: Training LSTM (50 epochs)...
       ‚úÖ AS Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=31.6669 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 2.7s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ AS LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ CAR LSTM: Epoch 10/50 (20%)
      ‚è≥ CAR LSTM: Epoch 20/50 (40%)
       ‚úÖ AS LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=36.4977 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 100}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ AS XGBoost: Starting GridSearchCV fit...
      ‚è≥ CAR LSTM: Epoch 30/50 (60%)
      ‚è≥ CAR LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.555359
         RMSE: 0.745224
         R¬≤ Score: -1.1562 (Poor - 115.6% variance explained)
      üîπ CAR: Training TCN (50 epochs)...
      ‚è≥ CAR TCN: Epoch 10/50 (20%)
      ‚è≥ CAR TCN: Epoch 20/50 (40%)
      ‚è≥ CAR TCN: Epoch 30/50 (60%)
      ‚è≥ CAR TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.440824
         RMSE: 0.663946
         R¬≤ Score: -0.7115
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä CAR: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ CAR Random Forest: Starting GridSearchCV fit...
       ‚úÖ CAR Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=107.9902 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 2.5s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ CAR LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ CAR LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=119.2936 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.6s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ CAR XGBoost: Starting GridSearchCV fit...
       ‚úÖ AMLX XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=370.7906 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 121.1s
    - LSTM: MSE=0.2298
    - TCN: MSE=0.1046
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 125.2 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1046
        ‚Ä¢ LSTM: MSE=0.2298
        ‚Ä¢ LightGBM Regressor (CPU): MSE=223.6297
        ‚Ä¢ Random Forest: MSE=258.2212
        ‚Ä¢ XGBoost: MSE=370.7906
   ‚úÖ AMLX: Phase 3/3 - Model selection complete!
  üèÜ WINNER for AMLX (TargetReturn): TCN with MSE=0.1046
üêõ DEBUG: AMLX - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for AMLX.
üêõ DEBUG: AMLX - Moving model to CPU before return...
üêõ DEBUG [22:28:42.323]: AMLX - Returning result metadata...
üêõ DEBUG: train_worker started for SRAD
üêõ DEBUG [22:28:42.324]: Main received result for AMLX
üêõ DEBUG: Training progress: 64/959 done
  ‚öôÔ∏è Training models for SRAD (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-65 - SRAD: Initiating feature extraction for training.
  [DIAGNOSTIC] SRAD: fetch_training_data - Initial data rows: 205
   ‚Ü≥ SRAD: rows after features available: 126
üéØ SRAD: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] SRAD: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö SRAD: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ SRAD: Training LSTM (50 epochs)...
       ‚úÖ SOUN XGBoost: GridSearchCV complete
    ‚úÖ üéØ BEST! XGBoost: MSE=165.6024 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 118.8s
    - LSTM: MSE=0.0865
    - TCN: MSE=0.0560
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 122.5 seconds (2.0 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0560
        ‚Ä¢ LSTM: MSE=0.0865
        ‚Ä¢ XGBoost: MSE=165.6024
        ‚Ä¢ Random Forest: MSE=171.7725
        ‚Ä¢ LightGBM Regressor (CPU): MSE=361.3210
   ‚úÖ SOUN: Phase 3/3 - Model selection complete!
  üèÜ WINNER for SOUN (TargetReturn): TCN with MSE=0.0560
üêõ DEBUG: SOUN - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for SOUN.
üêõ DEBUG: SOUN - Moving model to CPU before return...
üêõ DEBUG [22:28:42.376]: SOUN - Returning result metadata...
üêõ DEBUG: train_worker started for AGX
üêõ DEBUG [22:28:42.377]: Main received result for SOUN
  ‚öôÔ∏è Training models for AGX (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-63 - AGX: Initiating feature extraction for training.
  [DIAGNOSTIC] AGX: fetch_training_data - Initial data rows: 205
   ‚Ü≥ AGX: rows after features available: 126
üéØ AGX: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] AGX: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö AGX: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ AGX: Training LSTM (50 epochs)...
      ‚è≥ SRAD LSTM: Epoch 10/50 (20%)
      ‚è≥ AGX LSTM: Epoch 10/50 (20%)
      ‚è≥ SRAD LSTM: Epoch 20/50 (40%)
      ‚è≥ AGX LSTM: Epoch 20/50 (40%)
      ‚è≥ SRAD LSTM: Epoch 30/50 (60%)
      ‚è≥ AGX LSTM: Epoch 30/50 (60%)
      ‚è≥ SRAD LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.153175
         RMSE: 0.391376
         R¬≤ Score: -1.0153 (Poor - 101.5% variance explained)
      üîπ SRAD: Training TCN (50 epochs)...
      ‚è≥ AGX LSTM: Epoch 40/50 (80%)
      ‚è≥ SRAD TCN: Epoch 10/50 (20%)
      ‚è≥ SRAD TCN: Epoch 20/50 (40%)
      ‚è≥ SRAD TCN: Epoch 30/50 (60%)
      ‚è≥ SRAD TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.095233
         RMSE: 0.308599
         R¬≤ Score: -0.2530
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä SRAD: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ SRAD Random Forest: Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 0.344041
         RMSE: 0.586550
         R¬≤ Score: -1.0045 (Poor - 100.5% variance explained)
      üîπ AGX: Training TCN (50 epochs)...
      ‚è≥ AGX TCN: Epoch 10/50 (20%)
      ‚è≥ AGX TCN: Epoch 20/50 (40%)
      ‚è≥ AGX TCN: Epoch 30/50 (60%)
      ‚è≥ AGX TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.181009
         RMSE: 0.425452
         R¬≤ Score: -0.0546
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä AGX: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ AGX Random Forest: Starting GridSearchCV fit...
       ‚úÖ TTMI XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=51.3642 (Best Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}) | Time: 121.3s
    - LSTM: MSE=0.5589
    - TCN: MSE=0.5612
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 124.7 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.5589
        ‚Ä¢ TCN: MSE=0.5612
        ‚Ä¢ Random Forest: MSE=43.4548
        ‚Ä¢ XGBoost: MSE=51.3642
        ‚Ä¢ LightGBM Regressor (CPU): MSE=59.0920
   ‚úÖ TTMI: Phase 3/3 - Model selection complete!
  üèÜ WINNER for TTMI (TargetReturn): LSTM with MSE=0.5589
üêõ DEBUG: TTMI - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for TTMI.
üêõ DEBUG: TTMI - Moving model to CPU before return...
üêõ DEBUG [22:28:47.097]: TTMI - Returning result metadata...
üêõ DEBUG: train_worker started for TPR
üêõ DEBUG [22:28:47.100]: Main received result for TTMI
  ‚öôÔ∏è Training models for TPR (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-75 - TPR: Initiating feature extraction for training.
  [DIAGNOSTIC] TPR: fetch_training_data - Initial data rows: 205
   ‚Ü≥ TPR: rows after features available: 126
üéØ TPR: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] TPR: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö TPR: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ TPR: Training LSTM (50 epochs)...
      ‚è≥ TPR LSTM: Epoch 10/50 (20%)
      ‚è≥ TPR LSTM: Epoch 20/50 (40%)
       ‚úÖ SRAD Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=19.9920 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 3.4s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ SRAD LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ TPR LSTM: Epoch 30/50 (60%)
       ‚úÖ AGX Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=49.1719 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.3s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ AGX LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ SRAD LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=25.4964 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ SRAD XGBoost: Starting GridSearchCV fit...
      ‚è≥ TPR LSTM: Epoch 40/50 (80%)
       ‚úÖ AGX LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=58.7289 (Best Params: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ AGX XGBoost: Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 0.872095
         RMSE: 0.933860
         R¬≤ Score: -1.3951 (Poor - 139.5% variance explained)
      üîπ TPR: Training TCN (50 epochs)...
      ‚è≥ TPR TCN: Epoch 10/50 (20%)
      ‚è≥ TPR TCN: Epoch 20/50 (40%)
      ‚è≥ TPR TCN: Epoch 30/50 (60%)
      ‚è≥ TPR TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.705304
         RMSE: 0.839824
         R¬≤ Score: -0.9370
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä TPR: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ TPR Random Forest: Starting GridSearchCV fit...
       ‚úÖ TPR Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=22.4907 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 2.5s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ TPR LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ TPR LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=26.7254 (Best Params: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ TPR XGBoost: Starting GridSearchCV fit...
       ‚úÖ SBET XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=28917.6052 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 121.1s
    - LSTM: MSE=0.5726
    - TCN: MSE=0.3213
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 126.1 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.3213
        ‚Ä¢ LSTM: MSE=0.5726
        ‚Ä¢ Random Forest: MSE=24697.6494
        ‚Ä¢ LightGBM Regressor (CPU): MSE=26069.3750
        ‚Ä¢ XGBoost: MSE=28917.6052
   ‚úÖ SBET: Phase 3/3 - Model selection complete!
  üèÜ WINNER for SBET (TargetReturn): TCN with MSE=0.3213
üêõ DEBUG: SBET - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for SBET.
üêõ DEBUG: SBET - Moving model to CPU before return...
üêõ DEBUG [22:28:59.482]: SBET - Returning result metadata...
üêõ DEBUG [22:28:59.483]: Main received result for SBET
üêõ DEBUG: train_worker started for INVZ
  ‚öôÔ∏è Training models for INVZ (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-71 - INVZ: Initiating feature extraction for training.
  [DIAGNOSTIC] INVZ: fetch_training_data - Initial data rows: 205
   ‚Ü≥ INVZ: rows after features available: 126
üéØ INVZ: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] INVZ: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö INVZ: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ INVZ: Training LSTM (50 epochs)...
      ‚è≥ INVZ LSTM: Epoch 10/50 (20%)
      ‚è≥ INVZ LSTM: Epoch 20/50 (40%)
      ‚è≥ INVZ LSTM: Epoch 30/50 (60%)
      ‚è≥ INVZ LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.811299
         RMSE: 0.900722
         R¬≤ Score: -1.3327 (Poor - 133.3% variance explained)
      üîπ INVZ: Training TCN (50 epochs)...
      ‚è≥ INVZ TCN: Epoch 10/50 (20%)
      ‚è≥ INVZ TCN: Epoch 20/50 (40%)
      ‚è≥ INVZ TCN: Epoch 30/50 (60%)
      ‚è≥ INVZ TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.660622
         RMSE: 0.812787
         R¬≤ Score: -0.8994
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä INVZ: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ INVZ Random Forest: Starting GridSearchCV fit...
       ‚úÖ LGCY XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=38.2047 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 121.9s
    - LSTM: MSE=0.6166
    - TCN: MSE=0.5751
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 126.2 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.5751
        ‚Ä¢ LSTM: MSE=0.6166
        ‚Ä¢ Random Forest: MSE=35.9144
        ‚Ä¢ LightGBM Regressor (CPU): MSE=37.8035
        ‚Ä¢ XGBoost: MSE=38.2047
   ‚úÖ LGCY: Phase 3/3 - Model selection complete!
  üèÜ WINNER for LGCY (TargetReturn): TCN with MSE=0.5751
üêõ DEBUG: LGCY - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for LGCY.
üêõ DEBUG: LGCY - Moving model to CPU before return...
üêõ DEBUG [22:29:03.155]: LGCY - Returning result metadata...
üêõ DEBUG: train_worker started for DPRO
  ‚öôÔ∏è Training models for DPRO (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-61 - DPRO: Initiating feature extraction for training.
  [DIAGNOSTIC] DPRO: fetch_training_data - Initial data rows: 205
   ‚Ü≥ DPRO: rows after features available: 126
üéØ DPRO: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] DPRO: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö DPRO: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ DPRO: Training LSTM (50 epochs)...
      ‚è≥ DPRO LSTM: Epoch 10/50 (20%)
      ‚è≥ DPRO LSTM: Epoch 20/50 (40%)
      ‚è≥ DPRO LSTM: Epoch 30/50 (60%)
      ‚è≥ DPRO LSTM: Epoch 40/50 (80%)
       ‚úÖ INVZ Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=230.1456 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 2.7s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ INVZ LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ NET XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=144.6861 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 124.2s
    - LSTM: MSE=0.5211
    - TCN: MSE=0.6123
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 128.5 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.5211
        ‚Ä¢ TCN: MSE=0.6123
        ‚Ä¢ LightGBM Regressor (CPU): MSE=70.8419
        ‚Ä¢ Random Forest: MSE=75.6564
        ‚Ä¢ XGBoost: MSE=144.6861
   ‚úÖ NET: Phase 3/3 - Model selection complete!
  üèÜ WINNER for NET (TargetReturn): LSTM with MSE=0.5211
üêõ DEBUG: NET - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for NET.
üêõ DEBUG: NET - Moving model to CPU before return...
üêõ DEBUG [22:29:05.584]: NET - Returning result metadata...
üêõ DEBUG: train_worker started for EYE
       ‚úÖ AISP XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=199.2362 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 125.8s
    - LSTM: MSE=0.1751
    - TCN: MSE=0.1394
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 130.6 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1394
        ‚Ä¢ LSTM: MSE=0.1751
        ‚Ä¢ Random Forest: MSE=179.0719
        ‚Ä¢ XGBoost: MSE=199.2362
        ‚Ä¢ LightGBM Regressor (CPU): MSE=237.1278
   ‚úÖ AISP: Phase 3/3 - Model selection complete!
  üèÜ WINNER for AISP (TargetReturn): TCN with MSE=0.1394
üêõ DEBUG: AISP - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for AISP.
üêõ DEBUG: AISP - Moving model to CPU before return...
üêõ DEBUG [22:29:05.590]: AISP - Returning result metadata...
üêõ DEBUG: train_worker started for ESLT
üêõ DEBUG [22:29:05.591]: Main received result for AISP
üêõ DEBUG: Training progress: 68/959 done
  ‚öôÔ∏è Training models for EYE (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-74 - EYE: Initiating feature extraction for training.
  [DIAGNOSTIC] EYE: fetch_training_data - Initial data rows: 205
   ‚Ü≥ EYE: rows after features available: 126
üéØ EYE: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  ‚öôÔ∏è Training models for ESLT (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-69 - ESLT: Initiating feature extraction for training.
  [DIAGNOSTIC] ESLT: fetch_training_data - Initial data rows: 205
   ‚Ü≥ ESLT: rows after features available: 126
üéØ ESLT: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] EYE: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö EYE: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ EYE: Training LSTM (50 epochs)...
  [DIAGNOSTIC] ESLT: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö ESLT: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ ESLT: Training LSTM (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.550692
         RMSE: 0.742087
         R¬≤ Score: -1.4377 (Poor - 143.8% variance explained)
      üîπ DPRO: Training TCN (50 epochs)...
      ‚è≥ DPRO TCN: Epoch 10/50 (20%)
      ‚è≥ DPRO TCN: Epoch 20/50 (40%)
       ‚úÖ INVZ LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=271.0936 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ INVZ XGBoost: Starting GridSearchCV fit...
      ‚è≥ DPRO TCN: Epoch 30/50 (60%)
      ‚è≥ DPRO TCN: Epoch 40/50 (80%)
      ‚è≥ EYE LSTM: Epoch 10/50 (20%)
      ‚è≥ ESLT LSTM: Epoch 10/50 (20%)
      üìä TCN Regression Metrics:
         MSE: 0.269230
         RMSE: 0.518874
         R¬≤ Score: -0.1918
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä DPRO: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ DPRO Random Forest: Starting GridSearchCV fit...
       ‚úÖ LMND XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=83.0228 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 124.3s
    - LSTM: MSE=0.2840
    - TCN: MSE=0.2921
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 128.8 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ LSTM: MSE=0.2840
        ‚Ä¢ TCN: MSE=0.2921
        ‚Ä¢ Random Forest: MSE=62.6268
        ‚Ä¢ XGBoost: MSE=83.0228
        ‚Ä¢ LightGBM Regressor (CPU): MSE=88.1574
   ‚úÖ LMND: Phase 3/3 - Model selection complete!
  üèÜ WINNER for LMND (TargetReturn): LSTM with MSE=0.2840
üêõ DEBUG: LMND - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for LMND.
üêõ DEBUG: LMND - Moving model to CPU before return...
üêõ DEBUG [22:29:06.433]: LMND - Returning result metadata...
üêõ DEBUG: train_worker started for RDDT
  ‚öôÔ∏è Training models for RDDT (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-70 - RDDT: Initiating feature extraction for training.
  [DIAGNOSTIC] RDDT: fetch_training_data - Initial data rows: 205
   ‚Ü≥ RDDT: rows after features available: 126
üéØ RDDT: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] RDDT: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö RDDT: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ RDDT: Training LSTM (50 epochs)...
       ‚úÖ OPFI XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=195.2414 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 126.5s
    - LSTM: MSE=0.1611
    - TCN: MSE=0.0997
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 131.2 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0997
        ‚Ä¢ LSTM: MSE=0.1611
        ‚Ä¢ Random Forest: MSE=136.0601
        ‚Ä¢ XGBoost: MSE=195.2414
        ‚Ä¢ LightGBM Regressor (CPU): MSE=231.8172
   ‚úÖ OPFI: Phase 3/3 - Model selection complete!
  üèÜ WINNER for OPFI (TargetReturn): TCN with MSE=0.0997
üêõ DEBUG: OPFI - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for OPFI.
üêõ DEBUG: OPFI - Moving model to CPU before return...
üêõ DEBUG [22:29:06.727]: OPFI - Returning result metadata...
üêõ DEBUG: train_worker started for OPRT
üêõ DEBUG [22:29:06.728]: Main received result for OPFI
üêõ DEBUG [22:29:06.728]: Main received result for NET
üêõ DEBUG [22:29:06.728]: Main received result for LGCY
  ‚öôÔ∏è Training models for OPRT (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-66 - OPRT: Initiating feature extraction for training.
  [DIAGNOSTIC] OPRT: fetch_training_data - Initial data rows: 205
   ‚Ü≥ OPRT: rows after features available: 126
üéØ OPRT: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] OPRT: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö OPRT: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ OPRT: Training LSTM (50 epochs)...
      ‚è≥ EYE LSTM: Epoch 20/50 (40%)
      ‚è≥ ESLT LSTM: Epoch 20/50 (40%)
      ‚è≥ RDDT LSTM: Epoch 10/50 (20%)
      ‚è≥ OPRT LSTM: Epoch 10/50 (20%)
      ‚è≥ EYE LSTM: Epoch 30/50 (60%)
      ‚è≥ ESLT LSTM: Epoch 30/50 (60%)
       ‚úÖ BITU XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=74.4993 (Best Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}) | Time: 125.9s
    - LSTM: MSE=0.3081
    - TCN: MSE=0.1969
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 130.0 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.1969
        ‚Ä¢ LSTM: MSE=0.3081
        ‚Ä¢ LightGBM Regressor (CPU): MSE=57.5348
        ‚Ä¢ Random Forest: MSE=74.4473
        ‚Ä¢ XGBoost: MSE=74.4993
   ‚úÖ BITU: Phase 3/3 - Model selection complete!
  üèÜ WINNER for BITU (TargetReturn): TCN with MSE=0.1969
üêõ DEBUG: BITU - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for BITU.
üêõ DEBUG: BITU - Moving model to CPU before return...
üêõ DEBUG [22:29:07.829]: BITU - Returning result metadata...
üêõ DEBUG: train_worker started for JFIN
üêõ DEBUG [22:29:07.830]: Main received result for BITU
üêõ DEBUG: Training progress: 72/959 done
üêõ DEBUG [22:29:07.831]: Main received result for LMND
      ‚è≥ RDDT LSTM: Epoch 20/50 (40%)
  ‚öôÔ∏è Training models for JFIN (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-64 - JFIN: Initiating feature extraction for training.
  [DIAGNOSTIC] JFIN: fetch_training_data - Initial data rows: 205
   ‚Ü≥ JFIN: rows after features available: 126
üéØ JFIN: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] JFIN: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö JFIN: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ JFIN: Training LSTM (50 epochs)...
      ‚è≥ EYE LSTM: Epoch 40/50 (80%)
      ‚è≥ OPRT LSTM: Epoch 20/50 (40%)
      ‚è≥ ESLT LSTM: Epoch 40/50 (80%)
      ‚è≥ RDDT LSTM: Epoch 30/50 (60%)
      ‚è≥ JFIN LSTM: Epoch 10/50 (20%)
      üìä LSTM Regression Metrics:
         MSE: 0.629171
         RMSE: 0.793203
         R¬≤ Score: -1.2802 (Poor - 128.0% variance explained)
      üîπ EYE: Training TCN (50 epochs)...
      ‚è≥ OPRT LSTM: Epoch 30/50 (60%)
       ‚úÖ MSTR XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=76.6899 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 125.7s
    - LSTM: MSE=0.1323
    - TCN: MSE=0.0922
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 129.4 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.0922
        ‚Ä¢ LSTM: MSE=0.1323
        ‚Ä¢ Random Forest: MSE=55.1613
        ‚Ä¢ LightGBM Regressor (CPU): MSE=58.3629
        ‚Ä¢ XGBoost: MSE=76.6899
   ‚úÖ MSTR: Phase 3/3 - Model selection complete!
  üèÜ WINNER for MSTR (TargetReturn): TCN with MSE=0.0922
üêõ DEBUG: MSTR - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for MSTR.
üêõ DEBUG: MSTR - Moving model to CPU before return...
üêõ DEBUG [22:29:08.689]: MSTR - Returning result metadata...
üêõ DEBUG: train_worker started for CONL
üêõ DEBUG [22:29:08.690]: Main received result for MSTR
      ‚è≥ EYE TCN: Epoch 10/50 (20%)
  ‚öôÔ∏è Training models for CONL (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-72 - CONL: Initiating feature extraction for training.
  [DIAGNOSTIC] CONL: fetch_training_data - Initial data rows: 205
   ‚Ü≥ CONL: rows after features available: 126
üéØ CONL: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] CONL: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö CONL: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ CONL: Training LSTM (50 epochs)...
      üìä LSTM Regression Metrics:
         MSE: 0.268348
         RMSE: 0.518024
         R¬≤ Score: -1.4672 (Poor - 146.7% variance explained)
      üîπ ESLT: Training TCN (50 epochs)...
      ‚è≥ EYE TCN: Epoch 20/50 (40%)
      ‚è≥ ESLT TCN: Epoch 10/50 (20%)
      ‚è≥ EYE TCN: Epoch 30/50 (60%)
      ‚è≥ ESLT TCN: Epoch 20/50 (40%)
      ‚è≥ RDDT LSTM: Epoch 40/50 (80%)
      ‚è≥ JFIN LSTM: Epoch 20/50 (40%)
      ‚è≥ EYE TCN: Epoch 40/50 (80%)
      ‚è≥ ESLT TCN: Epoch 30/50 (60%)
      ‚è≥ OPRT LSTM: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.397821
         RMSE: 0.630731
         R¬≤ Score: -0.4418
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä EYE: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ EYE Random Forest: Starting GridSearchCV fit...
      ‚è≥ ESLT TCN: Epoch 40/50 (80%)
      ‚è≥ CONL LSTM: Epoch 10/50 (20%)
      üìä TCN Regression Metrics:
         MSE: 0.114204
         RMSE: 0.337940
         R¬≤ Score: -0.0500
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä ESLT: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ ESLT Random Forest: Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 0.368130
         RMSE: 0.606737
         R¬≤ Score: -1.2354 (Poor - 123.5% variance explained)
      üîπ RDDT: Training TCN (50 epochs)...
      ‚è≥ JFIN LSTM: Epoch 30/50 (60%)
      ‚è≥ RDDT TCN: Epoch 10/50 (20%)
      üìä LSTM Regression Metrics:
         MSE: 0.101666
         RMSE: 0.318852
         R¬≤ Score: -0.8947 (Poor - 89.5% variance explained)
      üîπ OPRT: Training TCN (50 epochs)...
      ‚è≥ CONL LSTM: Epoch 20/50 (40%)
      ‚è≥ RDDT TCN: Epoch 20/50 (40%)
      ‚è≥ OPRT TCN: Epoch 10/50 (20%)
      ‚è≥ RDDT TCN: Epoch 30/50 (60%)
       ‚úÖ DPRO Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=397.2992 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ DPRO LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ RDDT TCN: Epoch 40/50 (80%)
      ‚è≥ OPRT TCN: Epoch 20/50 (40%)
      üìä TCN Regression Metrics:
         MSE: 0.206705
         RMSE: 0.454649
         R¬≤ Score: -0.2552
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä RDDT: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ RDDT Random Forest: Starting GridSearchCV fit...
      ‚è≥ OPRT TCN: Epoch 30/50 (60%)
      ‚è≥ JFIN LSTM: Epoch 40/50 (80%)
      ‚è≥ CONL LSTM: Epoch 30/50 (60%)
       ‚úÖ NEXT XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=81.3554 (Best Params: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}) | Time: 125.6s
    - LSTM: MSE=0.3598
    - TCN: MSE=0.3586
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 129.2 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.3586
        ‚Ä¢ LSTM: MSE=0.3598
        ‚Ä¢ LightGBM Regressor (CPU): MSE=63.4641
        ‚Ä¢ Random Forest: MSE=72.5657
        ‚Ä¢ XGBoost: MSE=81.3554
   ‚úÖ NEXT: Phase 3/3 - Model selection complete!
  üèÜ WINNER for NEXT (TargetReturn): TCN with MSE=0.3586
üêõ DEBUG: NEXT - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for NEXT.
üêõ DEBUG: NEXT - Moving model to CPU before return...
üêõ DEBUG [22:29:10.522]: NEXT - Returning result metadata...
üêõ DEBUG: train_worker started for HTZ
üêõ DEBUG [22:29:10.524]: Main received result for NEXT
      ‚è≥ OPRT TCN: Epoch 40/50 (80%)
  ‚öôÔ∏è Training models for HTZ (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-67 - HTZ: Initiating feature extraction for training.
  [DIAGNOSTIC] HTZ: fetch_training_data - Initial data rows: 205
   ‚Ü≥ HTZ: rows after features available: 126
üéØ HTZ: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] HTZ: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö HTZ: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ HTZ: Training LSTM (50 epochs)...
      üìä TCN Regression Metrics:
         MSE: 0.071451
         RMSE: 0.267304
         R¬≤ Score: -0.3316
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä OPRT: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ OPRT Random Forest: Starting GridSearchCV fit...
      ‚è≥ CONL LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.219536
         RMSE: 0.468546
         R¬≤ Score: -1.1575 (Poor - 115.7% variance explained)
      üîπ JFIN: Training TCN (50 epochs)...
      ‚è≥ HTZ LSTM: Epoch 10/50 (20%)
       ‚úÖ DPRO LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=266.6797 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 1.0s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ DPRO XGBoost: Starting GridSearchCV fit...
      ‚è≥ JFIN TCN: Epoch 10/50 (20%)
      ‚è≥ JFIN TCN: Epoch 20/50 (40%)
      ‚è≥ JFIN TCN: Epoch 30/50 (60%)
      ‚è≥ JFIN TCN: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 1.094419
         RMSE: 1.046145
         R¬≤ Score: -1.6235 (Poor - 162.4% variance explained)
      üîπ CONL: Training TCN (50 epochs)...
      ‚è≥ HTZ LSTM: Epoch 20/50 (40%)
      üìä TCN Regression Metrics:
         MSE: 0.101547
         RMSE: 0.318665
         R¬≤ Score: 0.0021
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä JFIN: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ JFIN Random Forest: Starting GridSearchCV fit...
      ‚è≥ CONL TCN: Epoch 10/50 (20%)
      ‚è≥ CONL TCN: Epoch 20/50 (40%)
      ‚è≥ CONL TCN: Epoch 30/50 (60%)
      ‚è≥ CONL TCN: Epoch 40/50 (80%)
      ‚è≥ HTZ LSTM: Epoch 30/50 (60%)
      üìä TCN Regression Metrics:
         MSE: 0.634595
         RMSE: 0.796615
         R¬≤ Score: -0.5213
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä CONL: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ CONL Random Forest: Starting GridSearchCV fit...
      ‚è≥ HTZ LSTM: Epoch 40/50 (80%)
       ‚úÖ EYE Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=113.6470 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.7s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ EYE LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ ESLT Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=15.1751 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.8s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ ESLT LightGBM Regressor (CPU): Starting GridSearchCV fit...
      üìä LSTM Regression Metrics:
         MSE: 0.462730
         RMSE: 0.680243
         R¬≤ Score: -1.2420 (Poor - 124.2% variance explained)
      üîπ HTZ: Training TCN (50 epochs)...
       ‚úÖ RDDT Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=90.4408 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 3.3s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ RDDT LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ HTZ TCN: Epoch 10/50 (20%)
      ‚è≥ HTZ TCN: Epoch 20/50 (40%)
       ‚úÖ EYE LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=79.7815 (Best Params: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.9s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ EYE XGBoost: Starting GridSearchCV fit...
      ‚è≥ HTZ TCN: Epoch 30/50 (60%)
       ‚úÖ ESLT LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=16.3434 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ ESLT XGBoost: Starting GridSearchCV fit...
      ‚è≥ HTZ TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.208601
         RMSE: 0.456729
         R¬≤ Score: -0.0107
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä HTZ: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ HTZ Random Forest: Starting GridSearchCV fit...
       ‚úÖ OPRT Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=199.6203 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.6s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ OPRT LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ RDDT LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=83.0325 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ RDDT XGBoost: Starting GridSearchCV fit...
       ‚úÖ OPRT LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=172.0111 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.8s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ OPRT XGBoost: Starting GridSearchCV fit...
       ‚úÖ JFIN Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=197.7313 (Best Params: {'max_depth': 15, 'n_estimators': 200}) | Time: 3.4s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ JFIN LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ CONL Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=486.1139 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.5s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ CONL LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ JFIN LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=245.1178 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ JFIN XGBoost: Starting GridSearchCV fit...
       ‚úÖ CONL LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=945.7492 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ CONL XGBoost: Starting GridSearchCV fit...
       ‚úÖ HTZ Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=253.0969 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.1s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ HTZ LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ HTZ LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=160.7466 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.6s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ HTZ XGBoost: Starting GridSearchCV fit...
       ‚úÖ BITX XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=74.8295 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}) | Time: 123.8s
    - LSTM: MSE=0.3869
    - TCN: MSE=0.2347
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 127.3 seconds (2.1 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.2347
        ‚Ä¢ LSTM: MSE=0.3869
        ‚Ä¢ LightGBM Regressor (CPU): MSE=74.2392
        ‚Ä¢ XGBoost: MSE=74.8295
        ‚Ä¢ Random Forest: MSE=88.4541
   ‚úÖ BITX: Phase 3/3 - Model selection complete!
  üèÜ WINNER for BITX (TargetReturn): TCN with MSE=0.2347
üêõ DEBUG: BITX - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for BITX.
üêõ DEBUG: BITX - Moving model to CPU before return...
üêõ DEBUG [22:30:21.828]: BITX - Returning result metadata...
üêõ DEBUG: train_worker started for SBSW
üêõ DEBUG [22:30:21.834]: Main received result for BITX
üêõ DEBUG: Training progress: 76/959 done
  ‚öôÔ∏è Training models for SBSW (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-62 - SBSW: Initiating feature extraction for training.
  [DIAGNOSTIC] SBSW: fetch_training_data - Initial data rows: 205
   ‚Ü≥ SBSW: rows after features available: 126
üéØ SBSW: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] SBSW: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö SBSW: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ SBSW: Training LSTM (50 epochs)...
      ‚è≥ SBSW LSTM: Epoch 10/50 (20%)
      ‚è≥ SBSW LSTM: Epoch 20/50 (40%)
      ‚è≥ SBSW LSTM: Epoch 30/50 (60%)
      ‚è≥ SBSW LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.322393
         RMSE: 0.567797
         R¬≤ Score: -1.8043 (Poor - 180.4% variance explained)
      üîπ SBSW: Training TCN (50 epochs)...
      ‚è≥ SBSW TCN: Epoch 10/50 (20%)
      ‚è≥ SBSW TCN: Epoch 20/50 (40%)
      ‚è≥ SBSW TCN: Epoch 30/50 (60%)
      ‚è≥ SBSW TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.181538
         RMSE: 0.426073
         R¬≤ Score: -0.5791
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä SBSW: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ SBSW Random Forest: Starting GridSearchCV fit...
       ‚úÖ SBSW Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=240.7406 (Best Params: {'max_depth': 10, 'n_estimators': 200}) | Time: 3.1s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ SBSW LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ SBSW LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ üéØ BEST! LightGBM Regressor (CPU): MSE=210.4469 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.6s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ SBSW XGBoost: Starting GridSearchCV fit...
       ‚úÖ AS XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=37.6269 (Best Params: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200}) | Time: 129.5s
    - LSTM: MSE=0.6520
    - TCN: MSE=0.4296
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 132.8 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.4296
        ‚Ä¢ LSTM: MSE=0.6520
        ‚Ä¢ Random Forest: MSE=31.6669
        ‚Ä¢ LightGBM Regressor (CPU): MSE=36.4977
        ‚Ä¢ XGBoost: MSE=37.6269
   ‚úÖ AS: Phase 3/3 - Model selection complete!
  üèÜ WINNER for AS (TargetReturn): TCN with MSE=0.4296
üêõ DEBUG: AS - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for AS.
üêõ DEBUG: AS - Moving model to CPU before return...
üêõ DEBUG [22:30:32.027]: AS - Returning result metadata...
üêõ DEBUG [22:30:32.028]: Main received result for AS
üêõ DEBUG: train_worker started for GRNQ
  ‚öôÔ∏è Training models for GRNQ (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-73 - GRNQ: Initiating feature extraction for training.
  [DIAGNOSTIC] GRNQ: fetch_training_data - Initial data rows: 205
   ‚Ü≥ GRNQ: rows after features available: 126
üéØ GRNQ: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] GRNQ: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö GRNQ: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ GRNQ: Training LSTM (50 epochs)...
      ‚è≥ GRNQ LSTM: Epoch 10/50 (20%)
      ‚è≥ GRNQ LSTM: Epoch 20/50 (40%)
      ‚è≥ GRNQ LSTM: Epoch 30/50 (60%)
      ‚è≥ GRNQ LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.520055
         RMSE: 0.721148
         R¬≤ Score: -1.1503 (Poor - 115.0% variance explained)
      üîπ GRNQ: Training TCN (50 epochs)...
      ‚è≥ GRNQ TCN: Epoch 10/50 (20%)
      ‚è≥ GRNQ TCN: Epoch 20/50 (40%)
      ‚è≥ GRNQ TCN: Epoch 30/50 (60%)
      ‚è≥ GRNQ TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.441939
         RMSE: 0.664785
         R¬≤ Score: -0.8273
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä GRNQ: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ GRNQ Random Forest: Starting GridSearchCV fit...
       ‚úÖ CAR XGBoost: GridSearchCV complete
    ‚úÖ ‚ûñ XGBoost: MSE=188.7472 (Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}) | Time: 130.4s
    - LSTM: MSE=0.5554
    - TCN: MSE=0.4408
  ‚úÖ GridSearchCV optimization complete! Processed 5/3 models successfully
     ‚è±Ô∏è  Total time: 133.6 seconds (2.2 minutes)
     üìä Results summary:
        ‚Ä¢ TCN: MSE=0.4408
        ‚Ä¢ LSTM: MSE=0.5554
        ‚Ä¢ Random Forest: MSE=107.9902
        ‚Ä¢ LightGBM Regressor (CPU): MSE=119.2936
        ‚Ä¢ XGBoost: MSE=188.7472
   ‚úÖ CAR: Phase 3/3 - Model selection complete!
  üèÜ WINNER for CAR (TargetReturn): TCN with MSE=0.4408
üêõ DEBUG: CAR - train_and_evaluate_models completed
  ‚úÖ Single regression model, scaler, y_scaler, and GRU hyperparams saved for CAR.
üêõ DEBUG: CAR - Moving model to CPU before return...
üêõ DEBUG [22:30:37.804]: CAR - Returning result metadata...
üêõ DEBUG [22:30:37.805]: Main received result for CAR
üêõ DEBUG: train_worker started for PAYS
  ‚öôÔ∏è Training models for PAYS (FORCE_TRAINING is True, CONTINUE_TRAINING_FROM_EXISTING is False)...
  [DEBUG] SpawnPoolWorker-68 - PAYS: Initiating feature extraction for training.
  [DIAGNOSTIC] PAYS: fetch_training_data - Initial data rows: 205
   ‚Ü≥ PAYS: rows after features available: 126
üéØ PAYS: Starting model training (LSTM‚ÜíTCN‚ÜíML models)...
  [DIAGNOSTIC] PAYS: train_and_evaluate_models - Rows after dropping NaNs: 126
    - Using MSE loss for regression (predicting returns)
   üìö PAYS: Phase 1/3 - Training Deep Learning models (LSTM, TCN)...
      üîπ PAYS: Training LSTM (50 epochs)...
       ‚úÖ GRNQ Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=164.3126 (Best Params: {'max_depth': 10, 'n_estimators': 100}) | Time: 2.6s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ GRNQ LightGBM Regressor (CPU): Starting GridSearchCV fit...
      ‚è≥ PAYS LSTM: Epoch 10/50 (20%)
      ‚è≥ PAYS LSTM: Epoch 20/50 (40%)
       ‚úÖ GRNQ LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=209.9105 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ GRNQ XGBoost: Starting GridSearchCV fit...
      ‚è≥ PAYS LSTM: Epoch 30/50 (60%)
      ‚è≥ PAYS LSTM: Epoch 40/50 (80%)
      üìä LSTM Regression Metrics:
         MSE: 0.780561
         RMSE: 0.883493
         R¬≤ Score: -1.0396 (Poor - 104.0% variance explained)
      üîπ PAYS: Training TCN (50 epochs)...
      ‚è≥ PAYS TCN: Epoch 10/50 (20%)
      ‚è≥ PAYS TCN: Epoch 20/50 (40%)
      ‚è≥ PAYS TCN: Epoch 30/50 (60%)
      ‚è≥ PAYS TCN: Epoch 40/50 (80%)
      üìä TCN Regression Metrics:
         MSE: 0.622382
         RMSE: 0.788912
         R¬≤ Score: -0.6263
  üî¨ Comparing regressor performance (MSE via cross-validation with GridSearchCV):
   üìä PAYS: Phase 2/3 - Optimizing 3 traditional ML models with GridSearchCV...
     ‚ö° Using 3-fold cross-validation, parallel processing enabled
    üîç Optimizing Random Forest (1/3) - Testing 4 parameter combinations √ó 3-fold CV = 12 total model trainings...
       ‚è≥ PAYS Random Forest: Starting GridSearchCV fit...
       ‚úÖ PAYS Random Forest: GridSearchCV complete
    ‚úÖ üéØ BEST! Random Forest: MSE=95.5097 (Best Params: {'max_depth': 15, 'n_estimators': 100}) | Time: 2.7s
    üîç Optimizing LightGBM Regressor (CPU) (2/3) - Testing 18 parameter combinations √ó 3-fold CV = 54 total model trainings...
       ‚è≥ PAYS LightGBM Regressor (CPU): Starting GridSearchCV fit...
       ‚úÖ PAYS LightGBM Regressor (CPU): GridSearchCV complete
    ‚úÖ ‚ûñ LightGBM Regressor (CPU): MSE=275.6376 (Best Params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200}) | Time: 0.7s
    üîç Optimizing XGBoost (3/3) - Testing 8 parameter combinations √ó 3-fold CV = 24 total model trainings...
       ‚è≥ PAYS XGBoost: Starting GridSearchCV fit...
